# 2024 面试准备

# 3、JVM 部分面试题

## JVM

### 具体问题

- JVM了解吗，说说所知道的
  （？？我讲了内存区域、垃圾回收、类加载，然后，面试官说可以了）

- 你平时用的JVM版本是什么？最新版本是什么？

- **为什么要指针压缩，为什么能指针压缩？原理是什么？**

- 能说一下JVM的模型吗？

- 说说jvm？（说了内存区域和垃圾回收）

- 垃圾回收算法，jvm运行时区域等

- **JVM虚拟机启动有哪些线程？**

- **staic 和 final 关键字结合 jvm 来讲**

- GC 底层算法，JVM 内存模型，常见的垃圾回收器，双亲委派的类加载流程；

- 讲下 JVM。这块主要我自己在说，一口气说下来说了有二十多分钟吧，面试官一直没说话，我就一直说，从运行时数据区，讲到一个类具体是如何存储的，再讲到垃圾回收机制和垃圾收集算法，再讲到各个版本的 JDK 的垃圾收集器，再讲到 YoungGC 和 FullGC，再讲 YoungGC 的具体过程，对象是如何分配的，出现 OOM 时如何排查，已经自己在项目的一个 GC 调优做的具体工作  

- 问我a=2,b=1,c=a+b底层具体是一个什么样的过程，答了java内存的分布，具体在哪个位置，比如常量池在方法区，然后栈存对常量的应用之类的。
  问底层呢我答内存拷贝，问有多少次内存拷贝，然后又问在多核cpu和多线程下，然后也是这种情况，cpu和底层又具体是什么样的过程，互相之间怎么影响，怎么不影响。

- 问我对jvm的垃圾回收了解吗，说了从新生代到老年代的整体的过程，用什么垃圾回收算法，举了几个垃圾回收器的例子，说来空间分配担保和可能产生full gc的原因，反正尽可能细的去说自己知道的，越细越好。

- 讲讲 GC，初生代有哪几个块，怎么晋升到老年代，什么时候是 FULL GC，最好再给他讲讲 JVM 调优，我一般都说这是我作为兴趣爱好了解的，了解的不深，不懂的水面试官会觉得你再谦虚，懂得你就说了解的比较少，可能听过-xx 之类的命令把初生代内存设置大一些，少一些 Minor GC 会提升性能之类的。

- JVM 调优的目的？GC 的种类？垃圾回收算法有哪些？好像还问了为什么要分区。(笔试的时候有关于 JVM 参数的一些问题，我没背)

- 这三行代码 jvm 做了什么事情

  - ```java
    String a = "123";
    String b = new("456");
    String c = a + b;
    ```

- jvm 内存结构，垃圾回收策略，垃圾回收算法

### 思考方向

- 《深入理解 Java 虚拟机：JVM 高级特性与最佳实践》目录
  1. 走近 Java
     - 1.4 Java 虚拟机家族
       - 1.4.1 Sun Classic/Exact VM
         - 虚拟机始祖，JDK 1.4 退出商用虚拟机历史舞台
       - 1.4.2 HotSpot VM
         - Sun/Oracle JDK 和 OpenJDK 的默认虚拟机，也是目前使用最广的 Java 虚拟机
       - 1.4.3 Mobile/Embedded VM
         - 移动和嵌入式
       - 1.4.4 BEA JRockit / IBM J9 VM
         - BEA 已被 Oracle 收购，JDK 6 开始 JRockit 不再发展
         - J9 已完全开源，捐献给 Eclipse 基金会管理
       - 1.4.5 BEA Liquid VM / Azul VM
         - 与特定硬件平台绑定、软硬件配合工作的专有虚拟机
       - 1.4.6 Apache Harmony / Google Android Dalvik VM
         - 挑战者，不算严格的“Java 虚拟机”
       - 1.4.7 Microsoft JVM
         - Windows XP SP3 中 Java 虚拟机被完全抹去
     - 1.5 展望 Java 技术的未来
       - 1.5.1 无语言倾向
         - Graal VM
       - 1.5.2 新一代即时编译器
         - Graal 编译器
       - 1.5.3 向 Native 迈进
         - Substrate VM
       - 1.5.4 灵活的胖子
         - 在 JDK 9 时期，HotSpot 虚拟机开放了 Java 语言级别的编译器接口（Java Virtual Machine Compiler Interface，JVMCI）
         - 到了 JDK 10，HotSpot 又重构了Java虚拟机的垃圾收集器接口（Java Virtual Machine Compiler Interface），统一了其内部各款垃圾收集器的公共行为。
       - 1.5.5 语言语法持续增强
         - Coins 项目（在 JDK 7 已结束，反映 Java 语言中的微小变动）
         - Amber 项目（Coins 后新的语言特性改进项目）
         - Loom 项目（虚拟线程）
         - Valhalla 项目（提供值类型和基本类型的泛型支持，并提供明确的不可变类型和非引用类型的声明）
         - Panama 项目（目的是消弭Java虚拟机与本地代码之间的界线）
  2. Java 内存区域与内存溢出异常
     - 2.2 运行时数据区域
       - 2.2.1 程序计数器
         - 线程隔离
       - 2.2.2 Java 虚拟机栈
         - 线程隔离
       - 2.2.3 本地方法栈
         - 线程隔离
       - 2.2.4 Java 堆
         - 所有线程共享
       - 2.2.5 方法区
         - 所有线程共享
       - 2.2.6 运行时常量池
       - 2.2.7 直接内存
     - 2.3 HotSpot 虚拟机对象探秘
       - 2.3.1 对象的创建
       - 2.3.2 对象的内存布局
         - 对象头
         - 实例数据
         - 对齐填充
       - 2.3.3 对象的访问定位
         - 句柄
         - 直接指针
     - 2.4 实战：OutOfMemoryError 异常
       - 2.4.1 Java 堆溢出
       - 2.4.2 虚拟机栈和本地方法栈溢出
       - 2.4.3 方法区和运行时常量池溢出
       - 2.4.4 本地直接内存溢出
  3. 垃圾收集器与内存分配策略
     - 3.2 对象已死？
       - 3.2.1 引用计数算法
       - 3.2.2 可达性分析算法
       - 3.2.3 再谈引用
         - 强、软、弱、虚
       - 3.2.4 生存还是死亡？
         - finalize()
       - 3.2.5 回收方法区
         - 方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型
     - 3.3 垃圾收集算法
       - 3.3.1 分代收集理论
       - 3.3.2 标记-清除算法
       - 3.3.3 标记-复制算法
       - 3.3.4 标记-整理算法
     - 3.4 HotSpot 的算法细节实现
       - 3.4.1 根节点枚举
       - 3.4.2 安全点
         - 有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。
       - 3.4.3 安全区域
         - 安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。
       - 3.4.4 记忆集和卡表
         - 垃圾收集器在新生代中建立了名为记忆集（Remembered Set）的数据结构，用以避免把整个老年代加进GC Roots 扫描范围
         - 可以用一种称为“卡表”（Card Table）的方式去实现记忆集
           - 记录精度为“卡精度”：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。
       - 3.4.5 写屏障
         - 写前屏障
         - 写后屏障
           - 直至 G1 收集器出现之前，其他收集器都只用到了写后屏障
       - 3.4.6 并发的可达性分析
         - 并发扫描过程：三色标记（Tri-color Marking）
         - 并发扫描时对象消失问题的两种解决方案：
           - 增量更新（Incremental Update）
           - 原始快照（Snapshot At The Beginning，SATB）
     - **3.5 经典垃圾收集器**
       - 3.5.1 Serial 收集器
       - 3.5.2 ParNew 收集器
       - 3.5.3 Parallel Scavenge 收集器
       - 3.5.4 Serial Old 收集器
       - 3.5.5 Parallel Old 收集器
       - **3.5.6 CMS 收集器**
       - **3.5.7 Garbage First 收集器**
     - 3.6 低延迟垃圾收集器
       - **3.6.1 Shenandoah 收集器**
       - **3.6.2 ZGC 收集器**
     - 3.7 选择合适的垃圾收集器
       - 3.7.1 Epsilon 收集器
       - 3.7.2 收集器的权衡
       - 3.7.3 虚拟机及垃圾收集器日志
       - 3.7.4 垃圾收集器参数总结
     - 3.8 实战：内存分配与回收策略
       - 3.8.1 对象优先在 Eden 分配
       - 3.8.2 大对象直接进入老年代
       - 3.8.3 长期存活的对象将进入老年代
       - 3.8.4 动态对象年龄判定
       - 3.8.5 空间分配担保
  4. **虚拟机性能监控、故障处理工具**
     - 4.2 基础故障处理工具
       - 4.2.1 jps：虚拟机进程状况工具
       - 4.2.2 jstat：虚拟机统计信息监视工具
       - 4.2.3 jinfo：Java 配置信息监视工具
       - 4.2.4 jmap：Java 内存映像工具
       - 4.2.5 jhat：虚拟机堆转储快照分析工具
       - 4.2.6 jstack：Java 堆栈跟踪工具
       - 4.2.7 基础工具总结
     - 4.3 可视化故障处理工具
       - 4.3.1 JHSDB：基于服务性代理的调试工具
       - 4.3.2 JConsole：Java 监视和管理控制台
       - 4.3.3 VisualVM：多合一故障处理工具
       - 4.3.4 Java Mission Control：可持续在线的监控工具
     - 4.4 HotSpot 虚拟机插件及工具
  5. **调优案例分析与实战**
     - 5.2 案例分析
       - 5.2.1 大内存硬件上的程序部署策略
       - 5.2.2 集群间同步导致的内存溢出
       - 5.2.3 堆外内存导致的溢出错误
       - 5.2.4 外部命令导致系统缓慢
       - 5.2.5 服务器虚拟机进程崩溃
       - 5.2.6 不恰当数据结构导致内存占用过大
       - 5.2.7 由 Windows 虚拟内存导致的长时间停顿
       - 5.2.8 由安全点导致长时间停顿
     - 5.3 实战：Eclipse 运行速度调优
       - 5.3.1 调优前的程序运行状态
       - 5.3.2 升级 JDK 版本的性能变化及兼容问题
       - 5.3.3 编译时间和类加载时间的优化
       - 5.3.4 调整内存设置控制垃圾收集频率
       - 5.3.5 选择收集器降低延迟
  6. 类文件结构
     - 6.2 无关性的基石
     - 6.3 Class 类文件的结构
       - 6.3.1 魔数与 Class 文件的版本
       - 6.3.2 常量池
       - 6.3.3 访问标志
       - 6.3.4 类索引、父类索引与接口索引集合
       - 6.3.5 字段表集合
       - 6.3.6 方法表集合
       - 6.3.7 属性表集合
     - 6.4 字节码指令简介
       - 6.4.1 字节码与数据类型
       - 6.4.2 加载和存储指令
       - 6.4.3 运算指令
       - 6.4.4 类型转换指令
       - 6.4.5 对象创建与访问指令
       - 6.4.6 操作数栈管理指令
       - 6.4.7 控制转移指令
       - 6.4.8 方法调用和返回指令
       - 6.4.9 异常处理指令
       - 6.4.10 同步指令
     - 6.5 公有设计，私有实现
     - 6.6 Class 文件结构的发展
  7. 虚拟机类加载机制
     - 7.2 类加载的时机
     - **7.3 类加载的过程**
       - 7.3.1 加载
       - 7.3.2 验证
       - 7.3.3 准备
       - 7.3.4 解析
       - 7.3.5 初始化
     - 7.4 类加载器
       - 7.4.1 类与类加载器
       - **7.4.2 双亲委派模型**
       - 7.4.3 破坏双亲委派模型
     - 7.5 Java 模块化系统
       - 7.5.1 模块的兼容性
       - 7.5.2 模块化下的类加载器
  8. 虚拟机字节码执行引擎
     - **8.2 运行时栈帧结构**
       - 8.2.1 局部变量表
       - 8.2.2 操作数栈
       - 8.2.3 动态连接
       - 8.2.4 方法返回地址
       - 8.2.5 附加信息
     - 8.3 方法调用
       - 8.3.1 解析
       - 8.3.2 分派
     - **8.4 动态类型语言支持**
       - 8.4.1 动态类型语言
       - 8.4.2 Java 与动态类型
       - 8.4.3 java.lang.invoker 包
       - 8.4.4 invokedynamic 指令
       - 8.4.5 实战：掌控方法分派规则
     - 8.5 基于栈的字节码解释执行引擎
       - 8.5.1 解释执行
       - 8.5.2 基于栈的指令集与基于寄存器的指令集
       - 8.5.3 基于栈的解释器执行过程
  9. 类加载及其执行子系统的案例与实战
     - 9.2 案例分析
       - 9.2.1 Tomcat：正统的类加载器架构
       - **9.2.2 OSGi：灵活的类加载器架构**
       - 9.2.3 字节码生成技术与动态代理的实现
       - 9.2.4 Backport 工具：Java 的时光机器
     - 9.3 实战：自己动手实现远程执行功能
  10. 前端编译与优化
      - 10.2 Javac 编译器
        - 10.2.1 Javac 的源码与调试
        - 10.2.2 解析与填充符号表
        - 10.2.3 注解处理器
        - 10.2.4 语义分析与字节码生成
      - **10.3 Java 语法糖的味道**
        - **10.3.1 泛型**
        - **10.3.2 自动装箱、拆箱与遍历循环**
        - **10.3.3 条件编译**
      - 10.4 实战：插入式注解处理器
  11. 后端编译与优化
      - 11.2 即时编译器
        - 11.2.1 解释器与编译器
        - 11.2.2 编译对象与触发条件
        - 11.2.3 编译过程
        - 11.2.4 实战：查看及分析即时编译结果
      - 11.3 提前编译器
        - 11.3.1 提前编译的优劣得失
        - 11.3.2 实战：Jaotc 的提前编译
      - **11.4 编译器优化技术**
        - 11.4.1 优化技术概览
        - 11.4.2 方法内联
        - **11.4.3 逃逸分析**
        - 11.4.4 公共子表达式消除
        - 11.4.5 数组边界检查消除
      - 11.5 实战：深入理解 Graal 编译器
        - 11.5.1 历史背景
        - 11.5.2 构建编译调试环境
        - 11.5.3 JVMCI 编译器接口
        - 11.5.4 代码中间表示
        - 11.5.5 代码优化和生成
  12. Java 内存模型与线程
      - 12.2 硬件的效率与一致性
      - **12.3 Java 内存模型**
        - 12.3.1 主内存与工作内存
        - 12.3.2 内存间交互操作
        - 12.3.3 对于 volatile 型变量的特殊规则
        - 12.3.4 针对 long 和 double 型变量的特殊规则
        - 12.3.5 原子性、可见性与有序性
        - **12.3.6 先行发生原则**
      - 12.4 Java 与线程
        - 12.4.1 线程的实现
        - 12.4.2 Java 线程调度
        - 12.4.3 状态转换
      - 12.5 Java 与协程
        - 12.5.1 内核线程的局限
        - 12.5.2 协程的复苏
        - 12.5.3 Java 的解决方案
  13. 线程安全与锁优化
      - 13.2 线程安全
        - 13.2.1 Java 语言中的线程安全
        - 13.2.2 线程安全的实现方法
      - **13.3 锁优化**
        - **13.3.1 自旋锁与自适应自旋**
        - **13.3.2 锁消除**
        - **13.3.3 锁粗化**
        - **13.3.4 轻量级锁**
        - **13.3.5 偏向锁**
- 常考 Java 基础/多线程对应的 JVM 底层实现
  - static
  - final
    - 局部变量时变量不变性由 javac 编译器在编译期保障
  - 成员变量、局部变量
  - 类变量、构造函数、静态代码块加载顺序
    - `<clinit>()`
  - try-catch-finally
  - try-with-resources
  - 数组
  - 多态
  - 重写（Override）
    - 动态分派
  - 重载（Overload）
    - 静态分派
  - 泛型
    - 桥方法
  - 枚举类
  - 内部类
    - $
    - 类 final 变量
  - lambda 表达式
  - String
    - intern()
  - 自动装箱/拆箱
  - switch 对枚举和字符串的支持
  - for-each 循环
  - synchronized
  - volatile
- 其他常见框架/语言的 JVM 底层实现
  - Lombok
    - 插入式注解处理器

  - 动态类型语言
    - invokedynamic

  - 动态代理
    - 字节码：Javassist、CGLib、ASM


## 内存区域

### 具体问题

- jvm的基本结构
- jvm中那些结构是线程独有和共有的
- jvm 堆栈，区别，线程共享还是线程私有的
- JVM 运行时数据区？
- 在JDK8中移除永久代，并把方法区移至元空间，这么设计的原因是什么 `【2次】`
- **元空间需要进行GC么？需要的话，元空间的GC是young gc还是full gc**
- JVM内存空间分布
- JVM内存结构
- 你对jvm有了解吗？说一下jvm的内存分区？
  堆里面怎么分区的？（这题真不会，只说知道为了方便垃圾回收所以分了新生代区和老年代区，其他的真不知道）
- jvm分区模型
- 首先是模型分成哪几块，堆 栈等等。。
- 哪些是线程私有的哪些是共有的
- 1.6之前和现在1.8哪些地方做了改动(主要是静态区的变化)
- 说一说jvm的分区
- JVM内存结构
- JVM 内存划分， 堆内存分代
- JVM中的内存区域划分，堆的分代，为什么分代， 垃圾回收算法，垃圾回收器
- JVM堆划分，方法区
- JVM 运行时数据区，Synchronized 和 ReentrantLock 区别
- JVM 运行时数据区
- 堆空间怎么分的
- jvm内存分区？常量在哪？变量在哪？堆怎么划分的？
- jvm内存分区，gc发生在哪？
- 数组长度不确定，能在栈上分配内存吗？
- jvm的内存布局和gc过程
- JVM 的内存结构，哪些是线程私有，哪些是线程公有
- JVM 的结构，垃圾收集算法
-  JVM 内存区域
- JVM 的基本结构
- 运行时数据区的基本结构，各种结构都有什么用途
- Jvm 内存结构
- 堆和栈有什么区别
- 堆 和 栈 的区别？
- JVM 内存区域(两次问到，我顺便说了说永生代和元空间，两次面试看面试官表情应该算半拉亮点)
- JVM 的内存划分，各个部分的作用是什么？
- JVM 每个区具有什么功能？
- 元空间是起到什么作用？
- JVM 内存模型，哪些是公有的，哪些是私有的
- 堆是干嘛的，
- 常量池放在方法区和堆上有什么区别，是在更轻量的 GC 上回收
- 介绍一下 JVM 的内存区域？

### 易混点

- 内存模型
  - 是不同的概念。不知道是面经里面作者自己搞不懂，还是面试官自己搞不懂，容易把这两个混为一谈。

### 思考方向

#### 2.2 运行时数据区域

- 方法区、堆、虚拟机栈、本地方法栈、程序计数器

##### 2.2.1 程序计数器

- 线程隔离
  - 因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。
- 内容
  - 如果线程正在执行的是一个 Java 方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址
  - 如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined）
- 唯一在《Java 虚拟机规范》中没有规定任何 OutOfMemoryError 情况的区域

##### 2.2.2 Java 虚拟机栈

- 线程隔离
- 虚拟机栈描述的是 Java 方法执行的线程内存模型：每个方法被执行的时候，Java 虚拟机都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。
- 局部变量表
  - 内容
    - 存放了编译期可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、float、long、double）
    - 对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）
    - returnAddress 类型（指向了一条字节码指令的地址）
  - 这些数据类型在局部变量表中的存储空间以**局部变量槽（Slot）**来表示
    - 其中 64 位长度的 long 和 double 类型的数据会占用两个变量槽，其余的数据类型只占用一个
  - 局部变量表所需的内存空间在编译期间完成分配
    - 当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小
- 在《Java虚拟机规范》中，对这个内存区域规定了两类异常状况
  - 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常
  - 如果 Java 虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出 OutOfMemoryError 异常。
    - 具体虚拟机实现是否会抛出对应异常，请参考下面 OOM 专题。
      - **HotSpot 栈在创建线程申请内存以外时就不会 OOM**

##### 2.2.3 本地方法栈

- 线程隔离
- 虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native）方法服务
- **Hot-Spot 虚拟机直接就把本地方法栈和虚拟机栈合二为一**
- 与虚拟机栈一样，也会在栈深度溢出或者栈扩展失败时分别抛出 StackOverflowError 和 OutOfMemoryError 异常。
  - 具体虚拟机实现是否会抛出对应异常，请参考下面 OOM 专题。
    - **HotSpot 栈在创建线程申请内存以外时就不会 OOM**

##### 2.2.4 Java 堆

- 所有线程共享
- 是虚拟机所管理的内存中最大的一块。
- 在虚拟机启动时创建。
- 此内存区域的唯一目的就是存放对象实例
  - 即时编译技术：逃逸分析、栈上分配、标量替换 -> Java 对象实例都分配在堆上也渐渐变得不是那么绝对了
- 如果从分配内存的角度看，所有线程共享的 Java 堆中可以划分出多个线程私有的分配缓冲区（Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。
- 如果在 Java 堆中没有内存完成实例分配，并且堆也无法再扩展时，Java 虚拟机将会抛出 OutOfMemoryError 异常。

##### 2.2.5 方法区

- 所有线程共享

- 它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据

- 永久代：

  - JDK 8 以前 HostSpot 的实现

    - HotSpot虚拟机设计团队当初选择把收集器的分代设计扩展至方法区，或者说使用永久代来实现方法区而已
    - BEA JRockit、IBM J9 等没有永久代

  - JDK 6 的时候，HotSpot 开发团队就有放弃永久代，逐步改为采用本地内存（Native Memory）来实现方法区的计划了

  - JDK 7 的 HotSpot，已经把原本放在永久代的字符串常量池、静态变量等移出

  - JDK 8 终于完全废弃了永久代的概念，改用与 JRockit、J9 一样在本地内存中实现的元空间（Metaspace）来代替，把 JDK 7 中永久代还剩余的内容（主要是类型信息）全部移到元空间中

- 如果方法区无法满足新的内存分配需求时，将抛出 OutOfMemoryError 异常

##### 2.2.6 运行时常量池

- **运行时常量池（Runtime Constant Pool）是方法区的一部分。**
- Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。
  - 一般来说，除了保存 Class 文件中描述的符号引用外，还会把由符号引用翻译出来的直接引用也存储在运行时常量池中
- 运行时常量池相对于 Class 文件常量池的另外一个重要特征是具备动态性
  - 运行期间也可以将新的常量放入池中
  - 这种特性被开发人员利用得比较多的便是 String 类的 intern() 方法
- 当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。

##### 2.2.7 直接内存

- **并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域**
- 但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现
- NIO
  - 在 JDK 1.4 中新加入了 NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式
  - 它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作
  - 这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。
- 内存溢出
  - 显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括物理内存、SWAP分区或者分页文件）大小以及处理器寻址空间的限制
  - 一般服务器管理员配置虚拟机参数时，会根据实际内存去设置-Xmx等参数信息，但经常忽略掉直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常

## 对象的创建

### 具体问题

- 对象创建过程？
- 创建对象一定是在堆上创建吗，每次创建对象都是在堆上申请内存的吗
- 对象的生命周期（new 一个对象的过程）？

### 思考方向

#### 2.3 HotSpot 虚拟机对象探秘

##### 2.3.1 对象的创建

- 文中讨论的对象限于普通 Java 对象，不包括数组和 Class 对象等
- 过程
  - 类加载
    - 当 Java 虚拟机遇到一条字节码 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程
  - 分配内存
    - 对象所需内存的大小在类加载完成后便可完全确定
    - 堆内存规整 -> 分配方式：指针碰撞（Serial、ParNew）
    - 堆内存不规整 -> 分配方式：空闲列表（CMS）
    - 垃圾收集器是否有“空间压缩整理”能力决定是否规整
    - 线程安全
      - 可选方案一：CAS
      - 可选方案二：本地线程分配缓冲（Thread Local Allocation Buffer，TLAB）
  - 初始化零值
    - 内存分配完成之后，虚拟机必须将分配到的内存空间（但不包括对象头）都初始化为零值
    - 如果使用了 TLAB 的话，这一项工作也可以提前至 TLAB 分配时顺便进行
  - 进行必要的设置
    - 这些信息存放在对象的对象头（Object Header）之中。
      - 这个对象是哪个类的实例
      - 如何才能找到类的元数据信息
      - 对象的哈希码（实际上对象的哈希码会延后到真正调用 Object::hashCode() 方法时才计算）
      - 对象的GC分代年龄等信息。
    - 根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。
  - 从虚拟机的视角来看，一个新的对象已经产生了
    - 但是从 Java 程序的视角看来，对象创建才刚刚开始
      - 构造函数，即 Class 文件中的 `<init>()` 方法还没有执行
      - 所有的字段都为默认的零值
      - 对象需要的其他资源和状态信息也还没有按照预定的意图构造好。
    - new 指令之后会接着执行 `<init>()` 方法，按照程序员的意愿对对象进行初始化，这样一个真正可用的对象才算完全被构造出来

##### 2.3.2 对象的内存布局

- 对象头

  - 用于存储对象自身的运行时数据（Mark Word）

    - 标志位：锁状态标志

    - 存储内容

      | 存储内容                              | 标志位 | 状态               |
      | ------------------------------------- | ------ | ------------------ |
      | 对象哈希码（HashCode）、对象分代年龄  | 01     | 未锁定             |
      | 指向锁记录的指针                      | 00     | 轻量级锁定         |
      | 指向重量级锁的指针                    | 10     | 膨胀（重量级锁定） |
      | 空，不需要记录信息                    | 11     | GC 标记            |
      | 偏向线程 ID、偏向时间戳、对象分代年龄 | 01     | 可偏向             |

  - 类型指针

    - 对象指向它的类型元数据的指针

  - 如果对象是一个 Java 数组，还必须有一块用于记录数组长度的数据

    - 因为虚拟机可以通过普通 Java 对象的元数据信息确定 Java 对象的大小
    - 但是如果数组的长度是不确定的，将无法通过元数据中的信息推断出数组的大小

- 实例数据

  - 是对象真正存储的有效信息
  - 即我们在程序代码里面所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类中定义的字段都必须记录起来
    - 这部分的存储顺序会受到虚拟机分配策略参数（-XX：FieldsAllocationStyle 参数）和字段在 Java 源码中定义顺序的影响
    - HotSpot虚拟机默认的分配顺序为 longs/doubles、ints、shorts/chars、bytes/booleans、oops（Ordinary Object Pointers，OOPs），从以上默认的分配策略中可以看到，相同宽度的字段总是被分配到一起存放、
    - 在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前

- 对齐填充

  - 任何对象的大小都必须是 8 字节的整数倍

##### 2.3.3 对象的访问定位

- 句柄
  - Java 堆中将可能会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息
  - 好处：reference 中存储的是稳定句柄地址
    - 在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而 reference 本身不需要被修改
- 直接指针
  - Java 堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference 中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销
  - 好处：速度更快
    - 它节省了一次指针定位的时间开销，由于对象访问在 Java 中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本
  - HotSpot 主要使用该方式进行对象访问
    - 有例外情况，如果使用了 Shenandoah 收集器的话也会有一次额外的转发

## 内存溢出异常 OOM、内存泄漏

### 具体问题

- JVM OOM 排查？
- 什么会导致栈溢出、堆内存溢出？
- 怎么排查堆溢出
- 说下java里面的OOM
- JVM内存管理和垃圾回收。哪些操作会导致OOM？循环引用怎么解决？
- 内存泄漏，out of memory
- outofmemory，内存泄漏
- outofmemory遇到过没，设置jvm参数吗？
- 那你说说java泄露，可以写一个程序吗？
  （我当初一听第一反应就是终于我这个会了，就回答说： 这个问题很好解决，就说 只要写一个程序 无限创建一个new对象，这个对象是强引用，就可以保证堆被撑破，他说不行，我最后又加了一句，在这个基础上，循环引用，不会被GC，面试官最后说还是不行，其实当初也是慌了，就真的不知道该怎么办了，因为以前看过OOM怎么解决，但是没想过怎么产生OOM，觉得能产生OOM的还被面试官一直否决，最后面试完在网上查才知道，其实应该再加一个条件，就是循环引用的同时，保证一个对象必须是GC root，我当初面试也没尝试再说这一句，只能说紧张加学艺不精）
  评论：是不是问的是内存泄露，而你好像理解成内存溢出惹…？
- 内存溢出的原因 如何排查
- 什么是内存泄漏？什么是内存溢出？什么时候会发生内存泄露
- 什么时候会 OOM，服务 OOM 怎么办，如何排查
- Java 内存泄漏和排查
- 有没有调试过内存溢出的错误？
- 怎么解决内存泄露；
- 什么时候会有内存泄漏，怎么排查

### 思考方向

#### 2.4 实战：OutOfMemoryError 异常

- 除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生 OutOfMemoryError（下文称 OOM）异常的可能

##### 2.4.1 Java 堆溢出

- ```
  java.lang.OutOfMemoryError: Java heap space
  ```

- 如何制造 OOM

  - 只要不断地创建对象
  - 保证 GC Roots 到对象之间有可达路径来避免垃圾回收机制清除这些对象
  - 那么随着对象数量的增加，总容量触及最大堆的容量限制后就会产生 OOM

- 处理方法

  - 通过内存映像分析工具（如Eclipse Memory Analyzer）对 Dump 出来的堆转储快照进行分析
  - 确认内存中导致 OOM 的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）
    - 如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，找到泄漏对象是通过怎样的引用路径、与哪些 GC Roots 相关联，才导致垃圾收集器无法回收它们
    - 如果不是内存泄漏，换句话说就是内存中的对象确实都是必须存活的，那就应当检查 Java 虚拟机的堆参数（-Xmx与-Xms）设置，与机器的内存对比，看看是否还有向上调整的空间。再从代码上检查是否存在某些对象生命周期过长、持有状态时间过长、存储结构设计不合理等情况，尽量减少程序运行期的内存消耗
  - 详情见后续调优、工具等内容

##### 2.4.2 虚拟机栈和本地方法栈溢出

- HotSpot 虚拟机中并不区分虚拟机栈和本地方法栈

  - -Xoss 参数（设置本地方法栈大小）虽然存在，但实际上是没有任何效果的
  - 栈容量只能由 -Xss 参数来设定。

- HotSpot 虚拟机不支持栈的动态扩展

  - 除非在创建线程申请内存时就因无法获得足够内存而出现 OutOfMemoryError 异常

    - 通过不断建立线程的方式，在 HotSpot 上也是可以产生内存溢出异常的

    - ```
      java.lang.OutOfMemoryError: unable to create native thread
      ```

      - 从 JDK 7 起，以上提示信息中“unable to create native thread”后面，虚拟机会特别注明原因可能是“possiblyout of memory or process/resource limits reached”。

  - 否则在线程运行时是不会因为扩展而导致内存溢出的，只会因为栈容量无法容纳新的栈帧而导致 StackOverflowError 异常。

##### 2.4.3 方法区和运行时常量池溢出

- 运行时常量池是方法区的一部分

- String::intern() 是一个本地方法，它的作用是如果字符串常量池中已经包含一个等于此 String 对象的字符串，则返回代表池中这个字符串的 String 对象的引用；否则，会将此 String 对象包含的字符串添加到常量池中，并且返回此 String 对象的引用

- JDK 6 前的永久代

  - ```
    java.lang.OutOfMemoryError: PermGen space
    ```

  - 在 JDK 6 中，intern() 方法会把首次遇到的字符串实例复制到永久代的字符串常量池中存储，返回的也是永久代里面这个字符串实例的引用

    - 而由 StringBuilder 创建的字符串对象 str2 实例在 Java 堆上，所以和对应 str2.intern() 必然不可能是同一个引用

- JDK 7 起字符串常量移至 Java 堆之中

  - ```
    java.lang.OutOfMemoryError: Java heap space
    ```

  - 而 JDK 7（以及部分其他虚拟机，例如 JRockit）的 intern() 方法实现就不需要再拷贝字符串的实例到永久代了，既然字符串常量池已经移到 Java 堆中，那只需要在常量池里记录一下首次出现的实例引用即可，因此 intern() 返回的引用和由 StringBuilder 创建的那个字符串实例就是同一个。

- JDK 8 起元空间

  - -XX：MaxMetaspaceSize：设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。
  - -XX：MetaspaceSize：指定元空间的初始空间大小，以字节为单位，达到该值就会触发垃圾收集进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过-XX：MaxMetaspaceSize（如果设置了的话）的情况下，适当提高该值。
  - -XX：MinMetaspaceFreeRatio：作用是在垃圾收集之后控制最小的元空间剩余容量的百分比，可减少因为元空间不足导致的垃圾收集的频率。
  - -XX：MaxMetaspaceFreeRatio，用于控制最大的元空间剩余容量的百分比。

- 方法区的主要职责是用于存放类型的相关信息，如类名、访问修饰符、常量池、字段描述、方法描述等。

- 方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，要达成的条件是比较苛刻的。在经常运行时生成大量动态类的应用场景里，就应该特别关注这些类的回收状况。

##### 2.4.4 本地直接内存溢出

- 直接内存（Direct Memory）的容量大小可通过-XX：MaxDirectMemorySize参数来指定，如果不去指定，则默认与 Java 堆最大值（由 -Xmx 指定）一致
- 真正申请分配内存的方法是 Unsafe::allocateMemory()

## 垃圾回收

### 具体问题

- 什么是 gc，gc 怎么排查，怎么手动让 JAVA 虚拟机 OOM
- JVM回收机制，从判断对象死亡、GC Roots、Stop the World、回收算法优缺点讲起，提到引用计数弊端。
- 垃圾回收：年轻代老年代 回收算法 垃圾回收器等
- 问 JVM：GC 如何判断回收的垃圾对象？GC 算法有哪些？Minor Gc 和 Full GC 有什么不同呢？ZGC 垃圾回收器了解吗？
- 讲解一下 JVM 的垃圾回收；

### 思考方向

3 垃圾收集器与内存分配策略

- 3.2 对象已死？
  - 3.2.1 引用计数算法
  - 3.2.2 可达性分析算法
  - 3.2.3 再谈引用
    - 强、软、弱、虚
  - 3.2.4 生存还是死亡？
    - finalize()
  - 3.2.5 回收方法区
    - 方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型
- 3.3 垃圾收集算法
  - 3.3.1 分代收集理论
  - 3.3.2 标记-清除算法
  - 3.3.3 标记-复制算法
  - 3.3.4 标记-整理算法
- 3.4 HotSpot 的算法细节实现
  - 3.4.1 根节点枚举
  - 3.4.2 安全点
    - 有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。
  - 3.4.3 安全区域
    - 安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。
  - 3.4.4 记忆集和卡表
    - 垃圾收集器在新生代中建立了名为记忆集（Remembered Set）的数据结构，用以避免把整个老年代加进GC Roots 扫描范围
    - 可以用一种称为“卡表”（Card Table）的方式去实现记忆集
      - 记录精度为“卡精度”：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。
  - 3.4.5 写屏障
    - 写前屏障
    - 写后屏障
      - 直至 G1 收集器出现之前，其他收集器都只用到了写后屏障
  - 3.4.6 并发的可达性分析
    - 并发扫描过程：三色标记（Tri-color Marking）
    - 并发扫描时对象消失问题的两种解决方案：
      - 增量更新（Incremental Update）
      - 原始快照（Snapshot At The Beginning，SATB）
- **3.5 经典垃圾收集器**
  - 3.5.1 Serial 收集器
  - 3.5.2 ParNew 收集器
  - 3.5.3 Parallel Scavenge 收集器
  - 3.5.4 Serial Old 收集器
  - 3.5.5 Parallel Old 收集器
  - **3.5.6 CMS 收集器**
  - **3.5.7 Garbage First 收集器**
- 3.6 低延迟垃圾收集器
  - **3.6.1 Shenandoah 收集器**
  - **3.6.2 ZGC 收集器**
- 3.7 选择合适的垃圾收集器
  - 3.7.1 Epsilon 收集器
  - 3.7.2 收集器的权衡
  - 3.7.3 虚拟机及垃圾收集器日志
  - 3.7.4 垃圾收集器参数总结
- 3.8 实战：内存分配与回收策略
  - 3.8.1 对象优先在 Eden 分配
  - 3.8.2 大对象直接进入老年代
  - 3.8.3 长期存活的对象将进入老年代
  - 3.8.4 动态对象年龄判定
  - 3.8.5 空间分配担保

### 可达性分析

#### 具体问题

- JVM怎么判断一个对象是否是垃圾对象？
- 说说java里面的gc机制、垃圾回收算法、如何判断一个对象是无用对象？
- 可达性分析
- 再到jvm怎么回收垃圾，说到引用计数和根可达分析，jvm怎么确定根元素
- 判断gcroots的原则是什么
- 哪些可以作为GCROOT（这里太久没看了，没答全）
- root引用和引用计数
- 垃圾回收，怎么判断对象需要回收，垃圾回收机制
- 怎么判断需要垃圾回收？GC Root？
- GC Roots 是什么？主要用来做什么？
- 讲讲垃圾回收和死亡对象判断方法，具体讲讲可达性分析
- JVM,，哪些对象需要回收，垃圾收集算法
- GC 的过程，引用计数法还有在使用吗
- JVM 垃圾回收机制？如何判断需要回收？
- 如何判断一个类是无用的类
- 如何判断一个对象是否该被回收
- Java 引用类型，强软弱虚
- 强引用 弱引用 软引用 虚引用
- java 弱引用和虚引用的区别？
- 四种引用（强、软、弱、虚）
- 说说四种引用
- 场景题：如果是一个服务器用于存储数据，然后里面有一些数据是热点数组，需要缓存，用哪种引用
- JVM中给对象赋值为null，一定会被回收么？举个case，讲到了内存泄露。

#### 思考方向

##### 3.2 对象已死？

###### 3.2.1 引用计数算法

- 很难解决对象之间相互循环引用的问题

###### 3.2.2 可达性分析算法

- 这个算法的基本思路就是通过一系列称为“GC Roots”的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程所走过的路径称为“引用链”（Reference Chain），如果某个对象到 GC Roots 间没有任何引用链相连，或者用图论的话来说就是从 GC Roots 到这个对象不可达时，则证明此对象是不可能再被使用的
- GC Roots
  - 在虚拟机栈（栈帧中的本地变量表）中引用的对象，譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等。
  - 在方法区中类静态属性引用的对象，譬如 Java 类的引用类型静态变量。
  - 在方法区中常量引用的对象，譬如字符串常量池（String Table）里的引用。·在本地方法栈中 JNI（即通常所说的 Native 方法）引用的对象。
  - Java 虚拟机内部的引用，如基本数据类型对应的 Class 对象，一些常驻的异常对象（比如 NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。
  - 所有被同步锁（synchronized 关键字）持有的对象。
  - 反映 Java 虚拟机内部情况的 JMXBean、JVMTI 中注册的回调、本地代码缓存等。
  - 除了这些固定的 GC Roots 集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整 GC Roots 集合。
    - **分代收集和局部回收（Partial GC）**，如果只针对 Java 堆中某一块区域发起垃圾收集时（如最典型的只针对新生代的垃圾收集），必须考虑到内存区域是虚拟机自己的实现细节（在用户视角里任何内存区域都是不可见的），更不是孤立封闭的，所以某个区域里的对象完全有可能被位于堆中其他区域的对象所引用，**这时候就需要将这些关联区域的对象也一并加入 GC Roots 集合中去**，才能保证可达性分析的正确性。
    - **目前最新的几款垃圾收集器（如 OpenJDK 中的 G1、Shenandoah、ZGC 以及 Azul 的 PGC、C4 这些收集器）无一例外都具备了局部回收的特征**，为了避免GC Roots包含过多对象而过度膨胀，它们在实现上也做出了各种优化处理。关于这些概念、优化技巧以及各种不同收集器实现等内容，都将在本章后续内容中一一介绍。

###### 3.2.3 再谈引用

- 在 JDK 1.2 版之后，Java 对引用的概念进行了扩充，将引用分为**强引用（Strongly Reference）、软引用（Soft Reference）、弱引用（Weak Reference）和虚引用（Phantom Reference）**4 种，这 4 种引用强度依次逐渐减弱。
  - **强引用**是最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“Object
    obj=new Object()”这种引用关系
  - **软引用**是用来描述一些还有用，但非必须的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。在 JDK 1.2 版之后提供了 **SoftReference** 类来实现软引用
  - **弱引用**也是用来描述那些非必须对象，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生为止。当垃圾收集器开始工作，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在 JDK 1.2 版之后提供了 **WeakReference** 类来实现弱引用
  - **虚引用**也称为“幽灵引用”或者“幻影引用”，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知。在 JDK 1.2 版之后提供了 **PhantomReference** 类来实现虚引用

###### 3.2.4 生存还是死亡？

- 即使在可达性分析算法中判定为不可达的对象，也不是“非死不可”的，这时候它们暂时还处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程
  - 如果对象在进行可达性分析后发现没有与 GC Roots 相连接的引用链，那它将会被第一次标记
  - 随后进行一次筛选，筛选的条件是此对象是否有必要执行 **finalize()** 方法
    - 假如对象没有覆盖 finalize() 方法，或者 **finalize() 方法已经被虚拟机调用过**，那么虚拟机将这两种情况都视为“没有必要执行”。
    - 如果这个对象被判定为确有必要执行 finalize() 方法，那么该对象将会被放置在一个名为 **F-Queue** 的队列之中，并在稍后由一条由**虚拟机自动建立的、低调度优先级的 Finalizer 线程**去执行它们的 finalize() 方法
      - 这里所说的“执行”是指虚拟机会触发这个方法开始运行，但并不承诺一定会等待它运行结束。这样做的原因是，如果某个对象的 finalize() 方法执行缓慢，或者更极端地发生了死循环，将很可能导致 F-Queue 队列中的其他对象永久处于等待，甚至导致整个内存回收子系统的崩溃
    - finalize() 方法是对象逃脱死亡命运的最后一次机会，稍后收集器将对 F-Queue 中的对象进行第二次小规模的标记，**如果对象要在finalize()中成功拯救自己——只要重新与引用链上的任何一个对象建立关联即可**，譬如把自己（this关键字）赋值给某个类变量或者对象的成员变量，那在第二次标记时它将被移出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的要被回收了。
- 并不鼓励大家使用这个方法（ finalize() ）来拯救对象。相反，建议大家尽量避免使用它

###### 3.2.5 回收方法区

- 可以不要求虚拟机在方法区中实现垃圾收集
  - 事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如 JDK 11 时期的 ZGC 收集器就不支持类卸载）
- 方法区的垃圾收集主要回收两部分内容
  - 废弃的常量
    - 回收废弃常量与回收 Java 堆中的对象非常类似。举个常量池中字面量回收的例子，假如一个字符串“java”曾经进入常量池中，但是当前系统又没有任何一个字符串对象的值是“java”，换句话说，**已经没有任何字符串对象引用常量池中的“java”常量，且虚拟机中也没有其他地方引用这个字面量**。如果在这时发生内存回收，而且垃圾收集器判断确有必要的话，这个“java”常量就将会被系统清理出常量池。常量池中其他类（接口）、方法、字段的符号引用也与此类似。
  - 不再使用的类型
    - 条件比较苛刻。需要同时满足下面三个条件：
      - 该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。
      - 加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常是很难达成的。
      - 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。
    - Java 虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“**被允许**”，**而并不是和对象一样，没有引用了就必然会回收**。
      - 关于是否要对类型进行回收，HotSpot虚拟机提供了：
        - -Xnoclassgc参数进行控制
        - 还可以使用 -verbose:class 以及 -XX:+TraceClassLoading、-XX:+TraceClassUnLoading查看类加载和卸载信息
          - 其中 -verbose:class 和 -XX:+TraceClassLoading 可以在 Product 版的虚拟机中使用
          - -XX:+TraceClassUnLoading 参数需要 FastDebug 版的虚拟机支持。
    - 在大量使用反射、动态代理、CGLib 等**字节码框架**，动态生成 JSP 以及 OSGi 这类**频繁自定义类加载器**的场景中，**通常都需要 Java 虚拟机具备类型卸载的能力**，以保证不会对方法区造成过大的内存压力。

### GC 机制、算法

#### 具体问题

- 垃圾回收
- 垃圾回收算法
- 三种回收算法
- 了解JVM吗？为什么需要垃圾回收呢？
- 垃圾回收机制
- 项目中用的哪种垃圾回收机制？
- 项目中用的垃圾回收机制。设置JVM参数
- 回收算法
- 回收算法有哪些具体实现？垃圾回收器
- 讲讲Java GC机制？
- Java的垃圾回收机制
- Java垃圾回收，需要程序员自己回收吗？
- 垃圾回收机制
- GC，新生代为什么要采用复制算法
- GC 的过程，为什么要分代
- gc算法有哪些
- Java怎么进行垃圾回收的？什么对象会进老年代？
- 垃圾回收算法有哪些？为什么新生代使用复制算法？
- jvm的回收算法
- JVM的回收算法，当我背到一半后，打断了，说我知道你是为了面试背背而已，过几天忘了
- gc算法
- jvm的回收策略
- 高吞吐量的话用哪种gc算法
- Full GC
- full gc怎么触发
- FullGC什么时候会发生
- 发生 FULL GC 的条件
- Minor GC 与 Full GC 的触发机制是什么？
- major gc和full gc的区别，我脑抽，说反了，被鄙视了
- 执行了 system.gc(）触发的GC机制，FGC， 如何进行回收的， 分代回收
- 系统周期性卡顿，如何定位问题，结合GC日志， YGC,FGC， 调整分代的大小， 减小FGC时间
- 产生FGC的原因
- full gc问题，怎么排查
- 频繁GC的原因和解决方案
- 什么情况下老年代会发生GC？
- 安全点，安全点的作用？一些 JVM 源码（之前的文章写过，面试官和感兴趣）
- 垃圾回收算法；PS+PO，CMS 为什么要用标记清除算法？CMS 的前身，R 大的文章。
- 垃圾回收机制：场景：计算机性能好 但Idea（也是一个Java程序）但比较卡，原因：可能是因为频繁产生Full GC 怎么排查问题进行调整
- Full GC效果不好 每次只能从90%-》85%之后又90%了，这种情况下应该怎么办比较好   （如果是一次fullgc后，剩余对象不多。那么说明你eden区设置太小，导致短生命周期的对象进入了old区。如果一次fullgc后，old区回收率不大，那么说明old区太小。）
- 垃圾回收算法（标记-清除，标记-复制，标记-整理）
- 垃圾回收策略
- 介绍垃圾回收算法
  介绍复制回收算法
  哪种垃圾回收算法效率最低
  详细介绍标记算法，标记清除流程
- 介绍一下 JVM 的垃圾回收算法？
- Java 垃圾回收的方法新生代和老年代的不同的算法
- 垃圾回收机制讲一下
- 垃圾回收时标记存活对象的三色标记法原理，以及在出现漏标、错标情况时是如何解决的？
- 垃圾回收算法有哪些
- 分别介绍一下 GC 底层算法的优势和劣势以及它们的应用场景；
- 什么是复制算法，他的原理是什么？用在什么区？为什么用在这个区多？
- 标记整理法的缺点是什么？
- 标记复制和标记整理哪个能产生内存碎片（标记整理）

#### 思考方向

##### 3.3 垃圾收集算法

- 从如何判定对象消亡的角度出发，垃圾收集算法可以划分为“**引用计数式垃圾收集**”（Reference Counting GC）和“**追踪式垃圾收集**”（Tracing GC）两大类
  - 这两类也常被称作“**直接垃圾收集**”和“**间接垃圾收集**”。
  - 由于引用计数式垃圾收集算法在本书讨论到的主流 Java 虚拟机中均未涉及，所以我们暂不把它作为正文主要内容来讲解，本节介绍的所有算法均属于**追踪式垃圾收集**的范畴。

###### 3.3.1 分代收集理论

- 它建立在两个分代假说之上：
  - **弱分代假说（Weak Generational Hypothesis）**：绝大多数对象都是朝生夕灭的。
  - **强分代假说（Strong Generational Hypothesis）**：熬过越多次垃圾收集过程的对象就越难以消亡。
- 这两个分代假说共同奠定了多款常用的垃圾收集器的一致的设计原则：收集器应该将 Java 堆划分出不同的区域，然后将**回收对象依据其年龄（年龄即对象熬过垃圾收集过程的次数）分配到不同的区域之中存储**
- 按每次只回收其中某一个或者某些部分的区域划分回收类型
  - **部分收集（Partial GC）**：指目标不是完整收集整个 Java 堆的垃圾收集，其中又分为：
    - **新生代收集（Minor GC/Young GC）**：指目标只是新生代的垃圾收集。
    - **老年代收集（Major GC/Old GC）**：指目标只是老年代的垃圾收集。目前只有CMS收集器会有单独收集老年代的行为。另外请注意“Major GC”这个说法现在有点混淆，在不同资料上常有不同所指，读者需按上下文区分到底是指老年代的收集还是整堆收集。
    - **混合收集（Mixed GC）**：指目标是收集整个新生代以及部分老年代的垃圾收集。目前只有 G1 收集器会有这种行为。
  - **整堆收集（Full GC）**：收集整个 Java 堆和方法区的垃圾收集。
- 垃圾收集算法分类：
  - “标记-复制算法”
  - “标记-清除算法”
  - “标记-整理算法”
- 把分代收集理论具体放到现在的商用 Java 虚拟机里，设计者一般至少会把 Java 堆划分为**新生代（Young Generation）**和**老年代（Old Generation）**两个区域
  - HotSpot 的“分代式垃圾收集器框架”。原本 HotSpot 鼓励开发者尽量在这个框架内开发新的垃圾收集器，但除了最早期的两组四款收集器之外，后来的开发者并没有继续遵循。
    - 导致此事的原因有很多，最根本的是分代收集理论仍在不断发展之中，如何实现也有许多细节可以改进，被既定的代码框架约束反而不便
  - 分代收集并非只是简单划分一下内存区域那么容易，它至少存在一个明显的困难：对象不是孤立的，对象之间会存在跨代引用。
    - 添加第三条经验法则：
      - **跨代引用假说（Intergenerational Reference Hypothesis）**：跨代引用相对于同代引用来说仅占极少数
    - 依据这条假说，我们就不应再为了少量的跨代引用去扫描整个老年代，也不必浪费空间专门记录每一个对象是否存在及存在哪些跨代引用
    - 只需在新生代上建立一个全局的数据结构（该结构被称为**“记忆集”，Remembered Set**），这个结构把老年代划分成若干小块，**标识出老年代的哪一块内存会存在跨代引用**。
      - 此后当发生 Minor GC 时，只有包含了跨代引用的小块内存里的对象才会被加入到 GC Roots 进行扫描。

###### 3.3.2 标记-清除算法

- 最基础的垃圾收集算法
  - 后续的收集算法大多都是以标记-清除算法为基础，对其缺点进行改进而得到的。
- 在 1960 年由 Lisp 之父 John McCarthy 所提出
- 算法分为“标记”和“清除”两个阶段：
  - 首先标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象
  - 也可以反过来，标记存活的对象，统一回收所有未被标记的对象。
  - 标记过程就是对象是否属于垃圾的判定过程
- 它的主要缺点有两个
  - 第一个是**执行效率不稳定**，如果 Java 堆中包含大量对象，而且其中大部分是需要被回收的，这时必须进行大量标记和清除的动作，导致标记和清除两个过程的执行效率都随对象数量增长而降低
  - 第二个是**内存空间的碎片化问题**，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致当以后在程序运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作

###### 3.3.3 标记-复制算法

- 简称为复制算法
- 1969 年 Fenichel 提出了一种称为“半区复制”（Semispace Copying）的垃圾收集算法
- 它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉
  - 如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象
  - 而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。
- 缺点
  - 这种复制回收算法的代价是将**可用内存缩小为了原来的一半**，空间浪费未免太多了一点
- 现在的商用 Java 虚拟机大多都优先采用了这种收集算法去回收新生代
  - IBM 公司曾有一项专门研究对新生代“朝生夕灭”的特点做了更量化的诠释——新生代中的对象有 98% 熬不过第一轮收集。
  - 因此并不需要按照 1∶1 的比例来划分新生代的内存空间。
- 在 1989 年，Andrew Appel 针对具备“朝生夕灭”特点的对象，提出了一种更优化的半区复制分代策略，现在称为“Appel式回收”。
  - HotSpot 虚拟机的 Serial、ParNew 等新生代收集器均采用了这种策略来设计新生代的内存布局
  - Appel 式回收的具体做法是把新生代分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次分配内存只使用 Eden 和其中一块 Survivor。
  - 发生垃圾搜集时，将 Eden 和 Survivor 中仍然存活的对象一次性复制到另外一块 Survivor 空间上，然后直接清理掉 Eden 和已用过的那块 Survivor 空间。
  - HotSpot 虚拟机默认 **Eden 和 Survivor 的大小比例是 8∶1**，也即每次新生代中可用内存空间为整个新生代容量的 90%（Eden 的 80% 加上一个 Survivor 的 10%），只有一个 Survivor 空间，即 10% 的新生代是会被“浪费”的。
  - 当然，98% 的对象可被回收仅仅是“普通场景”下测得的数据，任何人都没有办法百分百保证每次回收都只有不多于 10% 的对象存活，因此Appel式回收还有一个充当罕见情况的“逃生门”的安全设计
    - 当 Survivor 空间不足以容纳一次 Minor GC 之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行**分配担保（Handle Promotion）**。

###### 3.3.4 标记-整理算法

- 针对老年代对象的存亡特征，1974 年 Edward Lueders 提出了另外一种有针对性的“标记-整理”（Mark-Compact）算法
  - 其中的标记过程仍然与“标记-清除”算法一样
  - 但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存空间一端移动，然后直接清理掉边界以外的内存
- 标记-清除算法与标记-整理算法的本质差异在于前者是一种非移动式的回收算法，而后者是移动式的。
  - 如果移动存活对象，尤其是在老年代这种每次回收都有大量对象存活区域，移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且**这种对象移动操作必须全程暂停用户应用程序才能进行**
    - 这就更加让使用者不得不小心翼翼地权衡其弊端了，像这样的停顿被最初的虚拟机设计者形象地描述为“**Stop The World**”
  - 但如果跟标记-清除算法那样完全不考虑移动和整理存活对象的话，弥散于堆中的存活对象导致的空间碎片化问题就只能依赖更为复杂的**内存分配器和内存访问器**来解决。
    - 譬如通过“分区空闲分配链表”来解决内存分配问题（计算机硬盘存储大文件就不要求物理连续的磁盘空间，能够在碎片化的硬盘上存储和访问就是通过硬盘分区表实现的）。
    - 内存的访问是用户程序最频繁的操作，甚至都没有之一，假如在这个环节上增加了额外的负担，势必会直接影响应用程序的吞吐量。
  - HotSpot 虚拟机里面关注吞吐量的 Parallel Scavenge 收集器是基于标记-整理算法的，而关注延迟的 CMS 收集器则是基于标记-清除算法的，这也从侧面印证这点。
    - 另外，还有一种“和稀泥式”解决方案可以不在内存分配和访问上增加太大额外负担，做法是让虚拟机平时多数时间都采用标记-清除算法，暂时容忍内存碎片的存在，直到内存空间的碎片化程度已经大到影响对象分配时，再采用标记-整理算法收集一次，以获得规整的内存空间。前面提到的基于标记-清除算法的 CMS 收集器面临空间碎片过多时采用的就是这种处理办法。

##### 3.4 HotSpot 的算法细节实现

###### 3.4.1 根节点枚举

- 固定可作为 GC Roots 的节点主要在全局性的引用（例如常量或类静态属性）与执行上下文（例如栈帧中的本地变量表）中
- **迄今为止，所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的**，因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的“Stop The World”的困扰。
- 目前主流 Java 虚拟机使用的都是**准确式垃圾收集**，所以当用户线程停顿下来之后，其实并不需要一个不漏地检查完所有执行上下文和全局的引用位置，**虚拟机应当是有办法直接得到哪些地方存放着对象引用的**
  - **准确式内存管理（Exact Memory Management，也可以叫 NonConservative/Accurate Memory Management）**是指虚拟机可以知道内存中某个位置的数据具体是什么类型。准确分辨出哪些内存是引用类型，这也是在垃圾收集时准确判断堆上的数据是否还可能被使用的前提。
- 在 HotSpot 的解决方案里，是使用一组称为 **OopMap** 的数据结构来达到这个目的。一旦类加载动作完成的时候，HotSpot 就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用。

###### 3.4.2 安全点

- 可能导致引用关系变化，或者说导致 OopMap 内容变化的指令非常多，如果为每一条指令都生成对应的 OopMap，那将会需要大量的额外存储空间，这样垃圾收集伴随而来的空间成本就会变得无法忍受的高昂
- 实际上 HotSpot 也的确没有为每条指令都生成 OopMap，前面已经提到，只是在“特定的位置”记录了这些信息，这些位置被称为**安全点（Safepoint）**。
  - 有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是强制要求必须执行到达安全点后才能够暂停。
- **安全点位置的选取**基本上是以“是否具有让程序长时间执行的特征”为标准进行选定的
  - 因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这样的原因而长时间执行
  - “长时间执行”的最明显特征就是指令序列的复用，例如方法调用、循环跳转、异常跳转等都属于指令序列复用，所以只有具有这些功能的指令才会产生安全点。
- 如何在垃圾收集发生时让所有线程（这里其实不包括执行 JNI 调用的线程）都跑到最近的安全点，然后停顿下来。这里有两种方案可供选择：
  - 抢先式中断（Preemptive Suspension）
    - 不需要线程的执行代码主动去配合，在垃圾收集发生时，系统首先把所有用户线程全部中断，如果发现有用户线程中断的地方不在安全点上，就恢复这条线程执行，让它一会再重新中断，直到跑到安全点上
    - 现在几乎没有虚拟机实现采用抢先式中断来暂停线程响应GC事件
  - 主动式中断（Voluntary Suspension）
    - 思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。
    - 轮询标志的地方和安全点是重合的，另外还要加上所有创建对象和其他需要在 Java 堆上分配内存的地方，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象。
    - HotSpot 使用内存保护陷阱的方式，把轮询操作精简至只有一条汇编指令的程度。

###### 3.4.3 安全区域

- 所谓的程序不执行就是没有分配处理器时间，典型的场景便是用户线程处于Sleep状态或者Blocked状态，这时候线程无法响应虚拟机的中断请求，不能再走到安全的地方去中断挂起自己，虚拟机也显然不可能持续等待线程重新被激活分配处理器时间。对于这种情况，就必须引入**安全区域（Safe Region）**来解决。
- 安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。

###### 3.4.4 记忆集和卡表

- 垃圾收集器在新生代中建立了名为**记忆集（Remembered Set）**的数据结构，用以避免把整个老年代加进GC Roots 扫描范围
  - 事实上并不只是新生代、老年代之间才有跨代引用的问题，所有涉及**部分区域收集（Partial GC）**行为的垃圾收集器，典型的如G1、ZGC和Shenandoah收集器，都会面临相同的问题
  - 记忆集是一种用于记录从非收集区域指向收集区域的指针集合的**抽象**数据结构
  - 在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了，并不需要了解这些跨代指针的全部细节。
    - 那设计者在实现记忆集的时候，便可以选择更为粗犷的记录粒度来节省记忆集的存储和维护成本，下面列举了一些可供选择（当然也可以选择这个范围以外的）的记录精度：
      - **字长精度**：每个记录精确到一个机器字长（就是处理器的寻址位数，如常见的32位或64位，这个精度决定了机器访问物理内存地址的指针长度），该字包含跨代指针。
      - **对象精度**：每个记录精确到一个对象，该对象里有字段含有跨代指针。
      - **卡精度**：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。
- 其中，第三种“卡精度”所指的是用一种称为**“卡表”（Card Table）**的方式去实现记忆集
  - 这也是目前最常用的一种记忆集实现形式
  - 记忆集其实是一种“抽象”的数据结构，抽象的意思是只定义了记忆集的行为意图，并没有定义其行为的具体实现。**卡表就是记忆集的一种具体实现**，它定义了记忆集的记录精度、与堆内存的映射关系等。
  - 卡表最简单的形式可以只是一个**字节数组**，而 HotSpot 虚拟机确实也是这样做的。
    - 字节数组 CARD_TABLE 的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作**“卡页”（Card Page）**。
    - 一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为 1，称为这个元素**变脏（Dirty）**，没有则标识为 0。
    - 在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入GC Roots中一并扫描。

###### 3.4.5 写屏障

- 有其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻。但问题是如何变脏，即**如何在对象赋值的那一刻去更新维护卡表呢**？
  - 假如是**解释执行**的字节码，那相对好处理，虚拟机负责每条字节码指令的执行，有充分的介入空间
  - 但在**编译执行**的场景中呢？经过即时编译后的代码已经是纯粹的机器指令流了，这就必须找到一个在机器码层面的手段，把维护卡表的动作放到每一个赋值操作之中
    - 在 HotSpot 虚拟机里是通过**写屏障（Write Barrier）**技术维护卡表状态的。
      - 注意将这里提到的“写屏障”，以及后面在低延迟收集器中会提到的“读屏障”与解决并发乱序执行问题中的“内存屏障”区分开来，避免混淆。
      - 在赋值前的部分的写屏障叫作**写前屏障（Pre-Write Barrier）**
      - 在赋值后的则叫作**写后屏障（Post-Write Barrier）**。
        - 直至 G1 收集器出现之前，其他收集器都只用到了写后屏障
    - 应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令
      - 一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生**额外的开销**，不过这个开销与Minor GC时扫描整个老年代的代价相比还是低得多的。
    - 卡表在高并发场景下还面临着**“伪共享”（False Sharing）**问题
      - 伪共享是处理并发底层细节时一种经常需要考虑的问题
      - 现代中央处理器的缓存系统中是以**缓存行（Cache Line）**为单位存储的，当多线程修改互相独立的变量时，如果这些变量恰好**共享同一个缓存行**，就会彼此影响（写回、无效化或者同步）而导致性能降低，这就是伪共享问题。
      - 一种简单的**解决方案**是不采用无条件的写屏障，而是**先检查卡表标记**，只有当该卡表元素未被标记过时才将其标记为变脏
        - 在 JDK 7 之后，HotSpot 虚拟机增加了一个新的参数 -XX:+UseCondCardMark，用来决定是否开启卡表更新的条件判断。开启会增加一次额外判断的开销，但能够避免伪共享问题

###### 3.4.6 并发的可达性分析

- 可达性分析算法理论上要求全过程都基于一个**能保障一致性的快照中**才能够进行分析，这意味着必须全程冻结用户线程的运行。
  - 在**根节点枚举**这个步骤中，由于 GC Roots 相比起整个 Java 堆中全部的对象毕竟还算是极少数，且在各种优化技巧（如 OopMap）的加持下，它带来的停顿已经是非常短暂且相对固定（不随堆容量而增长）的了。
  - 可**从GC Roots再继续往下遍历对象图**，这一步骤的停顿时间就必定会与 Java 堆容量直接成正比例关系了：堆越大，存储的对象越多，对象图结构越复杂，要标记更多对象而产生的停顿时间自然就更长
    - 如果能够削减这部分停顿时间的话，那收益也将会是系统性的。
- **三色标记（Tri-color Marking）**作为工具来辅助推导，把遍历对象图过程中遇到的对象，按照“**是否访问过**”这个条件标记成以下三种颜色
  - **白色**：表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。
  - **黑色**：表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接（不经过灰色对象）指向某个白色对象。
  - **灰色**：表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。
- 如果**用户线程与收集器是并发工作**呢？收集器在对象图上标记颜色，同时用户线程在修改引用关系——即修改对象图的结构，这样可能出现两种后果
  - 一种是把原本消亡的对象错误标记为存活，这不是好事，但其实是可以容忍的，只不过产生了一点逃过本次收集的浮动垃圾而已，下次收集清理掉就好
  - 另一种是把原本存活的对象错误标记为已消亡，这就是非常致命的后果了，程序肯定会因此发生错误
    - Wilson 于 1994 年在理论上证明了，当且仅当以下两个条件同时满足时，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色：
      - **赋值器插入了一条或多条从黑色对象到白色对象的新引用；**
      - **赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。**
    - 我们要解决并发扫描时的对象消失问题，只需破坏这两个条件的任意一个即可。由此分别产生了两种解决方案：
      - **增量更新（Incremental Update）**
        - 增量更新要破坏的是第一个条件
        - 当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。
        - 这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。
      - **原始快照（Snapshot At The Beginning，SATB）**
        - 原始快照要破坏的是第二个条件
        - 当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。
        - 这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索。

### 内存分配策略

#### 具体问题

- 堆如何分代
- 为什么要分代
- 新生区，老年区分布在那里，说一下他们的区别，和所使用的算法；
- 什么是新生区？什么是老年区？什么是永久代？
- 假设HashMap里面存放100万个对象，那么gc可能会有什么问题？
- byte[] a = new byte[10 * 1024]内存分配过程？多大的对象直接进入老年代？通过什么参数配置？
- 对象什么情况会进去老年代
- 那你知道一个对象怎么从新生代变成老年代吗？（懵逼，对不起，不知道，只简单的知道两个区的定义）
- 介绍 TLAB，PLAB，CAS 分配。
- Eden 和 Survivor 比例可以调整么，参数是什么？还用到了哪些参数？
- JVM 新生代怎么划分，大对象怎么分配
- 怎么释放一个用完的大对象的内存空间？

#### 思考方向

##### 3.8 实战：内存分配与回收策略

###### 3.8.1 对象优先在 Eden 分配

- 大多数情况下，对象在新生代 Eden 区中分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。

###### 3.8.2 大对象直接进入老年代

- 大对象就是指需要大量连续内存空间的Java对象，最典型的大对象便是那种很长的字符串，或者元素数量很庞大的数组
  - 本节例子中的byte[]数组就是典型的大对象
- 大对象对虚拟机的内存分配来说就是一个不折不扣的坏消息，比遇到一个大对象更加坏的消息就是遇到一群“朝生夕灭”的“短命大对象”，我们写程序的时候应注意避免。
- 在Java虚拟机中要避免大对象的原因
  - 在分配空间时，它容易导致内存明明还有不少空间时就提前触发垃圾收集，以获取足够的连续空间才能安置好它们
  - 当复制对象时，大对象就意味着高额的内存复制开销。
- HotSpot 虚拟机提供了 -XX:PretenureSizeThreshold 参数，指定大于该设置值的对象直接在老年代分配，这样做的目的就是避免在 Eden 区及两个 Survivor 区之间来回复制，产生大量的内存复制操作。
  - -XX:PretenureSizeThreshold 参数只对 Serial 和 ParNew 两款新生代收集器有效，HotSpot 的其他新生代收集器，如 Parallel Scavenge 并不支持这个参数。

###### 3.8.3 长期存活的对象将进入老年代

- 虚拟机给每个对象定义了一个对象年龄（Age）计数器，存储在对象头中
- 对象通常在 Eden 区里诞生，如果经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，该对象会被移动到 Survivor 空间中，并且将其对象年龄设为 1 岁。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（**默认为 15**），就会被晋升到老年代中。
- 对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 设置。

###### 3.8.4 动态对象年龄判定

- 为了能更好地适应不同程序的内存状况，HotSpot 虚拟机并不是永远要求对象的年龄必须达到 -XX:MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中**相同年龄所有对象大小的总和大于 Survivor 空间的一半**，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 -XX:MaxTenuringThreshold 中要求的年龄。

###### 3.8.5 空间分配担保

- 在发生 Minor GC 之前，虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果这个条件成立，那这一次 Minor GC 可以确保是安全的。如果不成立，则虚拟机会先查看 -XX:HandlePromotionFailure 参数的设置值是否允许**担保失败（Handle Promotion Failure）**
  - 如果允许，那会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小
    - 如果大于，将尝试进行一次 Minor GC，尽管这次 Minor GC 是有风险的；
  - 如果小于，或者 -XX:HandlePromotionFailure 设置不允许冒险，那这时就要改为进行一次 Full GC。
- 取历史平均值来比较其实仍然是一种赌概率的解决办法，也就是说假如某次 Minor GC 存活后的对象突增，远远高于历史平均值的话，依然会导致担保失败。
  - 如果出现了担保失败，那就只好老老实实地重新发起一次 Full GC，这样停顿时间就很长了。
  - 虽然担保失败时绕的圈子是最大的，但通常情况下都还是会将 -XX:HandlePromotionFailure 开关打开，避免 Full GC 过于频繁。

##### 栈上分配、TLAB、PLAB

- 栈上分配
  - 对于这些其他线程不会访问的对象，我们能不能让线程自己分配在它自己的栈空间上？这样不就可以节省不少交互时间了
  - 参考后续**逃逸分析**相关
- TLAB
  - TLAB（Thread Local Allocation Buffer），即线程本地分配缓存。这是一块线程专用的内存分配区域，TLAB 占用的是 eden 区的空间。在 TLAB 启用的情况下（默认开启），JVM 会为每一个线程分配一块 TLAB 区域。
- PLAB
  - PLAB（Promotion Local Allocation Buffers），即晋升本地分配缓存。**PLAB 的作用于 TLAB 类似，都是为了加速对象分配效率，避免多线程竞争而诞生的。** 只不过 PLAB 是应用于对象晋升到 Survivor 区或老年代。与 TLAB 类似，每个线程都有独立的 PLAB 区。
- 对象内存分配流程
  - 尝试栈上分配 -> 尝试 TLAB 分配 -> 是否可以直接进入老年代 -> Eden 分配

### 垃圾回收器

#### 具体问题

- 常见的垃圾回收器
- 聊聊垃圾回收，实习的时候团队用的是哪个垃圾收集器？项目用什么垃圾回收器`【2次】`
- 常用的垃圾回收器有哪些？
- 常见的垃圾回收器
- 常见的垃圾回收期
- CMS 垃圾收集器的特性，工作的四个流程，哪几个流程 stop the world
- 讲一讲CMS的回收过程
- 详细介绍下CMS？
- G1和CMS垃圾回收器
- ZGC，聊到了彭寒成的《新一代垃圾回收器 ZGC 设计与实现》和美团技术团队的文章。
- G1
- G1，聊到了中村成洋的《深入 Java 虚拟机：JVM G1GC 的算法与实现》。
- G1，最大的特点，标记位图，卡表卡页，SATB。
- G1的适用场景和实现原理
- 详细说一下Remembered Set的作用，什么时候会往里面写、更新等
- 还有一个Collection Set，你知道C Set的作用是什么吗？
- 常用 GC 算法，常用的垃圾收集器， G1 了解吗
- 垃圾回收器都有哪些
- G1 回收器与之前的回收器相比最大的不同是什么
- 新生代有哪些垃圾回收器
- ParNew 原理
- CMS 收集器收集过程
- 介绍 G1 垃圾收集器、回收过程，与 CMS 对比；
- JVM 垃圾回收器有哪些？
- 讲解一下 Serial 和 CMS，G1 回收器；
- 垃圾回收器、 算法、G1

#### 思考方向

##### 3.5 经典垃圾收集器

- 本节标题中“经典”二字并非情怀，它其实是讨论范围的限定语，这里讨论的是在 JDK 7 Update 4 之后（在这个版本中正式提供了商用的 G1 收集器，此前 G1 仍处于实验状态）、JDK 11 正式发布之前，OracleJDK 中的 HotSpot 虚拟机所包含的全部可用的垃圾收集器。

- 搭配

  - 新生代 Serial + 老年代 CMS（JDK 9 起删除该组合）
  - 新生代 Serial + 老年代 Serial Old(MSC)
  - 新生代 ParNew + 老年代 CMS
  - 新生代 ParNew + 老年代 SerialOld(MSC)（JDK 9 起删除该组合）
  - 新生代 ParallelScavenge + 老年代 SerialOld(MSC)（JDK 14 起弃用（Deprecate）该组合）
  - 新生代 ParallelScavenge + 老年代 Parallel Old
  - G1

###### 3.5.1 Serial 收集器

- Serial 收集器是最基础、历史最悠久的收集器
  - 曾经（在 JDK 1.3.1 之前）是 HotSpot 虚拟机新生代收集器的唯一选择。
  - 单线程工作的收集器
    - 它的“单线程”的意义并不仅仅是说明它只会使用一个处理器或一条收集线程去完成垃圾收集工作，更重要的是强调在它进行垃圾收集时，**必须暂停其他所有工作线程，直到它收集结束**。
    - “Stop The World” 这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可知、不可控的情况下把用户的正常工作的线程全部停掉，这对很多应用来说都是不能接受的
  - Serial/Serial Old 收集器运行逻辑
    - 用户线程都进入安全点后，暂停所有用户线程，**新生代 Serial 采取复制算法**，**单个 GC 线程**进行垃圾回收
    - 然后用户线程再进入安全点后，暂停所有用户线程，**老年代 Serial Old 采取标记-整理算法**，**单个 GC 线程**进行垃圾回收
  - 迄今为止，它依然是HotSpot虚拟机运行在**客户端模式下的默认新生代收集器**，有着优于其他收集器的地方，那就是简单而高效（与其他收集器的单线程相比）
    - 对于内存资源受限的环境，它是所有收集器里额外内存消耗（Memory Footprint）最小的
    - 对于单核处理器或处理器核心数较少的环境来说，Serial 收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。

###### 3.5.2 ParNew 收集器

- 实质上是 Serial 收集器的多线程并行版本
  - 除了同时使用多条线程进行垃圾收集之外，其余的行为都与Serial收集器完全一致，包括：
    - Serial 收集器可用的所有控制参数（例如：-XX:SurvivorRatio、-XX:PretenureSizeThreshold、-XX:HandlePromotionFailure 等）
    - 收集算法
    - Stop The World
    - 对象分配规则
    - 回收策略等
  - 在实现上这两种收集器也共用了相当多的代码。
- ParNew / Serial Old 收集器运行逻辑
  - 用户线程都进入安全点后，暂停所有用户线程，**新生代 ParNew 采取复制算法**，**多个 GC 线程**进行垃圾回收
  - 然后用户线程再进入安全点后，暂停所有用户线程，**老年代 Serial Old 采取标记-整理算法**，**单个 GC 线程**进行垃圾回收
- ParNew 收集器除了支持多线程并行收集之外，其他与 Serial 收集器相比并没有太多创新之处，但它却是不少运行在服务端模式下的 HotSpot 虚拟机，尤其是 JDK 7 之前的遗留系统中首选的新生代收集器，其中有一个与功能、性能无关但其实很重要的原因是：**除了 Serial 收集器外，目前只有它能与CMS 收集器配合工作**。
  - 在 JDK 5 中使用 CMS 来收集老年代的时候，新生代只能选择 ParNew 或者 Serial 收集器中的一个。
    - CMS 却无法与 JDK 1.4.0 中已经存在的新生代收集器 Parallel Scavenge 配合工作
      - 除了一个面向低延迟一个面向高吞吐量的目标不一致外，技术上的原因是 Parallel Scavenge 收集器及后面提到的 G1 收集器等都**没有使用** HotSpot 中原本设计的垃圾收集器的**分代框架**，而选择另外独立实现。
      - Serial、ParNew 收集器则共用了这部分的框架代码
  - ParNew 收集器是激活 CMS 后（使用 -XX:+UseConcMarkSweepGC 选项）的默认新生代收集器，也可以使用 -XX:+/-UseParNewGC 选项来强制指定或者禁用它。
  - 更先进的 G1 收集器带着 CMS 继承者和替代者的光环登场。G1 是一个面向全堆的收集器，不再需要其他新生代收集器的配合工作。
    - 所以自JDK 9开始，ParNew 加 CMS 收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案了。官方希望它能完全被 G1 所取代（CMS 直接在 9 被弃用（Deprecate）了）
    - 9 甚至还取消了 ParNew 加 Serial Old 以及 Serial 加 CMS 这两组收集器组合的支持（其实原本也很少人这样使用），并直接取消了 -XX:+UseParNewGC 参数，这意味着 ParNew 和 CMS 从此只能互相搭配使用，再也没有其他收集器能够和它们配合了。
    - 读者也可以理解为从此以后，ParNew 合并入 CMS，成为它专门处理新生代的组成部分。ParNew 可以说是 HotSpot 虚拟机中第一款退出历史舞台的垃圾收集器。
- 它默认开启的收集线程数与处理器核心数量相同
  - 可以使用 -XX:ParallelGCThreads 参数来限制垃圾收集的线程数
- 从 ParNew 收集器开始，后面还将会接触到若干款涉及“并发”和“并行”概念的收集器。
  - 并行和并发都是并发编程中的专业名词，在谈论垃圾收集器的上下文语境中，它们可以理解为：
  - 并行（Parallel）：并行描述的是多条垃圾收集器线程之间的关系，说明同一时间有多条这样的线程在协同工作，通常默认此时用户线程是处于等待状态。
  - 并发（Concurrent）：并发描述的是垃圾收集器线程与用户线程之间的关系，说明同一时间垃圾收集器线程与用户线程都在运行。由于用户线程并未被冻结，所以程序仍然能响应服务请求，但由于垃圾收集器线程占用了一部分系统资源，此时应用程序的处理的吞吐量将受到一定影响。

###### 3.5.3 Parallel Scavenge 收集器

- 也是一款新生代收集器
- 基于**标记-复制算法**实现的收集器
- 能够**并行收集的多线程收集器**
- 特点是它的关注点与其他收集器不同，目标是达到一个可控制的吞吐量（Throughput）
  - 所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值
  - 如果虚拟机完成某个任务，用户代码加上垃圾收集总共耗费了 100 分钟，其中垃圾收集花掉 1 分钟，那吞吐量就是99%。
  - 停顿时间越短就越适合需要与用户交互或需要保证服务响应质量的程序，良好的响应速度能提升用户体验；而高吞吐量则可以最高效率地利用处理器资源，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的分析任务。
- 由于与吞吐量关系密切，Parallel Scavenge 收集器也经常被称作“吞吐量优先收集器”。
- 提供了两个参数用于精确控制吞吐量
  - 控制最大垃圾收集停顿时间的 **-XX:MaxGCPauseMillis 参数**
    - -XX:MaxGCPauseMillis 参数允许的值是一个大于 0 的毫秒数，收集器将尽力保证内存回收花费的时间不超过用户设定值。
    - 不过大家不要异想天开地认为如果把这个参数的值设置得更小一点就能使得系统的垃圾收集速度变得更快，垃圾收集停顿时间缩短是以牺牲吞吐量和新生代空间为代价换取的
      - 系统把新生代调得小一些，收集 300MB 新生代肯定比收集 500MB 快，但这也直接导致垃圾收集发生得更频繁，原来 10 秒收集一次、每次停顿 100 毫秒，现在变成 5 秒收集一次、每次停顿 70 毫秒。停顿时间的确在下降，但吞吐量也降下来了。
  - 直接设置吞吐量大小的 **-XX:GCTimeRatio 参数**
    - -XX:GCTimeRatio 参数的值则应当是一个大于 0 小于 100 的整数，也就是垃圾收集时间占总时间的比率，相当于吞吐量的倒数。譬如把此参数设置为 19，那允许的最大垃圾收集时间就占总时间的 5%（即 1/(1+19)），**默认值为 99**，即允许最大 1%（即 1/(1+99)）的垃圾收集时间。
- 除上述两个参数之外，Parallel Scavenge 收集器还有一个**参数 -XX:+UseAdaptiveSizePolicy** 值得我们关注
  - 这是一个开关参数，当这个参数被激活之后，就不需要人工指定新生代的大小（-Xmn）、Eden 与 Survivor 区的比例（-XX:SurvivorRatio）、晋升老年代对象大小（-XX:PretenureSizeThreshold）等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。这种调节方式称为垃圾收集的自适应的调节策略（GC Ergonomics）。
  - 如果读者对于收集器运作不太了解，手工优化存在困难的话，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成也许是一个很不错的选择。
  - **自适应调节策略也是 Parallel Scavenge 收集器区别于 ParNew 收集器的一个重要特性**。

###### 3.5.4 Serial Old 收集器

- 是 Serial 收集器的老年代版本
- 它同样是一个单线程收集器
- 使用**标记-整理**算法
- 主要意义
  - 供客户端模式下的 HotSpot 虚拟机使用。
  - 在服务端模式下，它也可能有两种用途：
    - 一种是在 JDK 5 以及之前的版本中与 Parallel Scavenge 收集器搭配使用
    - 另外一种就是作为 CMS 收集器发生失败时的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。
    - 这两点都将在后面的内容中继续讲解。

###### 3.5.5 Parallel Old 收集器

- 是 Parallel Scavenge 收集器的老年代版本
- 支持**多线程并发收集**
- 基于**标记-整理**算法实现。
- 这个收集器是直到 JDK 6 时才开始提供的。在此之前，新生代的 Parallel Scavenge 收集器一直处于相当尴尬的状态
  - 原因是如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old（PS MarkSweep）收集器以外别无选择，其他表现良好的老年代收集器，如CMS无法与它配合工作。
  - 由于老年代 Serial Old 收集器在服务端应用性能上的“拖累”，使用 Parallel Scavenge 收集器也未必能在整体上获得吞吐量最大化的效果。
  - Parallel Scavenge + Serial Old 在 JDK 14 中被弃用
- 直到 Parallel Old 收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的搭配组合，在注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器这个组合。
- Parallel Scavenge / Parallel Old 收集器运行逻辑
  - 用户线程都进入安全点后，多个 GC 线程进行新生代垃圾回收
  - 然后用户线程再进入安全点后，多个 GC 线程进行老年代垃圾回收

###### 3.5.6 CMS 收集器

- 在 JDK 5 发布时，HotSpot 推出了一款在强交互应用中几乎可称为具有划时代意义的垃圾收集器——CMS 收集器。这款收集器是 HotSpot 虚拟机中第一款真正意义上支持并发的垃圾收集器，它首次实现了让垃圾收集线程与用户线程（基本上）同时工作。
- 在 JDK 9 被弃用，在 JDK 14 被删除
- CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。
- 基于**标记-清除算法**实现的
- 运作过程
  - 分为四个步骤，包括：
    - **初始标记（CMS initial mark）**
      - 初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快
    - **并发标记（CMS concurrent mark）**
      - 并发标记阶段就是从 GC Roots 的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行
    - **重新标记（CMS remark）**
      - 而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录
        - 参考**增量更新**
      - 这个阶段的停顿时间通常会比初始标记阶段稍长一些，但也远比并发标记阶段的时间短
    - **并发清除（CMS concurrent sweep）**
      - 最后是并发清除阶段，清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。
  - 其中初始标记、重新标记这两个步骤仍然需要“Stop The World”。
  - 由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一起工作，所以从总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发执行的。
- Concurrent Mark Sweep 收集器运行逻辑
  - 多个用户线程 -> Safepoint -> 初始标记 -> Safepoint -> 并发标记（多个用户线程可同时执行）-> Safepoint -> 重新标记 -> Safepoint -> 并发清理（多个用户线程可以同时执行）-> Safepoint -> 重置线程（多个用户线程可同时执行）
- 最主要的优点：
  - 并发收集
  - 低停顿
    - 一些官方公开文档里面也称之为“并发低停顿收集器”（Concurrent Low Pause Collector）
- 至少有以下三个明显的缺点
  - 首先，CMS 收集器对处理器资源非常敏感
    - 事实上，面向并发设计的程序都对处理器资源比较敏感。
    - 在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程（或者说处理器的计算能力）而导致应用程序变慢，降低总吞吐量。
    - CMS 默认启动的回收线程数是**（处理器核心数量 +3）/4**
      - 也就是说，如果处理器核心数在四个或以上，并发回收时垃圾收集线程只占用不超过 25% 的处理器运算资源，并且会随着处理器核心数量的增加而下降。
      - 但是当处理器核心数量不足四个时，CMS 对用户程序的影响就可能变得很大。
    - 为了缓解这种情况，虚拟机提供了一种称为**“增量式并发收集器”（Incremental Concurrent Mark Sweep/i-CMS）**的 CMS 收集器变种
      - 所做的事情和以前单核处理器年代 PC 机操作系统靠抢占式多任务来模拟多核并行多任务的思想一样，是在并发标记、清理的时候让收集器线程、用户线程交替运行，尽量减少垃圾收集线程的独占资源的时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得较少一些，直观感受是速度变慢的时间更多了，但速度下降幅度就没有那么明显。
      - 实践证明增量式的 CMS 收集器效果很一般，从 JDK 7 开始，i-CMS 模式已经被声明为“deprecated”，即已过时不再提倡用户使用，到 JDK 9 发布后 iCMS 模式被完全废弃。
  - 然后，由于 CMS 收集器无法处理“浮动垃圾”（Floating Garbage），有可能出现“Concurrent Mode Failure”失败进而导致另一次完全“Stop The World”的 Full GC 的产生。
    - 在 CMS 的并发标记和并发清理阶段，用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS 无法在当次收集中处理掉它们，只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。
    - 同样也是由于在垃圾收集阶段用户线程还需要持续运行，那就还需要**预留足够内存空间提供给用户线程使用**，因此 CMS 收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集，必须预留一部分空间供并发收集时的程序运作使用。
      - 在 JDK 5 的默认设置下，CMS 收集器当老年代使用了 68% 的空间后就会被激活，这是一个偏保守的设置
      - 到了 JDK 6 时，**CMS 收集器的启动阈值就已经默认提升至 92%**。
        - 但这又会更容易面临另一种风险：要是 CMS 运行期间预留的内存无法满足程序分配新对象的需要，就会出现一次“并发失败”（Concurrent Mode Failure）
        - 这时候虚拟机将不得不启动后备预案：冻结用户线程的执行，临时启用 Serial Old 收集器来重新进行老年代的垃圾收集，但这样停顿时间就很长了。
        - 适当调整参数 -XX:CMSInitiatingOccupancyFraction 的值来修改 CMS 的触发百分比，用户应在生产环境中根据实际应用情况来权衡设置。
  - 最后一个缺点，CMS 是一款基于“标记-清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生
    - 空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次 Full GC 的情况。
    - 为了解决这个问题
      - CMS 收集器提供了一个 **-XX:+UseCMSCompactAtFullCollection** 开关参数（默认是开启的，此参数从 JDK 9 开始废弃），用于在 CMS 收集器不得不进行 Full GC 时开启内存碎片的合并整理过程，由于这个内存整理必须移动存活对象，（在 Shenandoah 和 ZGC 出现前）是无法并发的。这样空间碎片问题是解决了，但停顿时间又会变长
      - 因此虚拟机设计者们还提供了另外一个参数 **-XX:CMSFullGCsBeforeCompaction**（此参数从 JDK 9 开始废弃），这个参数的作用是要求 CMS 收集器在执行过若干次（数量由参数值决定）不整理空间的 Full GC 之后，下一次进入 Full GC 前会先进行碎片整理（默认值为 0，表示每次进入 Full GC 时都进行碎片整理）。

###### 3.5.7 Garbage First 收集器

- Garbage First（简称 G1）收集器是垃圾收集器技术发展历史上的里程碑式的成果，它开创了收集器面向局部收集的设计思路和基于 Region 的内存布局形式。

  - 至 JDK 7 Update 4，Oracle 才认为它达到足够成熟的商用程度，移除了“Experimental”的标识；
  - 到了 JDK 8 Update 40 的时候，G1 提供并发的类卸载的支持，补全了其计划功能的最后一块拼图。这个版本以后的 G1 收集器才被 Oracle 官方称为“全功能的垃圾收集器”（Fully-Featured Garbage Collector）。

- JDK 9 发布之日，G1 宣告取代 Parallel Scavenge 加 Parallel Old 组合，成为**服务端模式下的默认垃圾收集器**，而 CMS 则沦落至被声明为不推荐使用（Deprecate）的收集器

- 设计者们希望做出一款能够建立起“停顿时间模型”（Pause Prediction Model）的收集器

  - 停顿时间模型的意思是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标，这几乎已经是实时Java（RTSJ）的中软实时垃圾收集器特征了。

- 它可以面向堆内存任何部分来组成回收集（Collection Set，一般简称 CSet）进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是 G1 收集器的 Mixed GC 模式。

- G1 开创的基于 Region 的堆内存布局是它能够实现这个目标的关键。

  - 虽然 G1 也仍是遵循分代收集理论设计的，但其堆内存的布局与其他收集器有非常明显的差异：G1 不再坚持固定大小以及固定数量的分代区域划分，而是把连续的 Java 堆划分为多个大小相等的独立区域（Region），每一个 Region 都可以根据需要，扮演新生代的 Eden 空间、Survivor 空间，或者老年代空间。
  - 收集器能够对扮演不同角色的 Region 采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。
  - Region 中还有一类特殊的 Humongous 区域，专门用来存储大对象。
    - G1认为只要大小超过了一个 Region 容量一半的对象即可判定为大对象。每个 Region 的大小可以通过参数 -XX:G1HeapRegionSize 设定，取值范围为 1MB～32MB，且应为 2 的 N 次幂。
    - 而对于那些超过了整个 Region 容量的超级大对象，将会被存放在 N 个连续的 Humongous Region 之中，G1 的大多数行为都把 Humongous Region 作为老年代的一部分来进行看待

- 虽然 G1 仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，它们都是一系列区域（不需要连续）的动态集合。

- G1 收集器之所以能建立可预测的停顿时间模型，是因为它将 Region 作为单次回收的最小单元，即每次收集到的内存空间都是 Region 大小的整数倍，这样可以有计划地避免在整个 Java 堆中进行全区域的垃圾收集。

  - 更具体的处理思路是让 G1 收集器去跟踪各个 Region 里面的垃圾堆积的“价值”大小
    - 价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（使用参数 -XX：MaxGCPauseMillis 指定，默认值是 200 毫秒），优先处理回收价值收益最大的那些 Region，这也就是“Garbage First”名字的由来。
    - 这种使用 Region 划分内存空间，以及具有优先级的区域回收方式，保证了 G1 收集器在有限的时间内获取尽可能高的收集效率。

- G1将堆内存“化整为零”的“解题思路”至少有（不限于）以下这些关键的细节问题需要妥善解决：

  - 譬如，将 Java 堆分成多个独立 Region 后，Region 里面存在的**跨 Region 引用对象如何解决**？
    - 使用记忆集避免全堆作为 GC Roots 扫描
      - 在 G1 收集器上记忆集的应用其实要复杂很多，它的每个 Region 都维护有自己的记忆集，这些记忆集会记录下别的 Region 指向自己的指针，并标记这些指针分别在哪些卡页的范围之内
      - G1 的记忆集在存储结构的本质上是一种哈希表，Key 是别的 Region 的起始地址，Value 是一个集合，里面存储的元素是卡表的索引号。
      - 这种“双向”的卡表结构（卡表是“我指向谁”，这种结构还记录了“谁指向我”）比原来的卡表实现起来更复杂，同时由于 Region 数量比传统收集器的分代数量明显要多得多，因此 G1 收集器要比其他的传统垃圾收集器有着更高的内存占用负担。
        - 根据经验，G1 至少要耗费大约相当于Java堆容量 10% 至 20% 的额外内存来维持收集器工作。
  - 譬如，在并发标记阶段如何保证**收集线程与用户线程互不干扰**地运行？
    - 这里首先要解决的是用户线程改变对象引用关系时，必须保证其不能打破原本的对象图结构，导致标记结果出现错误，该问题的解决办法笔者已经抽出独立小节来讲解过
      - CMS 收集器采用**增量更新**算法实现
      - 而 G1 收集器则是通过**原始快照**（SATB）算法来实现的
    - 此外，垃圾收集对用户线程的影响还体现在回收过程中新创建对象的内存分配上，程序要继续运行就肯定会持续有新对象被创建，G1 为每一个 Region 设计了两个名为 TAMS（Top at Mark Start）的指针，把 Region 中的一部分空间划分出来用于并发回收过程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上
      - G1 收集器默认在这个地址以上的对象是被隐式标记过的，即默认它们是存活的，不纳入回收范围。
    - 与 CMS 中的“Concurrent Mode Failure”失败会导致Full GC类似，如果内存回收的速度赶不上内存分配的速度，G1 收集器也要被迫冻结用户线程执行，导致 Full GC 而产生长时间“Stop The World”。
  - 譬如，怎样建立起**可靠的停顿预测模型**？
    - 用户通过 -XX:MaxGCPauseMillis 参数指定的停顿时间只意味着垃圾收集发生之前的期望值，但 G1 收集器要怎么做才能满足用户的期望呢？
    - G1 收集器的停顿预测模型是以**衰减均值（Decaying Average）**为理论基础来实现的，在垃圾收集过程中，G1 收集器会记录每个 Region 的回收耗时、每个 Region 记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得出平均值、标准偏差、置信度等统计信息。
      - 这里强调的“衰减平均值”是指它会比普通的平均值更容易受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。
      - Region 的统计状态越新越能决定其回收的价值。然后通过这些信息预测现在开始回收的话，由哪些 Region 组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益。

- 如果我们不去计算用户线程运行过程中的动作（如使用写屏障维护记忆集的操作），G1 收集器的运作过程大致可划分为以下四个步骤：

  - **初始标记（Initial Marking）**：仅仅只是标记一下 GC Roots 能直接关联到的对象，并且修改 TAMS 指针的值，让下一阶段用户线程并发运行时，能正确地在可用的 Region 中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行 Minor GC 的时候同步完成的，所以 G1 收集器在这个阶段实际并没有额外的停顿。
  - **并发标记（Concurrent Marking）**：从 GC Root 开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以后，还要重新处理 SATB 记录下的在并发时有引用变动的对象。
  - **最终标记（Final Marking）**：对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留下来的最后那少量的 SATB 记录。
  - **筛选回收（Live Data Counting and Evacuation）**：负责更新 Region 的统计数据，对各个 Region 的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个 Region 构成回收集，然后把决定回收的那一部分 Region 的存活对象复制到空的 Region 中，再清理掉整个旧 Region 的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。

- G1 收集器运行逻辑

  - 多个用户线程 -> Safepoint -> 初始标记 -> Safepoint -> 并发标记（多个用户线程可同时执行）-> Safepoint -> 最终标记 -> 筛选回收 -> Safepoint -> 

- 从上述阶段的描述可以看出，G1 收集器除了并发标记外，其余阶段也是要完全暂停用户线程的，换言之，它并非纯粹地追求低延迟，官方给它设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才能担当起“全功能收集器”的重任与期望

- 毫无疑问，可以由用户指定期望的停顿时间是 G1 收集器很强大的一个功能，设置不同的期望停顿时间，可使得 G1 在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。

  - 不过，这里设置的“期望值”必须是符合实际的，不能异想天开，毕竟 G1 是要冻结用户线程来复制对象的，这个停顿时间再怎么低也得有个限度。
  - 它默认的停顿目标为**两百毫秒**
    - 一般来说，回收阶段占到几十到一百甚至接近两百毫秒都很正常，但如果我们把停顿时间调得非常低，譬如设置为二十毫秒，很可能出现的结果就是由于停顿目标时间太短，导致每次选出来的回收集只占堆内存很小的一部分，收集器收集的速度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。
    - 很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间，但应用运行时间一长就不行了，最终占满堆引发Full GC反而降低性能，所以通常把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的。

- 从 G1 开始，最先进的垃圾收集器的设计导向都不约而同地变为追求能够应付应用的内存分配速率（Allocation Rate），而不追求一次把整个 Java 堆全部清理干净。

  - 这种新的收集器设计思路从工程实现上看是从 G1 开始兴起的，所以说 G1 是收集器技术发展的一个里程碑。

- 与 CMS 收集器互相比较

  - 可以指定最大停顿时间、分 Region 的内存布局、按收益动态确定回收集这些创新性设计带来的红利

  - 从最传统的算法理论上看，G1 也更有发展潜力。

    - 与 CMS 的“标记-清除”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器，但从局部（两个 Region 之间）上看又是基于“标记-复制”算法实现，无论如何，这两种算法都意味着 G1 运作期间不会产生内存空间碎片，垃圾收集完成之后能提供规整的可用内存。
    - 这种特性有利于程序长时间运行，在程序为大对象分配内存时不容易因无法找到连续内存空间而提前触发下一次收集。

  - 比起 CMS，G1 的弱项也可以列举出不少：

    如在用户程序运行过程中，G1 无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（Overload）都要比 CMS 要高。

    - 就内存占用来说，虽然 G1 和 CMS 都使用卡表来处理跨代指针，但 G1 的卡表实现更为复杂，而且堆中每个 Region，无论扮演的是新生代还是老年代角色，都必须有一份卡表，这导致 G1 的记忆集（和其他内存消耗）可能会占整个堆容量的 20% 乃至更多的内存空间；
      - 相比起来 CMS 的卡表就相当简单，只有唯一一份，而且只需要处理老年代到新生代的引用，反过来则不需要，由于新生代的对象具有朝生夕灭的不稳定性，引用变化频繁，能省下这个区域的维护开销是很划算的
    - 在执行负载的角度上，同样由于两个收集器各自的细节实现特点导致了用户程序运行时的负载会有不同
      - 譬如它们都使用到写屏障，CMS 用写后屏障来更新维护卡表；而 G1 除了使用写后屏障来进行同样的（由于G1的卡表结构复杂，其实是更烦琐的）卡表维护操作外，为了实现原始快照搜索（SATB）算法，还需要使用写前屏障来跟踪并发时的指针变化情况。
        - 相比起增量更新算法，原始快照搜索能够减少并发标记和重新标记阶段的消耗，避免 CMS 那样在最终标记阶段停顿时间过长的缺点，但是在用户程序运行过程中确实会产生由跟踪引用变化带来的额外负担。
      - 由于 G1 对写屏障的复杂操作要比 CMS 消耗更多的运算资源，所以 CMS 的写屏障实现是直接的同步操作，而 G1 就不得不将其实现为类似于消息队列的结构，把写前屏障和写后屏障中要做的事情都放到队列里，然后再异步处理。

  - 以上的优缺点对比仅仅是针对 G1 和 CMS 两款垃圾收集器单独某方面的实现细节的定性分析，下面是针对具体场景才能做的定量比较：

    - 按照笔者的实践经验，目前在小内存应用上 CMS 的表现大概率仍然要会优于 G1
    - 而在大内存应用上 G1 则大多能发挥其优势
    - 这个优劣势的 Java 堆容量平衡点通常在 6GB 至 8GB 之间，当然，以上这些也仅是经验之谈
    - 随着HotSpot的开发者对 G1 的不断优化，也会让对比结果继续向 G1 倾斜。（注：JDK 14 CMS 直接没了，笑）

##### 3.6 低延迟垃圾收集器

- 衡量垃圾收集器的三项最重要的指标是：内存占用（Footprint）、吞吐量（Throughput）和延迟（Latency），三者共同构成了一个“不可能三角”。

  - 在内存占用、吞吐量和延迟这三项指标里，延迟的重要性日益凸显，越发备受关注。
    - 其原因是随着计算机硬件的发展、性能的提升，我们越来越能容忍收集器多占用一点点内存；
    - 硬件性能增长，对软件系统的处理能力是有直接助益的，硬件的规格和性能越高，也有助于降低收集器运行时对应用程序的影响，换句话说，吞吐量会更高。
    - 但对延迟则不是这样，硬件规格提升，准确地说是内存的扩大，对延迟反而会带来负面的效果
      - 虚拟机要回收完整的 1TB 的堆内存，毫无疑问要比回收 1GB 的堆内存耗费更多时间

###### 3.6.1 Shenandoah 收集器

- Shenandoah作为第一款不由 Oracle（包括以前的 Sun）公司的虚拟机团队所领导开发的 HotSpot 垃圾收集器，不可避免地会受到一些来自“官方”的排挤。

  - Oracle 仍明确拒绝在 Oracle JDK 12 中支持 Shenandoah 收集器

- 最初 Shenandoah 是由 RedHat 公司独立发展的新型收集器项目，在 2014 年 RedHat 把 Shenandoah 贡献给了 OpenJDK，并推动它成为 OpenJDK 12 的正式特性之一，也就是后来的 JEP 189。

- 这个项目的目标是实现一种能在**任何堆内存大小下**都可以把垃圾收集的**停顿时间限制在十毫秒**以内的垃圾收集器

  - 该目标意味着相比 CMS 和 G1，Shenandoah 不仅要进行并发的垃圾标记，还要并发地进行对象清理后的整理动作。

- 从代码历史渊源上讲，比起稍后要介绍的有着 Oracle 正朔血统的 ZGC，Shenandoah 反而更像是 G1 的下一代继承者，它们两者有着相似的堆内存布局，在初始标记、并发标记等许多阶段的处理思路上都高度一致，甚至还直接共享了一部分实现代码

  - 这使得部分对 G1 的打磨改进和 Bug 修改会同时反映在 Shenandoah 之上
  - 而由于 Shenandoah 加入所带来的一些新特性，也有部分会出现在 G1 收集器中，譬如在并发失败后作为“逃生门”的 Full GC，G1 就是由于合并了 Shenandoah 的代码才获得多线程 Full GC 的支持。

- 那 Shenandoah 相比起 G1 又有什么改进呢？

  - 虽然 Shenandoah 也是使用基于 Region 的堆内存布局，同样有着用于存放大对象的 Humongous Region，默认的回收策略也同样是优先处理回收价值最大的 Region……
  - 但在管理堆内存方面，它与 G1 至少有三个明显的不同之处
    - 最重要的当然是支持并发的整理算法，G1的回收阶段是可以多线程并行的，但却不能与用户线程并发，这点作为Shenandoah最核心的功能稍后笔者会着重讲解。
    - 其次，Shenandoah（目前）是**默认不使用分代收集**的，换言之，不会有专门的新生代 Region 或者老年代 Region 的存在，没有实现分代，并不是说分代对 Shenandoah 没有价值，这更多是出于性价比的权衡，基于工作量上的考虑而将其放到优先级较低的位置上。
    - 最后，Shenandoah 摒弃了在 G1 中耗费大量内存和计算资源去维护的记忆集，改用名为“**连接矩阵”（Connection Matrix）**的全局数据结构来记录跨 Region 的引用关系，降低了处理跨代指针时的记忆集维护消耗，也降低了伪共享问题（见3.4.4节）的发生概率。
      - 连接矩阵可以简单理解为一张二维表格，如果 Region N 有对象指向 Region M，就在表格的 N 行 M 列中打上一个标记

- Shenandoah收集器的**工作过程**大致可以划分为以下九个阶段

  （此处以 Shenandoah 在 2016 年发表的原始论文进行介绍。在最新版本的 Shenandoah 2.0 中，进一步强化了“部分收集”的特性，初始标记之前还有 Initial Partial、Concurrent Partial 和 Final Partial 阶段，它们可以不太严谨地理解为对应于以前分代收集中的 Minor GC 的工作）：

  - **初始标记（Initial Marking）**：与 G1 一样，首先标记与 GC Roots 直接关联的对象，这个阶段仍是**“Stop The World”**的，但停顿时间与堆大小无关，只与 GC Roots 的数量相关。
  - **并发标记（Concurrent Marking）**：与 G1 一样，遍历对象图，标记出全部可达的对象，这个阶段是与用户线程一起并发的，时间长短取决于堆中存活对象的数量以及对象图的结构复杂程度。
  - **最终标记（Final Marking）**：与 G1 一样，处理剩余的 SATB 扫描，并在这个阶段统计出回收价值最高的 Region，将这些 Region 构成一组回收集（Collection Set）。最终标记阶段也会有一小段**短暂的停顿**。
  - **并发清理（Concurrent Cleanup）**：这个阶段用于清理那些整个区域内连一个存活对象都没有找到的 Region（这类 Region 被称为 Immediate Garbage Region）。
  - **并发回收（Concurrent Evacuation）**：并发回收阶段是 Shenandoah 与之前 HotSpot 中其他收集器的核心差异。在这个阶段，Shenandoah 要把回收集里面的存活对象先复制一份到其他未被使用的 Region 之中。
    - 复制对象这件事情如果将用户线程冻结起来再做那是相当简单的，但如果两者必须要同时并发进行的话，就变得复杂起来了。
      - 其困难点是在移动对象的同时，用户线程仍然可能不停对被移动的对象进行读写访问，移动对象是一次性的行为，但移动之后整个内存中所有指向该对象的引用都还是旧对象的地址，这是很难一瞬间全部改变过来的。
    - 对于并发回收阶段遇到的这些困难，Shenandoah 将会通过读屏障和被称为**“Brooks Pointers”**的转发指针来解决（讲解完 Shenandoah 整个工作过程之后笔者还要再回头介绍它）。
    - 并发回收阶段运行的时间长短取决于回收集的大小。
  - **初始引用更新（Initial Update Reference）**：并发回收阶段复制对象结束后，还需要把堆中所有指向旧对象的引用修正到复制后的新地址，这个操作称为引用更新。
    - 引用更新的初始化阶段实际上并未做什么具体的处理，设立这个阶段只是为了建立一个线程集合点，确保所有并发回收阶段中进行的收集器线程都已完成分配给它们的对象移动任务而已。
    - 初始引用更新时间很短，会产生一个**非常短暂的停顿**。
  - **并发引用更新（Concurrent Update Reference）**：真正开始进行引用更新操作，这个阶段是与用户线程一起并发的，时间长短取决于内存中涉及的引用数量的多少。
    - 并发引用更新与并发标记不同，它不再需要沿着对象图来搜索，只需要按照内存物理地址的顺序，线性地搜索出引用类型，把旧值改为新值即可。
  - **最终引用更新（Final Update Reference）**：解决了堆中的引用更新后，还要修正存在于 GC Roots 中的引用。
    - 这个阶段是 Shenandoah 的**最后一次停顿**，停顿时间只与 GC Roots 的数量相关。
  - **并发清理（Concurrent Cleanup）**：经过并发回收和引用更新之后，整个回收集中所有的 Region 已再无存活对象，这些 Region 都变成 Immediate Garbage Regions 了，最后再调用一次并发清理过程来回收这些 Region 的内存空间，供以后新对象分配使用。

- 以上对 Shenandoah 收集器这九个阶段的工作过程的描述可能拆分得略为琐碎，读者只要抓住其中三个最重要的并发阶段（并发标记、并发回收、并发引用更新），就能比较容易理清 Shenandoah 是如何运作的了。

- Shenandoah 的**弱项（高运行负担使得吞吐量下降）**和**强项（低延迟时间）**

- Brooks Pointer 详解

  - 1984 年，Rodney A.Brooks 在论文《Trading Data Space for Reduced Time and Code Space in Real-Time Garbage Collection on Stock Hardware》中提出了使用转发指针（Forwarding Pointer，也常被称为 Indirection Pointer）来实现对象移动与用户程序并发的一种解决方案。
    - 此前，要做类似的并发操作，通常是在被移动对象原有的内存上设置保护陷阱（Memory Protection Trap），一旦用户程序访问到归属于旧对象的内存空间就会产生自陷中段，进入预设好的异常处理器中，再由其中的代码逻辑把访问转发到复制后的新对象上。
    - 虽然确实能够实现对象移动与用户线程并发，但是如果没有操作系统层面的直接支持，这种方案将导致用户态频繁切换到核心态，代价是非常大的，不能频繁使用。
  - Brooks提出的新方案不需要用到内存保护陷阱，而是在原有对象布局结构的最前面统一增加一个新的引用字段，在正常不处于并发移动的情况下，**该引用指向对象自己**
    - 从结构上来看，Brooks 提出的转发指针与某些早期 Java 虚拟机使用过的句柄定位（参考对象定位）有一些相似之处
      - 两者都是一种间接性的对象访问方式，差别是句柄通常会统一存储在专门的句柄池中，而转发指针是分散存放在每一个对象头前面。
    - 缺点
      - 每次对象访问会带来一次额外的转向开销
    - 收益
      - 当对象拥有了一份新的副本时，只需要修改一处指针的值，即旧对象上转发指针的引用位置，使其指向新对象，便可将所有对该对象的访问转发到新的副本上
    - 问题
      - Brooks 形式的转发指针在设计上决定了它是必然会出现**多线程竞争问题**的
        - 实际上 Shenandoah 收集器是通过比较并交换（Compare And Swap，CAS）操作来保证并发时对象的访问正确性的。
      - **执行频率的问题**
        - 尽管通过对象头上的Brooks Pointer 来保证并发时原对象与复制对象的访问一致性，这件事情只从原理上看是不复杂的，但是“对象访问”这四个字的分量是非常重的
          - 对于一门面向对象的编程语言来说，对象的读取、写入，对象的比较，为对象哈希值计算，用对象加锁等，这些操作都属于对象访问的范畴，它们在代码中比比皆是
        - 要覆盖全部对象访问操作，Shenandoah 不得不同时设置读、写屏障去拦截。
          - 为了实现 Brooks Pointer，Shenandoah 在读、写屏障中都加入了额外的转发处理，尤其是使用读屏障的代价，这是比写屏障更大的。
          - 代码里对象读取的出现频率要比对象写入的频率高出很多，读屏障数量自然也要比写屏障多得多，所以读屏障的使用必须更加谨慎，不允许任何的重量级操作。
          - 计划在 JDK 13 中将Shenandoah的内存屏障模型改进为基于引用访问屏障（Load Reference Barrier）的实现（注：不确定最后是否在这个版本落地了）
            - 所谓“引用访问屏障”是指内存屏障只拦截对象中数据类型为引用类型的读写操作，而不去管原生数据类型等其他非引用字段的读写，这能够省去大量对原生类型、对象比较、对象加锁等场景中设置内存屏障所带来的消耗。

###### 3.6.2 ZGC 收集器

- ZGC（“Z”并非什么专业名词的缩写，这款收集器的名字就叫作 Z Garbage Collector）是一款在 JDK 11 中新加入的具有实验性质的低延迟垃圾收集器，是由 Oracle 公司研发的。（注：JDK 15 和 Shenandoah 一起进入产品阶段）
- ZGC 和 Shenandoah 的目标是高度相似的，都希望在尽可能对吞吐量影响不太大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停顿时间限制在十毫秒以内的低延迟。
- 但是 ZGC 和 Shenandoah 的实现思路又是差异显著的
  - 如果说 RedHat 公司开发的 Shenandoah 像是 Oracle 的 G1 收集器的实际继承者的话
  - 那 Oracle 公司开发的ZGC就更像是 Azul System 公司独步天下的 PGC（Pauseless GC）和 C4（Concurrent Continuously CompactingCollector）收集器的同胞兄弟。
    - 早在 2005 年，运行在 Azul VM 上的 PGC 就已经实现了标记和整理阶段都全程与用户线程并发运行的垃圾收集，而运行在 Zing VM 上的 C4 收集器是 PGC 继续演进的产物，主要增加了分代收集支持，大幅提升了收集器能够承受的对象分配速度。
- 主要特征：ZGC 收集器是一款**基于 Region 内存布局**的，（暂时）**不设分代的**，使用了**读屏障、染色指针和内存多重映射**等技术来实现**可并发的标记-整理**算法的，以**低延迟**为首要目标的一款垃圾收集器。
  - 首先从 ZGC 的**内存布局**说起。
    - 与 Shenandoah 和 G1 一样，ZGC 也采用基于 Region 的堆内存布局，但与它们不同的是， ZGC 的 Region（在一些官方资料中将它称为 Page 或者 ZPage，本章为行文一致继续称为 Region）具有**动态性**——动态创建和销毁，以及动态的区域容量大小。在 x64 硬件平台下，ZGC 的 Region 可以具有的大、中、小三类容量：
      - 小型 Region（Small Region）：容量固定为 2MB，用于放置小于 256KB 的小对象。
      - 中型 Region（Medium Region）：容量固定为 32MB，用于放置大于等于 256KB 但小于 4MB 的对象。
      - 大型 Region（Large Region）：容量不固定，可以动态变化，但必须为 2MB 的整数倍，用于放置 4MB 或以上的大对象。每个大型 Region 中只会存放一个大对象，这也预示着虽然名字叫作“大型 Region”，但它的实际容量完全有可能小于中型 Region，最小容量可低至 4MB。大型 Region 在 ZGC 的实现中是不会被重分配（重分配是 ZGC 的一种处理动作，用于复制对象的收集器阶段，稍后会介绍到）的，因为复制一个大对象的代价非常高昂。
  - 接下来是 ZGC 的核心问题——**并发整理算法**的实现。
    - ZGC 收集器有一个标志性的设计是它采用的染色指针技术（Colored Pointer，其他类似的技术中可能将它称为 Tag Pointer 或者 Version Pointer）。
      - 从前，如果我们要在对象上存储一些额外的、只供收集器或者虚拟机本身使用的数据，通常会在对象头中增加额外的存储字段
      - HotSpot 虚拟机的几种收集器有不同的标记实现方案，有的把标记直接记录在对象头上（如 Serial 收集器），有的把标记记录在与对象相互独立的数据结构上（如 G1、Shenandoah 使用了一种相当于堆内存的 1/64 大小的，称为 BitMap 的结构来记录标记信息），而 ZGC 的染色指针是最直接的、最纯粹的，它直接把标记信息记在引用对象的指针上，这时，与其说可达性分析是遍历对象图来标记对象，还不如说是遍历“引用图”来标记“引用”了。
      - 染色指针是一种直接将少量额外的信息存储在指针上的技术，可是为什么指针本身也可以存储额外信息呢？
        - 尽管 Linux 下 64 位指针的高 18 位不能用来寻址，但剩余的 46 位指针所能支持的 64TB 内存在今天仍然能够充分满足大型服务器的需要。
        - 鉴于此，ZGC 的染色指针技术继续盯上了这剩下的 46 位指针宽度，将其高4位提取出来存储四个标志信息。通过这些标志位，虚拟机可以直接从指针中看到其引用对象的三色标记状态、是否进入了重分配集（即被移动过）、是否只能通过 finalize() 方法才能被访问到
        - 当然，由于这些标志位进一步压缩了原本就只有 46 位的地址空间，也直接导致 ZGC 能够管理的内存不可以超过 4TB（2 的 42 次幂）
      - 诸多约束
        - 染色指针有 4TB 的内存限制
        - 不能支持 32位平台
        - 不能支持压缩指针（-XX:+UseCompressedOops）等
      - 三大优势
        - 染色指针可以使得一旦某个Region的存活对象被移走之后，这个Region立即就能够被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正后才能清理。
        - 染色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，设置内存屏障，尤其是写屏障的目的通常是为了记录对象引用的变动情况，如果将这些信息直接维护在指针中，显然就可以省去一些专门的记录操作。实际上，到目前为止ZGC都并未使用任何写屏障，只使用了读屏障（一部分是染色指针的功劳，一部分是ZGC现在还不支持分代收集，天然就没有跨代引用的问题）。
        - 染色指针可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。
      - 不过，要顺利应用染色指针有一个必须解决的前置问题：Java虚拟机作为一个普普通通的进程，这样随意重新定义内存中某些指针的其中几位，操作系统是否支持？处理器是否支持？这是很现实的问题，无论中间过程如何，程序代码最终都要转换为机器指令流交付给处理器去执行，处理器可不会管指令流中的指针哪部分存的是标志位，哪部分才是真正的寻址地址，只会把整个指针都视作一个内存地址来对待。
        - Linux/x86-64 平台上的 ZGC 使用了**多重映射（Multi-Mapping）**将多个不同的虚拟内存地址映射到同一个物理内存地址上，这是一种多对一映射，意味着 ZGC 在虚拟内存中看到的地址空间要比实际的堆内存容量来得更大。
  - ZGC的运作过程大致可划分为以下四个大的阶段。全部四个阶段都是可以并发执行的，仅是两个阶段中间会存在短暂的停顿小阶段，这些小阶段，譬如初始化GC Root直接关联对象的Mark Start
    - **并发标记（Concurrent Mark）**：与G1、Shenandoah一样，并发标记是遍历对象图做可达性分析的阶段，前后也要经过类似于G1、Shenandoah的初始标记、最终标记（尽管ZGC中的名字不叫这些）的短暂停顿，而且这些停顿阶段所做的事情在目标上也是相类似的。
      - 与G1、Shenandoah不同的是，ZGC 的标记是在指针上而不是在对象上进行的，标记阶段会更新染色指针中的Marked 0、Marked 1标志位。
    - **并发预备重分配（Concurrent Prepare for Relocate）**：这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成**重分配集（Relocation Set）**。
      - 重分配集与G1收集器的回收集（Collection Set）还是有区别的，ZGC划分Region的目的并非为了像G1那样做收益优先的增量回收。相反，ZGC每次回收都会扫描所有的Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本。
      - 因此，ZGC的重分配集只是决定了里面的存活对象会被重新复制到其他的Region中，里面的Region会被释放，而并不能说回收行为就只是针对这个集合里面的Region进行，因为标记过程是针对全堆的。
      - 此外，在 JDK 12 的 ZGC 中开始支持的类卸载以及弱引用的处理，也是在这个阶段中完成的。
    - **并发重分配（Concurrent Relocate）**：重分配是ZGC执行过程中的核心阶段，
      - 这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个**转发表（Forward Table）**，记录从旧对象到新对象的转向关系。
      - 得益于染色指针的支持，ZGC 收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障所截获，然后立即根据 Region 上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的**“自愈”（Self Healing）**能力。
        - 这样做的好处是只有第一次访问旧对象会陷入转发，也就是只慢一次，对比Shenandoah 的 Brooks 转发指针，那是每次对象访问都必须付出的固定开销，简单地说就是每次都慢，因此 ZGC 对用户程序的运行时负载要比 Shenandoah 来得更低一些。
        - 还有另外一个直接的好处是由于染色指针的存在，一旦重分配集中某个 Region 的存活对象都复制完毕后，这个 Region 就可以立即释放用于新对象的分配（但是转发表还得留着不能释放掉），哪怕堆中还有很多指向这个对象的未更新指针也没有关系，这些旧指针一旦被使用，它们都是可以自愈的。
    - **并发重映射（Concurrent Remap）**：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，这一点从目标角度看是与 Shenandoah 并发引用更新阶段一样的，但是 ZGC的并发重映射并不是一个必须要“迫切”去完成的任务
      - 因为前面说过，即使是旧引用，它也是可以自愈的，最多只是第一次使用时多一次转发和修正操作。重映射清理这些旧引用的主要目的是为了不变慢（还有清理结束后可以释放转发表这样的附带收益），所以说这并不是很“迫切”。
      - 因此，ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销。一旦所有指针都被修正之后，原来记录新旧对象关系的转发表就可以释放掉了。
- ZGC的设计理念与Azul System公司的PGC和C4收集器一脉相承[10]，是迄今垃圾收集器研究的最前沿成果，它与Shenandoah一样做到了几乎整个收集过程都全程可并发，短暂停顿也只与GC Roots大小相关而与堆内存大小无关，因而同样实现了任何堆上停顿都小于十毫秒的目标。
- 相比G1、Shenandoah等先进的垃圾收集器，ZGC在实现细节上做了一些不同的权衡选择
  - 譬如G1需要通过写屏障来维护记忆集，才能处理跨代指针，得以实现Region的增量回收。记忆集要占用大量的内存空间，写屏障也对正常程序运行造成额外负担，这些都是权衡选择的代价。
  - ZGC就完全没有使用记忆集，它甚至连分代都没有，连像CMS中那样只记录新生代和老年代间引用的卡表也不需要，因而完全没有用到写屏障，所以给用户线程带来的运行负担也要小得多。
    - ZGC的这种选择也限制了它能承受的对象分配速率不会太高
- ZGC还有一个常在技术资料上被提及的优点是支持“NUMA-Aware”的内存分配。
  - NUMA（Non Uniform Memory Access，非统一内存访问架构）是一种为多处理器或者多核处理器的计算机所设计的内存架构。
  - 在NUMA架构下，ZGC收集器会优先尝试在请求线程当前所处的处理器的本地内存上分配对象，以保证高效内存访问。
  - 在ZGC之前的收集器就只有针对吞吐量设计的Parallel Scavenge支持NUMA内存分配，如今ZGC也成为另外一个选择。

##### 3.7 选择合适的垃圾收集器

###### 3.7.1 Epsilon 收集器

- JDK 11
- 这是一款以不能够进行垃圾收集为“卖点”的垃圾收集器
- Epsilon收集器由RedHat公司在JEP 318中提出，在此提案里Epsilon被形容成一个无操作的收集器（A No-Op Garbage Collector），而事实上只要Java虚拟机能够工作，垃圾收集器便不可能是真正“无操作”的。
  - 原因是“垃圾收集器”这个名字并不能形容它全部的职责，更贴切的名字应该是本书为这一部分所取的标题——“自动内存管理子系统”。
  - 一个垃圾收集器除了垃圾收集这个本职工作之外，它还要负责堆的管理与布局、对象的分配、与解释器的协作、与编译器的协作、与监控子系统协作等职责，其中至少堆的管理和对象的分配这部分功能是Java虚拟机能够正常运作的必要支持，是一个最小化功能的垃圾收集器也必须实现的内容。
- 从 JDK 10 开始，为了隔离垃圾收集器与 Java 虚拟机解释、编译、监控等子系统的关系，RedHat 提出了垃圾收集器的统一接口，即 JEP 304 提案，Epsilon 是这个接口的有效性验证和参考实现，同时也用于需要剥离垃圾收集器影响的性能测试和压力测试。

###### 3.7.2 收集器的权衡

- 我们应该如何选择一款适合自己应用的收集器呢？这个问题的答案主要受以下三个因素影响
  - 应用程序的主要关注点是什么？如果是数据分析、科学计算类的任务，目标是能尽快算出结果，那**吞吐量**就是主要关注点；如果是SLA应用，那停顿时间直接影响服务质量，严重的甚至会导致事务超时，这样**延迟**就是主要关注点；而如果是客户端应用或者嵌入式应用，那垃圾收集的**内存占用**则是不可忽视的。
  - 运行应用的基础设施如何？譬如硬件规格，要涉及的系统架构是 x86-32/64、SPARC 还是 ARM/Aarch64；处理器的数量多少，分配内存的大小；选择的操作系统是 Linux、Solaris 还是Windows 等。
  - 使用 JDK 的发行商是什么？版本号是多少？是ZingJDK/Zulu、OracleJDK、Open-JDK、OpenJ9抑或是其他公司的发行版？该JDK对应了《Java虚拟机规范》的哪个版本？

###### 3.7.3 虚拟机及垃圾收集器日志

- 在 JDK 9 以前，HotSpot 并没有提供统一的日志处理框架，虚拟机各个功能模块的日志开关分布在不同的参数上，日志级别、循环日志大小、输出格式、重定向等设置在不同功能上都要单独解决。
- 直到 JDK 9，这种混乱不堪的局面才终于消失，HotSpot所有功能的日志都收归到了“-Xlog”参数上，这个参数的能力也相应被极大拓展了

###### 3.7.4 垃圾收集器参数总结

| 参数                            | 描述                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| UseSerialGC                     | **虚拟机运行在 Client 模式下的默认值**，打开此开关后，使用 Serial + Serial Old 的收集器组合进行内存回收 |
| UseParNewGC                     | 打开此开关后，使用 ParNew + Serial Old 的收集器组合进行内存回收，在 JDK 9 后不再支持 |
| UseConcMarkSweepGC              | 打开此开关后，使用 ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器将作为 CMS 收集器出现“Concurrent Mode Failure”失败后的后备收集器使用 |
| UseParallelGC                   | **JDK 9 之前虚拟机运行在 Server 模式下的默认值**，打开此开关后，使用 Parallel Scavenge + Serial Old（PS MarkSweep）的收集器组合进行内存回收 |
| UseParallelOldGC                | 打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合进行内存回收（**注：有文章说实际上 Java 7u4 之后，包括 8，Server 模式下默认是这个组合了**） |
| SurvivorRatio                   |                                                              |
| PretenureSizeThreshold          |                                                              |
| MaxTenuringThreshold            |                                                              |
| UseAdaptiveSizePolicy           |                                                              |
| HandlePromotionFailure          |                                                              |
| ParallelGCThreads               |                                                              |
| GCTimeRatio                     |                                                              |
| MaxGCPauseMillis                |                                                              |
| CMSInitiating OccupancyFraction |                                                              |
| UseCMSCompactAtFullCollection   |                                                              |
| CMSFullGCsBeforeCompaction      |                                                              |
| UseG1GC                         |                                                              |
| G1HeapRegionSize=n              |                                                              |
| MaxGCPauseMillis                |                                                              |
| G1NewSizePercent                |                                                              |
| G1MaxNewSizePercent             |                                                              |
| ParallelGCThreads               |                                                              |
| ConcGCThreads=n                 |                                                              |
| InitiatingHeapOccupancyPercent  |                                                              |
| UseShenandoahGC                 |                                                              |
| ShenandoahGCHeuristics          |                                                              |
| UseZGC                          |                                                              |
| UseNUMA                         |                                                              |

## 虚拟机性能监控、故障处理工具

### 具体问题

- JVM相关的分析工具有使用过哪些？具体的性能调优步骤吗？
- 说一下垃圾回收？如果GC突然很慢怎么排查，比如原来GC完成只需要1秒，现在要5秒？了解哪些gc相关的工具，比如jstack之类的
- 有没有用过工具，怎么查看Java堆的统计信息 (参考《深入理解Java虚拟机》第4章，没用过工具，只说了常用了JVM参数)
- jvm工具，jstack jconsole 这些，还是看一丢丢，留个印象
- 服务器CPU使用率很高，如何排查， top 定位进程， 如果是Java，通过jstack进行线程快照分析，jmap，jhat 等等，
- 用到过内存分析工具吗；
- 查看运行内存，JVM 状态有什么方法

### 思考方向

#### 4.2 基础故障处理工具

- Java 开发人员肯定都知道 JDK 的 bin 目录中有 java.exe、javac.exe 这两个命令行工具，但并非所有程序员都了解过 JDK 的 bin 目录下其他各种小工具的作用。
  - 除了编译和运行 Java 程序外，打包、部署、签名、调试、监控、运维等各种场景都可能会用到它们
- 在本章，笔者将介绍这些工具中的一部分，主要是用于监视虚拟机运行状态和进行故障处理的工具。
  - 这些故障处理工具根据软件可用性和授权的不同，可以把它们划分成三类：
    - 商业授权工具：主要是JMC（Java Mission Control）及它要使用到的JFR（Java Flight Recorder），JMC 这个原本来自于 JRockit 的运维监控套件从 JDK 7 Update 40 开始就被集成到 OracleJDK 中，JDK 11之前都无须独立下载，但是在商业环境中使用它则是要付费的
    - 正式支持工具：这一类工具属于被长期支持的工具，不同平台、不同版本的JDK之间，这类工具可能会略有差异，但是不会出现某一个工具突然消失的情况
    - 实验性工具：这一类工具在它们的使用说明中被声明为“没有技术支持，并且是实验性质的”（Unsupported and Experimental）产品，日后可能会转正，也可能会在某个JDK版本中无声无息地消失。但事实上它们通常都非常稳定而且功能强大，也能在处理应用程序性能问题、定位故障时发挥很大的作用。

##### 4.2.1 jps：虚拟机进程状况工具

- JDK的很多小工具的名字都参考了UNIX命令的命名方式，jps（JVM Process Status Tool）是其中的典型。

- 除了名字像UNIX的ps命令之外，它的功能也和ps命令类似：可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID（LVMID，Local Virtual Machine Identifier）。

  - 虽然功能比较单一，但它绝对是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进程。
  - 对于本地虚拟机进程来说，LVMID与操作系统的进程ID（PID，Process Identifier）是一致的，使用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID
  - 但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就必须依赖 jps 命令显示主类的功能才能区分了。

- 选项

  - | 选项 | 作用                                                     |
    | ---- | -------------------------------------------------------- |
    | -q   | 只输出 LVMID，省略主类的名称                             |
    | -m   | 输出虚拟机进程启动时传递给主类 main() 函数的参数         |
    | -l   | 输出主类的全名，如果进程执行的是 JAR 包，则输出 JAR 路径 |
    | -v   | 输出虚拟机进程启动时的 JVM 参数                          |

##### 4.2.2 jstat：虚拟机统计信息监视工具

- jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。

- 它可以显示本地或者远程虚拟机进程中的类加载、内存、垃圾收集、即时编译等运行时数据

  - 在没有 GUI 图形界面、只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的常用工具。

- jstat命令格式为：

  ```shell
  jstat [ option vmid [interval[s|ms] [count]] ]
  ```

  - 对于命令格式中的 VMID 与 LVMID 需要特别说明一下

    - 如果是本地虚拟机进程，VMID 与 LVMID 是一致的；

    - 如果是远程虚拟机进程，那 VMID 的格式应当是：

      ```
      [protocol:][//]lvmid[@hostname[:port]/servername]
      ```

  - 参数interval和count代表查询间隔和次数

    - 如果省略这2个参数，说明只查询一次。

    - 假设需要每250毫秒查询一次进程2764垃圾收集状况，一共查询20次，那命令应当是：

      ```shell
      jstat -gc 2764 250 20
      ```

  - 选项option代表用户希望查询的虚拟机信息，主要分为三类：类加载、垃圾收集、运行期编译状况。

    - | 选项              | 作用                                                         |
      | ----------------- | ------------------------------------------------------------ |
      | -class            | 监视类加载、卸载数量、总空间以及类加载所耗费的时间           |
      | -gc               | 监视 Java 堆状况，包括 Eden 区、2 个 Survivor 区、老年代、永久代等的容量，已用空间，垃圾收集时间合计等信息 |
      | -gccapacity       | 监视内容与 -gc 基本相同，但输出主要关注 Java 堆各大区域使用到的最大、最小空间 |
      | -gcutil           | 监视内容与 -gc 基本相同，但输出主要关注已使用空间占总空间的百分比 |
      | -gcgauge          | 与 -gcutil 功能一样，但是会额外输出导致上一次垃圾收集产生的原因 |
      | -gcnew            | 监视新生代垃圾收集状况                                       |
      | -gcnewcapacity    | 监视内容与 -gcnew 基本相同，输出主要关注使用到的最大、最小空间 |
      | -gcold            | 监视老年代垃圾收集状况                                       |
      | -gcoldcapacity    | 监视内容与 -gcold 基本相同，输出主要关注使用到的最大、最小空间 |
      | -gcpermcapacity   | 输出永久代使用到的最大、最小空间                             |
      | -compiler         | 输出即时编译器编译过的方法、耗时等信息                       |
      | -printcompilation | 输出已经被即时编译的方法                                     |

##### 4.2.3 jinfo：Java 配置信息监视工具

- jinfo（Configuration Info for Java）的作用是实时查看和调整虚拟机各项参数。

  - 使用 jps 命令的 -v 参数可以查看虚拟机启动时显式指定的参数列表
  - 但如果想知道未被显式指定的参数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了
  - jinfo还可以使用 -sysprops 选项把虚拟机进程的System.getProperties()的内容打印出来。

- JDK 6之后，jinfo在Windows和Linux平台都有提供，并且加入了在运行期修改部分参数值的能力（可以使用-flag[+|-]name或者-flag name=value在运行期修改一部分运行期可写的虚拟机参数值）。

- jinfo命令格式：

  ```shell
  jinfo [ option ] pid
  ```

##### 4.2.4 jmap：Java 内存映像工具

- jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。

  - 如果不使用 jmap 命令，要想获取 Java 堆转储快照也还有一些比较“暴力”的手段：
    - 譬如在第2章中用过的 -XX:+HeapDumpOnOutOfMemoryError 参数，可以让虚拟机在内存溢出异常出现之后自动生成堆转储快照文件
    - 通过 -XX:+HeapDumpOnCtrlBreak 参数则可以使用[Ctrl]+[Break]键让虚拟机生成堆转储快照文件
    - 又或者在Linux系统下通过 Kill -3 命令发送进程退出信号“恐吓”一下虚拟机，也能顺利拿到堆转储快照。

- jmap的作用并不仅仅是为了获取堆转储快照，它还可以查询finalize执行队列、Java堆和方法区的详细信息，如空间使用率、当前用的是哪种收集器等。

- jmap命令格式：

  ```shell
  jmap [ option ] vmid
  ```

  - option选项的合法值与具体含义

    - | 选项           | 作用                                                         |
      | -------------- | ------------------------------------------------------------ |
      | -dump          | 生成 Java 堆转储快照。格式为 `-dump:[live,]format=b,file=<filename>`，其中 live 子参数说明是否只 dump 出存活的对象 |
      | -finalizerinfo | 显示在 F-Queue 中等待 Finalizer 线程执行 finalize 方法的对象。只在 Linux/Solaris 平台下有效 |
      | -heap          | 显示 Java 堆详细信息，如使用哪种回收器、参数配置、分代状况等。只在 Linux/Solaris 平台下有效 |
      | -histo         | 显示堆中对象统计信息，包括类、实例数量、合计容量             |
      | -permstat      | 以 ClassLoader 为统计口径显示永久代内存状态。只在 Linux/Solaris 平台下有效 |
      | -F             | 当虚拟机进程对 -dump 选项没有响应时，可使用这个选项强制生成 dump 快照。只在 Linux/Solaris 平台下有效 |

##### 4.2.5 jhat：虚拟机堆转储快照分析工具

- JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。
- jhat内置了一个微型的HTTP/Web服务器，生成堆转储快照的分析结果后，可以在浏览器中查看。
- 在实际工作中，除非手上真的没有别的工具可用，否则多数人是不会直接使用jhat命令来分析堆转储快照文件的，主要原因有两个方面。
  - 一是一般不会在部署应用程序的服务器上直接分析堆转储快照，即使可以这样做，也会尽量将堆转储快照文件复制到其他机器上进行分析，因为分析工作是一个耗时而且极为耗费硬件资源的过程，既然都要在其他机器上进行，就没有必要再受命令行工具的限制了。
  - 另外一个原因是jhat的分析功能相对来说比较简陋，后文将会介绍到的VisualVM，以及专业用于分析堆转储快照文件的Eclipse Memory Analyzer、IBM HeapAnalyzer 等工具，都能实现比jhat更强大专业的分析功能。

##### 4.2.6 jstack：Java 堆栈跟踪工具

- jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。

  - 线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂起等，都是导致线程长时间停顿的常见原因。
  - 线程出现停顿时通过jstack来查看各个线程的调用堆栈，就可以获知没有响应的线程到底在后台做些什么事情，或者等待着什么资源。

- jstack命令格式：

  ```shell
  jstack [ option ] vmid
  ```

  - option选项的合法值与具体含义

    - | 选项 | 作用                                          |
      | ---- | --------------------------------------------- |
      | -F   | 当正常输出的请求不被响应时，强制输出线程堆栈  |
      | -l   | 除堆栈外，显示关于锁的附加信息                |
      | -m   | 如果调用到本地方法的话，可以显示 C/C++ 的堆栈 |

- 从JDK 5起，java.lang.Thread类新增了一个getAllStackTraces()方法用于获取虚拟机中所有线程的StackTraceElement对象。

  - 使用这个方法可以通过简单的几行代码完成jstack的大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看线程堆栈，这也算是笔者的一个小经验。

##### 4.2.7 基础工具总结

- 基础工具：用于支持基本的程序创建和运行

  - | 名称         | 主要作用 |
    | ------------ | -------- |
    | appletviewer |          |
    | extcheck     |          |
    | jar          |          |
    | java         |          |
    | javac        |          |
    | javadoc      |          |
    | javah        |          |
    | javap        |          |
    | jlink        |          |
    | jdb          |          |
    | jdeps        |          |
    | jdeprscan    |          |

- 安全：用于程序签名、设置安全测试等

  - | 名称       | 主要作用 |
    | ---------- | -------- |
    | keytool    |          |
    | jarsigner  |          |
    | policytool |          |

- 国际化：用于创建本地语言文件

  - | 名称         | 主要作用 |
    | ------------ | -------- |
    | native2ascii |          |

- 远程方法调用：用于跨Web或网络的服务交互

  - | 名称        | 主要作用 |
    | ----------- | -------- |
    | rmic        |          |
    | rmiregistry |          |
    | rmid        |          |
    | serialver   |          |

- Java IDL与RMI-IIOP：在JDK 11中结束了十余年的CORBA支持，这些工具不再提供

  - | 名称       | 主要作用 |
    | ---------- | -------- |
    | tnameserv  |          |
    | idlj       |          |
    | orbd       |          |
    | servertool |          |

- 部署工具：用于程序打包、发布和部署

  - | 名称         | 主要作用 |
    | ------------ | -------- |
    | javapackager |          |
    | pack200      |          |
    | unpack200    |          |

- Java Web Start

  - | 名称   | 主要作用 |
    | ------ | -------- |
    | javaws |          |

- 性能监控和故障处理：用于监控分析Java虚拟机运行信息，排查问题

  - | 名称      | 主要作用 |
    | --------- | -------- |
    | jps       |          |
    | jstat     |          |
    | jstatd    |          |
    | jinfo     |          |
    | jmap      |          |
    | jhat      |          |
    | jstack    |          |
    | jhsdb     |          |
    | jsadebugd |          |
    | jcmd      |          |
    | jconsole  |          |
    | jmc       |          |
    | jvisualvm |          |

- WebService工具：与CORBA一起在JDK 11中被移除

  - | 名称      | 主要作用 |
    | --------- | -------- |
    | schemagen |          |
    | wsgen     |          |
    | wsimport  |          |
    | xjc       |          |

- REPL和脚本工具

  - | 名称       | 主要作用 |
    | ---------- | -------- |
    | jshell     |          |
    | jjs        |          |
    | jrunscript |          |

#### 4.3 可视化故障处理工具

- JDK中除了附带大量的命令行工具外，还提供了几个功能集成度更高的可视化工具，用户可以使用这些可视化工具以更加便捷的方式进行进程故障诊断和调试工作。
  - 这类工具主要包括JConsole、JHSDB、VisualVM和JMC四个。
    - 其中，JConsole是最古老，早在JDK 5时期就已经存在的虚拟机监控工具
    - 而JHSDB虽然名义上是JDK 9中才正式提供，但之前已经以sa-jdi.jar包里面的HSDB（可视化工具）和CLHSDB（命令行工具）的形式存在了很长一段时间。它们两个都是JDK的正式成员，随着JDK一同发布，无须独立下载，使用也是完全免费的。
    - VisualVM在JDK 6 Update 7中首次发布，直到JRockit Mission Control与OracleJDK的融合工作完成之前，它都曾是Oracle主力推动的多合一故障处理工具，现在它已经从OracleJDK中分离出来，成为一个独立发展的开源项目。VisualVM已不是JDK中的正式成员，但仍是可以免费下载、使用的。
    - Java Mission Control，曾经是大名鼎鼎的来自BEA公司的图形化诊断工具，随着BEA公司被Oracle收购，它便被融合进OracleJDK之中。在JDK 7 Update 40时开始随JDK一起发布，后来Java SEAdvanced产品线建立，Oracle明确区分了Oracle OpenJDK和OracleJDK的差别，JMC从JDK 11开始又被移除出JDK。
      - 虽然在2018年Oracle将JMC开源并交付给OpenJDK组织进行管理，但开源并不意味着免费使用，JMC需要与HotSpot内部的“飞行记录仪”（Java Flight Recorder，JFR）配合才能工作，而在JDK 11以前，JFR的开启必须解锁OracleJDK的商业特性支持（使用JCMD的 VM.unlock_commercial_features或启动时加入-XX:+UnlockCommercialFeatures参数），所以这项功能在生产环境中仍然是需要付费才能使用的商业特性。

##### 4.3.1 JHSDB：基于服务性代理的调试工具

##### 4.3.2 JConsole：Java 监视和管理控制台

##### 4.3.3 VisualVM：多合一故障处理工具

- VisualVM（All-in-One Java Troubleshooting Tool）是功能最强大的运行监视和故障处理程序之一，曾经在很长一段时间内是Oracle官方主力发展的虚拟机故障处理工具。
  - Oracle曾在VisualVM的软件说明中写上了“All-in-One”的字样，预示着它除了常规的运行监视、故障处理外，还将提供其他方面的能力，譬如性能分析（Profiling）。
  - 而且相比第三方工具，VisualVM还有一个很大的优点：不需要被监视的程序基于特殊Agent去运行，因此它的通用性很强，对应用程序实际性能的影响也较小，使得它可以直接应用在生产环境中。
- 首次启动VisualVM后，读者先不必着急找应用程序进行监测，初始状态下的VisualVM并没有加载任何插件，虽然基本的监视、线程面板的功能主程序都以默认插件的形式提供，但是如果不在VisualVM上装任何扩展插件，就相当于放弃它最精华的功能，和没有安装任何应用软件的操作系统差不多。
- 挑选几个有特色的功能和插件进行简要介绍
  - 生成、浏览堆转储快照
    - 在VisualVM中生成堆转储快照文件有两种方式，可以执行下列任一操作：
      - 在“应用程序”窗口中右键单击应用程序节点，然后选择“堆Dump”。
      - 在“应用程序”窗口中双击应用程序节点以打开应用程序标签，然后在“监视”标签中单击“堆Dump”。
    - 生成堆转储快照文件之后，应用程序页签会在该堆的应用程序下增加一个以[heap-dump]开头的子节点，并且在主页签中打开该转储快照
  - 分析程序性能
    - 在Profiler页签中，VisualVM提供了程序运行期间方法级的处理器执行时间分析以及内存分析。
    - 做Profiling分析肯定会对程序运行性能有比较大的影响，所以一般不在生产环境使用这项功能，或者改用JMC来完成，JMC的Profiling能力更强，对应用的影响非常轻微。
  - BTrace动态日志跟踪
    - BTrace 是一个很神奇的VisualVM插件，它本身也是一个可运行的独立程序。
    - BTrace的作用是在不中断目标程序运行的前提下，通过HotSpot虚拟机的Instrument功能动态加入原本并不存在的调试代码。
    - BTrace的用途很广泛，打印调用堆栈、参数、返回值只是它最基础的使用形式，在它的网站上有使用BTrace进行性能监视、定位连接泄漏、内存泄漏、解决多线程竞争问题等的使用案例，有兴趣的读者可以去网上了解相关信息。
    - BTrace能够实现动态修改程序行为，是因为它是基于Java虚拟机的Instrument开发的。
      - Instrument是Java虚拟机工具接口（Java Virtual Machine Tool Interface，JVMTI）的重要组件，提供了一套代理（Agent）机制，使得第三方工具程序可以以代理的方式访问和修改Java虚拟机内部的数据。阿里巴巴开源的诊断工具Arthas也通过Instrument实现了与BTrace类似的功能。

##### 4.3.4 Java Mission Control：可持续在线的监控工具

#### 4.4 HotSpot 虚拟机插件及工具

- HotSpot的研发过程中，开发团队曾经编写（或者收集）过不少虚拟机的插件和辅助工具，它们存放在HotSpot源码hotspot/src/share/tools目录下，包括（含曾经有过但新版本中已被移除的）：
  - Ideal Graph Visualizer：用于可视化展示C2即时编译器是如何将字节码转化为理想图，然后转化为机器码的。
  - Client Compiler Visualizer [1]：用于查看C1即时编译器生成高级中间表示（HIR），转换成低级中间表示（LIR）和做物理寄存器分配的过程。
  - MakeDeps：帮助处理HotSpot的编译依赖的工具。
  - Project Creator：帮忙生成Visual Studio的.project文件的工具。
  - LogCompilation：将-XX:+LogCompilation输出的日志整理成更容易阅读的格式的工具。
  - HSDIS：即时编译器的反汇编插件。
- 关于Client Compiler Visualizer 和 Ideal Graph Visualizer，在本书第11章会有专门的使用介绍
- 而 Project Creator、LogCompilation、MakeDeps 这三个工具对本书的讲解和实验帮助有限
- 最后一个 HSDIS 是学习、实践本书第四部分“程序编译与代码优化”的有力辅助工具，借本章讲解虚拟机工具的机会，简要介绍其使用方法。
  - HSDIS是一个被官方推荐的HotSpot虚拟机即时编译代码的反汇编插件，它包含在HotSpot虚拟机的源码当中
  - HSDIS插件的作用是让HotSpot的-XX：+PrintAssembly指令调用它来把即时编译器动态生成的本地代码还原为汇编代码输出，同时还会自动产生大量非常有价值的注释，这样我们就可以通过输出的汇编代码来从最本质的角度分析问题。
  - JITWatch 是HSDIS经常搭配使用的可视化的编译日志分析工具

## 调优分析实战

### 具体问题

- 高并发后台怎么优化GC，我主要是说了调整eden和surival的比例啥啥啥的
- GC优化，程序中应该如何优化？
- 有没有做过 JVM 调优？
- jvm参数调优怎么做的
  我回答的是用的微服务部署，有的微服务访问很频繁的，就多给他设置一些内存，比如网关，一些不怎么用到的，可以设置稍微小一点。然后他说：你们这就是全凭感觉瞎设置呗
- jvm调优做过吗，有哪些参数可以调，具体怎么调
- JVM 调优过程？怎么发现 JVM 的问题的？怎么做预警处理？
- JMV 优化过程，效果。为什么要升级垃圾收集器？
- jvm调优
- 加分项，美团面试的时候一面和面试官讨论了调优的一些细节 --xmns啥的
- 如果一个系统要进行调优你会考虑哪些方面；答:jvm(非常详细的展开），如果有数据库查询可以用索引等等。。。
- 聊了这么久虚拟机，你调过优吗？怎么调的。。。一脸懵逼
- 有没有jvm调优经验（没有）
- GC 调优
- CPU 占用率达到 100% 可能由什么造成
- jvm怎么调优，什么看gc的日志之类的
- 项目中关于 FULL GC 调优的细节
- cpu标高100%什么原因？为什么会出现死循环？
- 场景题：cpu 打满且频繁 full GC，怎么解决？
- JVM 调优经验 说一下做了什么？
- JVM 的常用参数有哪些
- JVM 调优常用的手段是什么
- jvm 调优你如何做的？现象->排查过程->解决方式->不同解决方案的对比与选择
- 有 jvm 调优的经验吗？实际工作中遇到过内存相关的问题吗？用过哪些堆栈工具调试？

### 思考方向

#### 5.2 案例分析

##### 5.2.1 大内存硬件上的程序部署策略

- 案例

  - 一个15万PV/日左右的在线文档类型网站最近更换了硬件系统
    - 服务器的硬件为四路志强处理器、16GB物理内存，操作系统为64位CentOS 5.4，Resin作为Web服务器。
    - 整个服务器暂时没有部署别的应用，所有硬件资源都可以提供给这访问量并不算太大的文档网站使用。
  - 软件版本选用的是64位的JDK 5，管理员启用了一个虚拟机实例，使用-Xmx和-Xms参数将Java堆大小固定在12GB。
  - 使用一段时间后发现服务器的运行效果十分不理想，网站经常不定期出现长时间失去响应。

- 原因

  - 监控服务器运行状况后发现网站失去响应是由垃圾收集停顿所导致的

    - 在该系统软硬件条件下，HotSpot虚拟机是以服务端模式运行，默认使用的是吞吐量优先收集器，回收12GB的Java堆，一次FullGC的停顿时间就高达14秒。

  - 由于程序设计的原因，访问文档时会把文档从磁盘提取到内存中，导致内存中出现很多由文档序列化产生的大对象，这些大对象大多在分配时就直接进入了老年代，没有在Minor GC中被清理掉。

  - 每一款Java虚拟机中的每一款垃圾收集器都有自己的应用目标与最适合的应用场景，如果在特定场景中选择了不恰当的配置和部署方式，自然会事倍功半。

    - 目前单体应用在较大内存的硬件上主要的部署方式有两种：
      - 通过一个单独的Java虚拟机实例来管理大量的Java堆内存
      - 同时使用若干个Java虚拟机，建立逻辑集群来利用硬件资源。

    - 此案例中的管理员采用了第一种部署方式。
      - 对于用户交互性强、对停顿时间敏感、内存又较大的系统，并不是一定要使用Shenandoah、ZGC这些明确以控制延迟为目标的垃圾收集器才能解决问题
      - 使用Parallel Scavenge/Old收集器，并且给Java虚拟机分配较大的堆内存也是有很多运行得很成功的案例的，但前提是必须把应用的Full GC频率控制得足够低，至少要低到不会在用户使用过程中发生，譬如十几个小时乃至一整天都不出现一次Full GC
        - 这样可以通过在深夜执行定时任务的方式触发Full GC甚至是自动重启应用服务器来保持内存可用空间在一个稳定的水平。
        - 控制Full GC频率的关键是老年代的相对稳定，这主要取决于应用中绝大多数对象能否符合“朝生夕灭”的原则，即大多数对象的生存时间不应当太长，尤其是不能有成批量的、长生存时间的大对象产生，这样才能保障老年代空间的稳定。
      - 除此之外，如果读者计划使用单个Java虚拟机实例来管理大内存，还需要考虑下面可能面临的问题：
        - 回收大块堆内存而导致的长时间停顿，自从G1收集器的出现，增量回收得到比较好的应用，这个问题有所缓解，但要到ZGC和Shenandoah收集器成熟之后才得到相对彻底地解决。
        - 大内存必须有64位Java虚拟机的支持，但由于压缩指针、处理器缓存行容量（Cache Line）等因素，64位虚拟机的性能测试结果普遍略低于相同版本的32位虚拟机。
        - 必须保证应用程序足够稳定，因为这种大型单体应用要是发生了堆内存溢出，几乎无法产生堆转储快照（要产生十几GB乃至更大的快照文件），哪怕成功生成了快照也难以进行分析；如果确实出了问题要进行诊断，可能就必须应用JMC这种能够在生产环境中进行的运维工具。
        - 相同的程序在64位虚拟机中消耗的内存一般比32位虚拟机要大，这是由于指针膨胀，以及数据类型对齐补白等因素导致的，可以开启（默认即开启）压缩指针功能来缓解。
    - 鉴于上述这些问题，现阶段仍然有一些系统管理员选择第二种方式来部署应用：同时使用若干个虚拟机建立逻辑集群来利用硬件资源。

##### 5.2.2 集群间同步导致的内存溢出

##### 5.2.3 堆外内存导致的溢出错误

##### 5.2.4 外部命令导致系统缓慢

##### 5.2.5 服务器虚拟机进程崩溃

##### 5.2.6 不恰当数据结构导致内存占用过大

##### 5.2.7 由 Windows 虚拟内存导致的长时间停顿

##### 5.2.8 由安全点导致长时间停顿

#### 5.3 实战：Eclipse 运行速度调优

##### 5.3.1 调优前的程序运行状态

##### 5.3.2 升级 JDK 版本的性能变化及兼容问题

##### 5.3.3 编译时间和类加载时间的优化

##### 5.3.4 调整内存设置控制垃圾收集频率

##### 5.3.5 选择收集器降低延迟

## 虚拟机执行子系统（Class 文件、字节码、类加载机制）

### 具体问题

- 类加载机制
- ClassLoader原理和应用
- Java中有个String类，如果我们自己写一个java.lang.String类，会出现问题吗 (参考《深入理解Java虚拟机》第7章 虚拟机类加载机制，主要讲了类加载器的种类和双亲委派模型)
- 类加载过程？类隔离了解过吗？
- 多态和重载的底层实现原理，字节码层面的了解过吗？
- Java的类加载过程、机制，每个过程的作用
- JAVA类加载过程（加载（类加载器问题） 验证 准备 解析 初始化）
- 类加载器
- 双亲委任
- 如果发生了冲突，会出现什么情况-- 编译不报错，运行调用bootstrapclassloader加载rt.jar中的类
- JVM 是怎么判断两个类相等
- 类加载器
- 类加载过程
- 双亲委派模型
- JVM 的类加载过程。谈到了双亲委派模型。
- 怎么打破双亲委派模型。自己实现一个类加载器，怎么打破类加载器？问具体的实现细节。
- 类加载器都有哪些 双亲委派机制
- 类加载过程？
- 类加载的过程是什么，每个过程具体做到了什么事
- 双亲委派模型的好处
- 双亲委派机制，和类加载器，双亲委派机制的源码看看？（问比较多次了）
- java 对象的内存结构？标记字是做什么的？
- 问 JVM：双亲委派模型的理解，有没有在项目中实践过自定义类加载器。
- 双亲委派模型的类加载机制？
- 同一个 JVM 能不能加载全县定性类名是相同的一个类？能不能加载同一个类？
- 简述双亲委派模型
- 简述类加载过程
- Java 的类加载过程；
- 介绍一下双亲委派机制；
- 为什么双亲委派机制能够避免类的重复加载呢？
- 如何自定义一个与 Java 核心方法同名同参数的函数呢？
- 双亲委派机制的双亲是那双亲呢？
- 自定义类加载的过程是什么？
- 类加载机制

### 思考方向

#### 6、类文件结构

##### 6.2 无关性的基石

##### 6.3 Class 类文件的结构

- 6.3.1 魔数与 Class 文件的版本
- 6.3.2 常量池
  - 常量池中主要存放两大类常量：
    - 字面量（Literal）
      - 字面量比较接近于Java语言层面的常量概念，如文本字符串、被声明为final的常量值等。
    - 符号引用（Symbolic References）。
      - 而符号引用则属于编译原理方面的概念，主要包括下面几类常量：
        - 被模块导出或者开放的包（Package）
        - 类和接口的全限定名（Fully Qualified Name）
        - 字段的名称和描述符（Descriptor）
        - 方法的名称和描述符
        - 方法句柄和方法类型（Method Handle、Method Type、Invoke Dynamic）
        - 动态调用点和动态常量（Dynamically-Computed Call Site、Dynamically-Computed Constant）
- 6.3.3 访问标志
  - ACC_PUBLIC
  - ACC_FINAL
  - ACC_SUPER
  - ACC_INTERFACE
  - ACC_ABSTRACT
  - ACC_SYNTHETIC
  - ACC_ANNOTATION
  - ACC_ENUM
  - ACC_MODULE
- 6.3.4 类索引、父类索引与接口索引集合
- 6.3.5 字段表集合
- 6.3.6 方法表集合
  - 方法表的结构如同字段表一样，依次包括访问标志（access_flags）、名称索引（name_index）、描述符索引（descriptor_index）、属性表集合（attributes）几项
    - 因为volatile关键字和transient关键字不能修饰方法，所以方法表的访问标志中没有了ACC_VOLATILE标志和ACC_TRANSIENT标志。
    - 与之相对，synchronized、native、strictfp和abstract关键字可以修饰方法，方法表的访问标志中也相应地增加了ACC_SYNCHRONIZED、ACC_NATIVE、ACC_STRICTFP和ACC_ABSTRACT标志。
- 6.3.7 属性表集合

##### 6.4 字节码指令简介

- 6.4.1 字节码与数据类型
  - 对于大部分与数据类型相关的字节码指令，它们的操作码助记符中都有特殊的字符来表明专门为哪种数据类型服务：i代表对int类型的数据操作，l代表long，s代表short，b代表byte，c代表char，f代表float，d代表double，a代表reference。
  - 大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的对int类型作为运算类型（Computational Type）来进行的。
- 6.4.2 加载和存储指令
  - 这类指令包括：
    - 将一个局部变量加载到操作栈：`iload`、`iload_<n>`、`lload`、`lload_<n>`、`fload`、`fload_<n>`、`dload`、`dload_<n>`、`aload`、`aload_<n>`
    - 将一个数值从操作数栈存储到局部变量表：`istore`、`istore_<n>`、`lstore`、`lstore_<n>`、`fstore`、`fstore_<n>`、`dstore`、`dstore_<n>`、`astore`、`astore_<n>`
    - 将一个常量加载到操作数栈：`bipush`、`sipush`、`ldc`、`ldc_w`、`ldc2_w`、`aconst_null`、`iconst_m1`、`iconst_<i>`、`lconst_<l>`、`fconst_<f>`、`dconst_<d>`
    - 扩充局部变量表的访问索引的指令：`wide`
  - 上面所列举的指令助记符中，有一部分是以尖括号结尾的（例如 `iload_<n>`），这些指令助记符实际上代表了一组指令（例如 `iload_<n>`，它代表了iload_0、iload_1、iload_2和iload_3这几条指令）。
- 6.4.3 运算指令
  - 所有的算术指令包括：
    - 加法指令：iadd、ladd、fadd、dadd
    - 减法指令：isub、lsub、fsub、dsub
    - 乘法指令：imul、lmul、fmul、dmul
    - 除法指令：idiv、ldiv、fdiv、ddiv
    - 求余指令：irem、lrem、frem、drem
    - 取反指令：ineg、lneg、fneg、dneg
    - 位移指令：ishl、ishr、iushr、lshl、lshr、lushr
    - 按位或指令：ior、lor
    - 按位与指令：iand、land
    - 按位异或指令：ixor、lxor
    - 局部变量自增指令：iinc
    - 比较指令：dcmpg、dcmpl、fcmpg、fcmpl、lcmp
- 6.4.4 类型转换指令
  - Java虚拟机直接支持（即转换时无须显式的转换指令）以下数值类型的宽化类型转换（WideningNumeric Conversion，即小范围类型向大范围类型的安全转换）：
    - int类型到long、float或者double类型
    - long类型到float、double类型
    - float类型到double类型
  - 与之相对的，处理窄化类型转换（Narrowing Numeric Conversion）时，就必须显式地使用转换指令来完成
    - 这些转换指令包括i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f。
- 6.4.5 对象创建与访问指令
  - 这些指令包括：
    - 创建类实例的指令：new
    - 创建数组的指令：newarray、anewarray、multianewarray
    - 访问类字段（static字段，或者称为类变量）和实例字段（非static字段，或者称为实例变量）的指令：getfield、putfield、getstatic、putstatic
    - 把一个数组元素加载到操作数栈的指令：baload、caload、saload、iaload、laload、faload、daload、aaload
    - 将一个操作数栈的值储存到数组元素中的指令：bastore、castore、sastore、iastore、fastore、dastore、aastore
    - 取数组长度的指令：arraylength
    - 检查类实例类型的指令：instanceof、checkcast
- 6.4.6 操作数栈管理指令
  - 包括：
    - 将操作数栈的栈顶一个或两个元素出栈：pop、pop2
    - 复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2
    - 将栈最顶端的两个数值互换：swap
- 6.4.7 控制转移指令
  - 控制转移指令包括：
    - 条件分支：ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_icmpge、if_acmpeq和if_acmpne
    - 复合条件分支：tableswitch、lookupswitch
    - 无条件分支：goto、goto_w、jsr、jsr_w、ret
- 6.4.8 方法调用和返回指令
  - 方法调用（分派、执行过程）将在第8章具体讲解，这里仅列举以下五条指令用于方法调用：
    - invokevirtual指令：用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。
    - invokeinterface指令：用于调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。
    - invokespecial指令：用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法。
    - invokestatic指令：用于调用类静态方法（static方法）。
    - invokedynamic指令：用于在运行时动态解析出调用点限定符所引用的方法。并执行该方法。前面四条调用指令的分派逻辑都固化在Java虚拟机内部，用户无法改变，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。
  - 方法返回指令是根据返回值的类型区分的
    - 包括 ireturn（当返回值是boolean、byte、char、short和int类型时使用）、lreturn、freturn、dreturn和areturn，另外还有一条return指令供声明为void的方法、实例初始化方法、类和接口的类初始化方法使用。
- 6.4.9 异常处理指令
  - 在Java程序中显式抛出异常的操作（throw语句）都由athrow指令来实现
  - 除了用throw语句显式抛出异常的情况之外，《Java虚拟机规范》还规定了许多运行时异常会在其他Java虚拟机指令检测到异常状况时自动抛出。例如前面介绍整数运算中，当除数为零时，虚拟机会在idiv或ldiv指令中抛出ArithmeticException异常。
  - 而在Java虚拟机中，处理异常（catch语句）不是由字节码指令来实现的（很久之前曾经使用jsr 和 ret指令来实现，现在已经不用了），而是采用异常表来完成。
- 6.4.10 同步指令
  - Java虚拟机可以支持方法级的同步和方法内部一段指令序列的同步，这两种同步结构都是使用管程（Monitor，更常见的是直接将它称为“锁”）来实现的。
    - 方法级的同步是隐式的，无须通过字节码指令来控制，它实现在方法调用和返回操作之中。虚拟机可以从方法常量池中的方法表结构中的ACC_SYNCHRONIZED访问标志得知一个方法是否被声明为同步方法。
    - 同步一段指令集序列通常是由Java语言中的synchronized语句块来表示的，Java虚拟机的指令集中有monitorenter和monitorexit两条指令来支持synchronized关键字的语义，正确实现synchronized关键字需要Javac编译器与Java虚拟机两者共同协作支持

##### 6.5 公有设计，私有实现

##### 6.6 Class 文件结构的发展

#### 7、虚拟机类加载机制

##### 7.1 概述

- Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这个过程被称作虚拟机的类加载机制。
- 与那些在编译时需要进行连接的语言不同，在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成的
  - 这种策略让Java语言进行提前编译会面临额外的困难，也会让类加载时稍微增加一些性能开销
  - 但是却为Java应用提供了极高的扩展性和灵活性，Java天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的。
    - 例如，编写一个面向接口的应用程序，可以等到运行时再指定其实际的实现类，用户可以通过Java预置的或自定义类加载器，让某个本地的应用程序在运行时从网络或其他地方上加载一个二进制流作为其程序代码的一部分。

##### 7.2 类加载的时机

- 一个类型从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期将会经历加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）七个阶段
  - 其中验证、准备、解析三个部分统称为连接（Linking）
  - 加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类型的加载过程必须按照这种顺序按部就班地开始
    - 请注意，这里笔者写的是按部就班地“开始”，而不是按部就班地“进行”或按部就班地“完成”，强调这点是因为这些阶段通常都是互相交叉地混合进行的，会在一个阶段执行的过程中调用、激活另一个阶段。
  - 而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定）。
- 关于在什么情况下需要开始类加载过程的第一个阶段“加载”，《Java虚拟机规范》中并没有进行强制约束，这点可以交给虚拟机的具体实现来自由把握
- 但是对于初始化阶段，《Java虚拟机规范》则是严格规定了**有且只有**六种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）：这六种场景中的行为称为**对一个类型进行主动引用**。
  - 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果类型没有进行过初始化，则需要先触发其初始化阶段。
    - 能够生成这四条指令的典型Java代码场景有：
      - 使用new关键字实例化对象的时候。
      - 读取或设置一个类型的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候。
      - 调用一个类型的静态方法的时候。
  - 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。
  - 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。
  - 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。
  - 当使用JDK 7新加入的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。
  - 当一个接口中定义了JDK 8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。

##### 7.3 类加载的过程

###### 7.3.1 加载

- 在加载阶段，Java虚拟机需要完成以下三件事情：
  - 通过一个类的全限定名来获取定义此类的二进制字节流。
    - 它并没有指明二进制字节流必须得从某个Class文件中获取，确切地说是根本没有指明要从哪里获取、如何获取。许多举足轻重的Java技术都建立在这一基础之上，例如：
      - 从ZIP压缩包中读取，这很常见，最终成为日后JAR、EAR、WAR格式的基础。
      - 从网络中获取，这种场景最典型的应用就是Web Applet。
      - 运行时计算生成，这种场景使用得最多的就是动态代理技术，在java.lang.reflect.Proxy中，就是用了ProxyGenerator.generateProxyClass()来为特定接口生成形式为“*$Proxy”的代理类的二进制字节流。
      - 由其他文件生成，典型场景是JSP应用，由JSP文件生成对应的Class文件。
      - 从数据库中读取，这种场景相对少见些，例如有些中间件服务器（如SAP Netweaver）可以选择把程序安装到数据库中来完成程序代码在集群间的分发。
      - 可以从加密文件中获取，这是典型的防Class文件被反编译的保护措施，通过加载时解密Class文件来保障程序运行逻辑不被窥探。
  - 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
  - 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。
- 相对于类加载过程的其他阶段，非数组类型的加载阶段（准确地说，是加载阶段中获取类的二进制字节流的动作）是开发人员可控性最强的阶段。
  - 加载阶段既可以使用Java虚拟机里内置的引导类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员通过定义自己的类加载器去控制字节流的获取方式（重写一个类加载器的findClass()或loadClass()方法），实现根据自己的想法来赋予应用程序获取运行代码的动态性。
- 对于数组类而言，情况就有所不同，数组类本身不通过类加载器创建，它是由Java虚拟机直接在内存中动态构造出来的。但数组类与类加载器仍然有很密切的关系，因为数组类的元素类型（ElementType，指的是数组去掉所有维度的类型）最终还是要靠类加载器来完成加载
  - 一个数组类（下面简称为C）创建过程遵循以下规则：
    - 如果数组的组件类型（Component Type，指的是数组去掉一个维度的类型，注意和前面的元素类型区分开来）是引用类型，那就递归采用本节中定义的加载过程去加载这个组件类型，数组C将被标识在加载该组件类型的类加载器的类名称空间上（这点很重要，在7.4节会介绍，一个类型必须与类加载器一起确定唯一性）。
    - 如果数组的组件类型不是引用类型（例如int[]数组的组件类型为int），Java虚拟机将会把数组C标记为与引导类加载器关联。
    - 数组类的可访问性与它的组件类型的可访问性一致，如果组件类型不是引用类型，它的数组类的可访问性将默认为public，可被所有的类和接口访问到。
  - 加载阶段结束后，Java虚拟机外部的二进制字节流就按照虚拟机所设定的格式存储在方法区之中了，方法区中的数据存储格式完全由虚拟机实现自行定义
- 加载阶段与连接阶段的部分动作（如一部分字节码文件格式验证动作）是交叉进行的，加载阶段尚未完成，连接阶段可能已经开始，但这些夹在加载阶段之中进行的动作，仍然属于连接阶段的一部分，这两个阶段的开始时间仍然保持着固定的先后顺序。

###### 7.3.2 验证

- 验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中包含的信息符合《Java虚拟机规范》的全部约束要求，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。
- 验证阶段大致上会完成下面四个阶段的检验动作
  - 文件格式验证
    - 第一阶段要验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理
    - 这一阶段可能包括下面这些验证点：
      - 是否以魔数0xCAFEBABE开头。
      - 主、次版本号是否在当前Java虚拟机接受范围之内。
      - 常量池的常量中是否有不被支持的常量类型（检查常量tag标志）。
      - 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。
      - CONSTANT_Utf8_info型的常量中是否有不符合UTF-8编码的数据。
      - Class文件中各个部分及文件本身是否有被删除的或附加的其他信息。
      - ……
    - 该验证阶段的主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。
    - 这阶段的验证是基于二进制字节流进行的，只有通过了这个阶段的验证之后，这段字节流才被允许进入Java虚拟机内存的方法区中进行存储
      - 所以后面的三个验证阶段全部是基于方法区的存储结构上进行的，不会再直接读取、操作字节流了。
  - 元数据验证
    - 第二阶段是对字节码描述的信息进行语义分析，以保证其描述的信息符合《Java语言规范》的要求
    - 这个阶段可能包括的验证点如下：
      - 这个类是否有父类（除了java.lang.Object之外，所有的类都应当有父类）。
      - 这个类的父类是否继承了不允许被继承的类（被final修饰的类）。
      - 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法。
      - 类中的字段、方法是否与父类产生矛盾（例如覆盖了父类的final字段，或者出现不符合规则的方法重载，例如方法参数都一致，但返回值类型却不同等）。
      - ……
    - 第二阶段的主要目的是对类的元数据信息进行语义校验，保证不存在与《Java语言规范》定义相悖的元数据信息。
  - 字节码验证
    - 第三阶段是整个验证过程中最复杂的一个阶段，主要目的是通过数据流分析和控制流分析，确定程序语义是合法的、符合逻辑的。
    - 这阶段就要对类的方法体（Class文件中的Code属性）进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的行为，例如：
      - 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，例如不会出现类似于“在操作栈放置了一个int类型的数据，使用时却按long类型来加载入本地变量表中”这样的情况。
      - 保证任何跳转指令都不会跳转到方法体以外的字节码指令上。
      - 保证方法体中的类型转换总是有效的，例如可以把一个子类对象赋值给父类数据类型，这是安全的，但是把父类对象赋值给子类数据类型，甚至把对象赋值给与它毫无继承关系、完全不相干的一个数据类型，则是危险和不合法的。
      - ……
    - 由于数据流分析和控制流分析的高度复杂性，Java虚拟机的设计团队为了避免过多的执行时间消耗在字节码验证阶段中，在JDK 6之后的Javac编译器和Java虚拟机里进行了一项联合优化，把尽可能多的校验辅助措施挪到Javac编译器里进行。
      - 具体做法是给方法体Code属性的属性表中新增加了一项名为“StackMapTable”的新属性，这项属性描述了方法体所有的基本块（Basic Block，指按照控制流拆分的代码块）开始时本地变量表和操作栈应有的状态，在字节码验证期间，Java虚拟机就不需要根据程序推导这些状态的合法性，只需要检查StackMapTable属性中的记录是否合法即可。
      - 这样就将字节码验证的类型推导转变为类型检查，从而节省了大量校验时间。
      - 而到了 JDK 7 之后，尽管虚拟机中仍然保留着类型推导验证器的代码，但是对于主版本号大于50（对应JDK6）的Class文件，使用类型检查来完成数据流分析校验则是唯一的选择，不允许再退回到原来的类型推导的校验方式。
  - 符号引用验证
    - 最后一个阶段的校验行为发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段——解析阶段中发生。
    - 符号引用验证可以看作是对类自身以外（常量池中的各种符号引用）的各类信息进行匹配性校验，通俗来说就是，该类是否缺少或者被禁止访问它依赖的某些外部类、方法、字段等资源。
    - 本阶段通常需要校验下列内容：
      - 符号引用中通过字符串描述的全限定名是否能找到对应的类。
      - 在指定类中是否存在符合方法的字段描述符及简单名称所描述的方法和字段。
      - 符号引用中的类、字段、方法的可访问性（private、protected、public、`<package>`）是否可被当前类访问。
    - 符号引用验证的主要目的是确保解析行为能正常执行
      - 如果无法通过符号引用验证，Java虚拟机将会抛出一个java.lang.IncompatibleClassChangeError的子类异常，典型的如：java.lang.IllegalAccessError、java.lang.NoSuchFieldError、java.lang.NoSuchMethodError等。
- 验证阶段对于虚拟机的类加载机制来说，是一个非常重要的、但却不是必须要执行的阶段，因为验证阶段只有通过或者不通过的差别，只要通过了验证，其后就对程序运行期没有任何影响了。
  - 如果程序运行的全部代码（包括自己编写的、第三方包中的、从外部加载的、动态生成的等所有代码）都已经被反复使用和验证过，在生产环境的实施阶段就可以考虑使用 -Xverify:none 参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。

###### 7.3.3 准备

- 准备阶段是正式为类中定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值的阶段
  - 从概念上讲，这些变量所使用的内存都应当在方法区中进行分配，但必须注意到方法区本身是一个逻辑上的区域
    - 在JDK 7及之前，HotSpot使用永久代来实现方法区时，实现是完全符合这种逻辑概念的；
    - 而在JDK 8及之后，类变量则会随着Class对象一起存放在Java堆中，这时候“类变量在方法区”就完全是一种对逻辑概念的表述了
- 关于准备阶段，还有两个容易产生混淆的概念笔者需要着重强调
  - 首先是这时候进行内存分配的仅包括类变量，而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中
  - 其次是这里所说的初始值“通常情况”下是数据类型的零值
    - “特殊情况”：如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量值就会被初始化为ConstantValue属性所指定的初始值

###### 7.3.4 解析

- 解析阶段是Java虚拟机将常量池内的符号引用替换为直接引用的过程
  - 符号引用在第6章讲解 Class 文件格式的时候已经出现过多次，在Class文件中它以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现
  - 那解析阶段中所说的直接引用与符号引用又有什么关联呢？
    - 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。
    - 直接引用（Direct References）：直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄。
- 《Java虚拟机规范》之中并未规定解析阶段发生的具体时间，只要求了在执行ane-warray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invoke-special、invokestatic、invokevirtual、ldc、ldc_w、ldc2_w、multianewarray、new、putfield和putstatic这17个用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析。
- 对同一个符号引用进行多次解析请求是很常见的事情，**除 invokedynamic 指令以外**，虚拟机实现可以**对第一次解析的结果进行缓存**，譬如在运行时直接引用常量池中的记录，并把常量标识为已解析状态，从而避免解析动作重复进行。
  - 不过对于invokedynamic指令，上面的规则就不成立了。当碰到某个前面已经由invokedynamic指令触发过解析的符号引用时，并不意味着这个解析结果对于其他invokedynamic指令也同样生效。
  - 因为 invokedynamic 指令的目的本来就是用于动态语言支持[1]，它对应的引用称为“动态调用点限定符（Dynamically-Computed Call Site Specifier）”，这里“动态”的含义是指必须等到程序实际运行到这条指令时，解析动作才能进行。
  - 相对地，其余可触发解析的指令都是“静态”的，可以在刚刚完成加载阶段，还没有开始执行代码时就提前进行解析。
- 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符这7类符号引用进行
  - 分别对应于常量池的CONSTANT_Class_info、CON-STANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info、CONSTANT_MethodType_info、CONSTANT_MethodHandle_info、CONSTANT_Dyna-mic_info和CONSTANT_InvokeDynamic_info 8种常量类型
  - 1.类或接口的解析
  - 2.字段解析
  - 3.方法解析
  - 4.接口方法解析

###### 7.3.5 初始化

- 类的初始化阶段是类加载过程的最后一个步骤，之前介绍的几个类加载的动作里，除了在加载阶段用户应用程序可以通过自定义类加载器的方式局部参与外，其余动作都完全由Java虚拟机来主导控制。
  - 直到初始化阶段，Java虚拟机才真正开始执行类中编写的Java程序代码，将主导权移交给应用程序。
- 进行准备阶段时，变量已经赋过一次系统要求的初始零值，而在初始化阶段，则会根据程序员通过程序编码制定的主观计划去初始化类变量和其他资源。
  - 我们也可以从另外一种更直接的形式来表达：初始化阶段就是执行类构造器 `<clinit>()` 方法的过程。
  - `<clinit>()` 并不是程序员在Java代码中直接编写的方法，它是Javac编译器的自动生成物
- `<clinit>()`
  - `<clinit>()` 方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问
  - `<clinit>()` 方法与类的构造函数（即在虚拟机视角中的实例构造器 `<init>()` 方法）不同，它不需要显式地调用父类构造器，Java虚拟机会保证在子类的 `<clinit>()` 方法执行前，父类的 `<clinit>()` 方法已经执行完毕。因此在Java虚拟机中第一个被执行的 `<clinit>()` 方法的类型肯定是 java.lang.Object。
  - 由于父类的 `<clinit>()` 方法先执行，也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作
  - `<clinit>()` 方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成 `<clinit>()` 方法。
  - 接口中不能使用静态语句块，但仍然有变量初始化的赋值操作，因此接口与类一样都会生成 `<clinit>()` 方法。但接口与类不同的是，执行接口的 `<clinit>()` 方法不需要先执行父接口的 `<clinit>()` 方法，因为只有当父接口中定义的变量被使用时，父接口才会被初始化。此外，接口的实现类在初始化时也一样不会执行接口的  `<clinit>()` 方法。
  - Java 虚拟机必须保证一个类的 `<clinit>()` 方法在多线程环境中被正确地加锁同步，如果多个线程同时去初始化一个类，那么只会有其中一个线程去执行这个类的 `<clinit>()` 方法，其他线程都需要阻塞等待，直到活动线程执行完毕 `<clinit>()` 方法。如果在一个类的 `<clinit>()` 方法中有耗时很长的操作，那就可能造成多个进程阻塞，在实际应用中这种阻塞往往是很隐蔽的。

##### 7.4 类加载器

- Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为**“类加载器”（Class Loader）**。
  - 类加载器可以说是Java语言的一项创新，它是早期Java语言能够快速流行的重要原因之一。
  - 类加载器最初是为了满足Java Applet的需求而设计出来的，在今天用在浏览器上的Java Applet技术基本上已经被淘汰，但类加载器却在**类层次划分、OSGi、程序热部署、代码加密**等领域大放异彩，成为Java技术体系中一块重要的基石，可谓是失之桑榆，收之东隅。

###### 7.4.1 类与类加载器

- 类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远超类加载阶段。
- 对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。
  - 这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。
  - 这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括了使用instanceof关键字做对象所属关系判定等各种情况。

###### 7.4.2 双亲委派模型

- 站在Java虚拟机的角度来看，只存在两种不同的类加载器：

  - 一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现[1]，是虚拟机自身的一部分；
  - 另外一种就是其他所有的类加载器，这些类加载器都由Java语言实现，独立存在于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。

- 站在Java开发人员的角度来看，类加载器就应当划分得更细致一些。自 JDK 1.2 以来，Java 一直保持着三层类加载器、双亲委派的类加载架构，尽管这套架构在Java模块化系统出现后有了一些调整变动，但依然未改变其主体结构，我们将在7.5节中专门讨论模块化系统下的类加载器。

- JDK 8及之前版本的Java，对于这个时期的Java应用，绝大多数Java程序都会使用到以下3个系统提供的类加载器来进行加载。

  - **启动类加载器（Bootstrap Class Loader）**：前面已经介绍过，这个类加载器负责加载存放在<JAVA_HOME>\lib目录，或者被-Xbootclasspath参数所指定的路径中存放的，而且是Java虚拟机能够识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机的内存中。

    - 启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器去处理，那直接使用null代替即可

  - **扩展类加载器（Extension Class Loader）**：这个类加载器是在类 sun.misc.Launcher$ExtClassLoader 中以Java代码的形式实现的。它负责加载<JAVA_HOME>\lib\ext目录中，或者被java.ext.dirs系统变量所指定的路径中所有的类库。

    - 根据“扩展类加载器”这个名称，就可以推断出这是一种Java系统类库的扩展机制，JDK的开发团队允许用户将具有通用性的类库放置在ext目录里以扩展Java SE的功能
    - 在 JDK 9 之后，这种扩展机制被模块化带来的天然的扩展能力所取代。
    - 由于扩展类加载器是由Java代码实现的，开发者可以直接在程序中使用扩展类加载器来加载Class文件。

  - **应用程序类加载器（Application Class Loader）**：这个类加载器由sun.misc.Launcher$AppClassLoader来实现。由于应用程序类加载器是ClassLoader类中的getSystemClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”。

    - 它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。
    - 如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。

  - JDK 9之前的Java应用都是由这三种类加载器互相配合来完成加载的，如果用户认为有必要，还可以加入**自定义的类加载器**来进行拓展，典型的如增加除了磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。

    - ```mermaid
      graph BT
      	ucl1[自定义类加载器 User Class Loader] --> acl[应用程序类加载器 Application Class  Loader] --> ecl[扩展类加载器 Extension Class Loader] --> bcl[启动类加载器 Boostrap Class Loader]
      	ucl2[自定义类加载器 User Class Loader] --> acl
      ```

- 展示的各种类加载器之间的层次关系被称为类加载器的**“双亲委派模型（Parents Delegation Model）”**。

  - 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。
  - 不过这里类加载器之间的父子关系一般不是以继承（Inheritance）的关系来实现的，而是通常使用组合（Composition）关系来复用父加载器的代码。
  - 双亲委派模型的工作过程是：
    - 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成
    - 每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中
    - 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。
  - 使用双亲委派模型来组织类加载器之间的关系，一个显而易见的好处就是Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。
    - 例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都能够保证是同一个类。
    - 如果读者有兴趣的话，可以尝试去写一个与rt.jar类库中已有类重名的Java类，将会发现它可以正常编译，但永远无法被加载运行
  - 双亲委派模型对于保证Java程序的稳定运作极为重要，但它的实现却异常简单，用以实现双亲委派的代码只有短短十余行，全部集中在java.lang.ClassLoader的loadClass()方法之中
    - 这段代码的逻辑清晰易懂：先检查请求加载的类型是否已经被加载过，若没有则调用父加载器的loadClass()方法，若父加载器为空则默认使用启动类加载器作为父加载器。假如父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。

###### 7.4.3 破坏双亲委派模型

- 上文提到过双亲委派模型**并不是一个具有强制性约束的模型**，而是Java设计者推荐给开发者们的类加载器实现方式。在Java的世界中大部分的类加载器都遵循这个模型，但也有例外的情况，直到Java模块化出现为止，双亲委派模型主要出现过3次较大规模“被破坏”的情况。
  - 双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即JDK 1.2面世以前的“远古”时代。
    - 由于双亲委派模型在JDK 1.2之后才被引入，但是类加载器的概念和抽象类java.lang.ClassLoader则在Java的第一个版本中就已经存在，面对已经存在的用户自定义类加载器的代码，Java设计者们引入双亲委派模型时不得不做出一些妥协
    - 为了兼容这些已有代码，无法再以技术手段避免loadClass()被子类覆盖的可能性，只能在JDK 1.2之后的java.lang.ClassLoader中添加一个新的protected方法findClass()，并引导用户编写的类加载逻辑时尽可能去重写这个方法，而不是在loadClass()中编写代码。
  - 双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的，双亲委派很好地解决了各个类加载器协作时基础类型的一致性问题（越基础的类由越上层的加载器进行加载），基础类型之所以被称为“基础”，是因为它们总是作为被用户代码继承、调用的API存在，但程序设计往往没有绝对不变的完美规则，如果有基础类型又要调用回用户的代码，那该怎么办呢？
    - 这并非是不可能出现的事情，一个典型的例子便是JNDI服务
    - 但JNDI存在的目的就是对资源进行查找和集中管理，它需要调用由其他厂商实现并部署在应用程序的ClassPath下的JNDI服务提供者接口（Service Provider Interface，SPI）的代码，现在问题来了，启动类加载器是绝不可能认识、加载这些代码的，那该怎么办？
    - 为了解决这个困境，Java的设计团队只好引入了一个不太优雅的设计：**线程上下文类加载器（Thread Context ClassLoader）**。
      - 这个类加载器可以通过 java.lang.Thread 类的 setContextClassLoader() 方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。
      - 有了线程上下文类加载器，程序就可以做一些“舞弊”的事情了。
        - JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码，这是一种父类加载器去请求子类加载器完成类加载的行为
        - 这种行为实际上是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则，但也是无可奈何的事情。
      - Java中涉及SPI的加载基本上都采用这种方式来完成，例如JNDI、JDBC、JCE、JAXB和JBI等。
      - 不过，当SPI的**服务提供者多于一个**的时候，代码就只能根据具体提供者的类型来硬编码判断
        - 为了消除这种极不优雅的实现方式，在JDK 6时，JDK提供了java.util.ServiceLoader类，以META-INF/services中的配置信息，辅以责任链模式，这才算是给SPI的加载提供了一种相对合理的解决方案。
  - 双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的，这里所说的“动态性”指的是一些非常“热”门的名词：代码热替换（Hot Swap）、模块热部署（Hot Deployment）等。
    - 曾经在很长一段时间内，IBM凭借着OSGi广泛应用基础让 Jigsaw 吃尽苦头，其影响一直持续到Jigsaw随JDK 9面世才算告一段落。
    - 而且即使Jigsaw现在已经是Java的标准功能了，它仍需小心翼翼地避开OSGi运行期动态热部署上的优势，仅局限于静态地解决模块间封装隔离和访问控制的问题
    - 现在我们先来简单看一看OSGi是如何通过类加载器实现热部署的。
      - OSGi实现模块化热部署的关键是它自定义的类加载器机制的实现，每一个程序模块（OSGi中称为 Bundle）都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。
      - 在OSGi环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构
      - 当收到类加载请求时，OSGi将按照下面的顺序进行类搜索：
        - 1）将以 java.* 开头的类，委派给父类加载器加载。
        - 2）否则，将委派列表名单内的类，委派给父类加载器加载。
        - 3）否则，将Import列表中的类，委派给Export这个类的Bundle的类加载器加载。
        - 4）否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。
        - 5）否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载。
        - 6）否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载。
        - 7）否则，类查找失败。
- 本节中笔者虽然使用了“被破坏”这个词来形容上述不符合双亲委派模型原则的行为，但这里“被破坏”并不一定是带有贬义的。只要有明确的目的和充分的理由，突破旧有原则无疑是一种创新。
  - 正如OSGi中的类加载器的设计不符合传统的双亲委派的类加载器架构，且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议
  - 但对这方面有了解的技术人员基本还是能达成一个共识，认为OSGi中对类加载器的运用是值得学习的，完全弄懂了OSGi的实现，就算是掌握了类加载器的精粹。

##### 7.5 Java 模块化系统

- 在JDK 9中引入的Java模块化系统（Java Platform Module System，JPMS）是对Java技术的一次重要升级，为了能够实现模块化的关键目标——可配置的封装隔离机制，Java虚拟机对类加载架构也做出了相应的变动调整，才使模块化系统得以顺利地运作
- JDK 9的模块不仅仅像之前的JAR包那样只是简单地充当代码的容器，除了代码外，Java的模块定义还包含以下内容：
  - 依赖其他模块的列表。
  - 导出的包列表，即其他模块可以使用的列表。
  - 开放的包列表，即其他模块可反射访问模块的列表。
  - 使用的服务列表。
  - 提供服务的实现列表。
- 可配置的封装隔离机制首先要解决JDK 9之前基于类路径（ClassPath）来查找依赖的可靠性问题。
  - 此前，如果类路径中缺失了运行时依赖的类型，那就只能等程序运行到发生该类型的加载、链接时才会报出运行的异常。
  - 而在JDK 9以后，如果启用了模块化进行封装，模块就可以声明对其他模块的显式依赖，这样Java虚拟机就能够在启动时验证应用程序开发阶段设定好的依赖关系在运行期是否完备，如有缺失那就直接启动失败，从而避免了很大一部分由于类型依赖而引发的运行时异常。
- 可配置的封装隔离机制还解决了原来类路径上跨JAR文件的public类型的可访问性问题。
  - JDK 9中的public类型不再意味着程序的所有地方的代码都可以随意访问到它们，模块提供了更精细的可访问性控制，必须明确声明其中哪一些public的类型可以被其他哪一些模块访问，这种访问控制也主要是在类加载过程中完成的，具体内容笔者在前文对解析阶段的讲解中已经介绍过。

###### 7.5.1 模块的兼容性

- 为了使可配置的封装隔离机制能够兼容传统的类路径查找机制，JDK 9提出了与“类路径”（ClassPath）相对应的“模块路径”（ModulePath）的概念。
  - 简单来说，就是某个类库到底是模块还是传统的JAR包，只取决于它存放在哪种路径上。
    - 只要是放在类路径上的JAR文件，无论其中是否包含模块化信息（是否包含了module-info.class文件），它都会被当作传统的JAR包来对待；
    - 相应地，只要放在模块路径上的JAR文件，即使没有使用JMOD后缀，甚至说其中并不包含module-info.class文件，它也仍然会被当作一个模块来对待。
- 模块化系统将按照以下规则来保证使用传统类路径依赖的Java程序可以不经修改地直接运行在JDK 9及以后的Java版本上，即使这些版本的JDK已经使用模块来封装了Java SE的标准类库，模块化系统的这套规则也仍然保证了传统程序可以访问到所有标准类库模块中导出的包。
  - **JAR文件在类路径的访问规则**：所有类路径下的JAR文件及其他资源文件，都被视为自动打包在一个匿名模块（Unnamed Module）里，这个匿名模块几乎是没有任何隔离的，它可以看到和使用类路径上所有的包、JDK系统模块中所有的导出包，以及模块路径上所有模块中导出的包。
  - **模块在模块路径的访问规则**：模块路径下的具名模块（Named Module）只能访问到它依赖定义中列明依赖的模块和包，匿名模块里所有的内容对具名模块来说都是不可见的，即具名模块看不见传统JAR包的内容。
  - **JAR文件在模块路径的访问规则**：如果把一个传统的、不包含模块定义的JAR文件放置到模块路径中，它就会变成一个自动模块（Automatic Module）。尽管不包含module-info.class，但自动模块将默认依赖于整个模块路径中的所有模块，因此可以访问到所有模块导出的包，自动模块也默认导出自己所有的包。
  - 以上3条规则保证了即使Java应用依然使用传统的类路径，升级到JDK 9对应用来说几乎（类加载器上的变动还是可能会导致少许可见的影响，将在下节介绍）不会有任何感觉，项目也不需要专门为了升级JDK版本而去把传统JAR包升级成模块。

###### 7.5.2 模块化下的类加载器

- 为了保证兼容性，JDK 9并没有从根本上动摇从JDK 1.2以来运行了二十年之久的三层类加载器架构以及双亲委派模型。但是为了模块化系统的顺利施行，模块化下的类加载器仍然发生了一些应该被注意到变动，主要包括以下几个方面。

  - 首先，是扩展类加载器（Extension Class Loader）被平台类加载器（Platform Class Loader）取代。

    - 这其实是一个很顺理成章的变动，既然整个JDK都基于模块化进行构建（原来的rt.jar和tools.jar被拆分成数十个JMOD文件），其中的Java类库就已天然地满足了可扩展的需求，那自然无须再保留<JAVA_HOME>\lib\ext目录，此前使用这个目录或者java.ext.dirs系统变量来扩展JDK功能的机制已经没有继续存在的价值了，用来加载这部分类库的扩展类加载器也完成了它的历史使命。
    - 类似地，在新版的JDK中也取消了<JAVA_HOME>\jre目录，因为随时可以组合构建出程序运行所需的JRE来，譬如假设我们只使用java.base模块中的类型，那么随时可以通过以下命令打包出一个“JRE”：`jlink -p $JAVA_HOME/jmods --add-modules java.base --output jre`

  - 其次，平台类加载器和应用程序类加载器都不再派生自java.net.URLClassLoader，如果有程序直接依赖了这种继承关系，或者依赖了URLClassLoader类的特定方法，那代码很可能会在JDK 9及更高版本的JDK中崩溃。

    - 现在启动类加载器、平台类加载器、应用程序类加载器全都继承于 jdk.internal.loader.BuiltinClassLoader，在 BuiltinClassLoader 中实现了新的模块化架构下类如何从模块中加载的逻辑，以及模块中资源可访问性的处理。

  - 另外，读者可能已经注意到图 7-6 中有“BootClassLoader”存在，启动类加载器现在是在Java虚拟机内部和Java类库共同协作实现的类加载器，尽管有了 BootClassLoader 这样的Java类，但为了与之前的代码保持兼容，所有在获取启动类加载器的场景（譬如Object.class.getClassLoader()）中仍然会返回null来代替，而不会得到BootClassLoader的实例。

  - 最后，JDK 9中虽然仍然维持着三层类加载器和双亲委派的架构，但类加载的委派关系也发生了变动。**当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器完成加载**，也许这可以算是对双亲委派的第四次破坏。

    - ```mermaid
      graph BT
      	ucl1[自定义类加载器 User Class Loader] --> acl[应用程序类加载器 Application Class  Loader] --> pcl[平台类加载器 Platform Class Loader] --> bcl[启动类加载器 Boostrap Class Loader]
      	ucl2[自定义类加载器 User Class Loader] --> acl
      	pcl -->  acl --> bcl
      ```

- 在Java模块化系统明确规定了三个类加载器负责各自加载的模块，即前面所说的归属关系，如下所示。

  - 启动类加载器负责加载的模块：
    - java.base
    - java.datatransfer
    - java.desktop
    - java.instrument
    - java.logging
    - java.management
    - java.management.rmi
    - java.naming
    - java.prefs
    - java.rmi
    - java.security.sasl
    - java.xml
    - jdk.httpserver
    - jdk.internal.vm.ci
    - jdk.management
    - jdk.management.agent
    - jdk.naming.rmi
    - jdk.net
    - jdk.sctp
    - jdk.unsupported
  - 平台类加载器负责加载的模块：
    - java.activation*
    - java.compiler*
    - java.corba*
    - java.scripting
    - java.se
    - java.se.ee
    - java.security.jgss
    - java.smartcardio
    - java.sql jdk.localedata
    - java.sql.rowset
    - java.transaction*
    - java.xml.bind*
    - java.xml.crypto
    - java.xml.ws*
    - java.xml.ws.annotation*
    - jdk.accessibility
    - jdk.charsets
    - jdk.crypto.cryptoki
    - jdk.crypto.ec
    - jdk.dynalink
    - jdk.incubator.httpclient
    - jdk.internal.vm.compiler*
    - jdk.jsobject
    - jdk.naming.dns
    - jdk.scripting.nashorn
    - jdk.security.auth
    - jdk.security.jgss
    - jdk.xml.dom
    - jdk.zipfs
  - 应用程序类加载器负责加载的模块：
    - jdk.aot
    - jdk.attach
    - jdk.compiler
    - jdk.editpad
    - jdk.hotspot.agent
    - jdk.internal.ed
    - jdk.internal.jvmstat
    - jdk.internal.le
    - jdk.internal.opt
    - jdk.jartool
    - jdk.javadoc
    - jdk.jcmd
    - jdk.jconsole
    - jdk.jdeps
    - jdk.jdi
    - jdk.jdwp.agent
    - jdk.jlink
    - jdk.jshell
    - jdk.jstatd
    - jdk.pack
    - jdk.policytool
    - jdk.rmic
    - jdk.scripting.nashorn.shell
    - jdk.xml.bind*
    - jdk.xml.ws*

#### 8、虚拟机字节码执行引擎

##### 8.1 概述

- 执行引擎是Java虚拟机核心的组成部分之一。
- “虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是
  - 物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的
  - 而虚拟机的执行引擎则是由软件自行实现的，因此可以不受物理条件制约地定制指令集与执行引擎的结构体系，能够执行那些不被硬件直接支持的指令集格式。
- 在《Java虚拟机规范》中制定了Java虚拟机字节码执行引擎的概念模型，这个概念模型成为各大发行商的Java虚拟机执行引擎的统一外观（Facade）。
  - 在不同的虚拟机实现中，执行引擎在执行字节码的时候，通常会有解释执行（通过解释器执行）和编译执行（通过即时编译器产生本地代码执行）两种选择，也可能两者兼备，还可能会有同时包含几个不同级别的即时编译器一起工作的执行引擎。
  - 但从外观上来看，所有的Java虚拟机的执行引擎输入、输出都是一致的：输入的是字节码二进制流，处理过程是字节码解析执行的等效过程，输出的是执行结果，本章将主要从概念模型的角度来讲解虚拟机的方法调用和字节码执行。

##### 8.2 运行时栈帧结构

- Java虚拟机以方法作为最基本的执行单元，“栈帧”（Stack Frame）则是用于支持虚拟机进行方法调用和方法执行背后的数据结构，它也是虚拟机运行时数据区中的虚拟机栈（Virtual Machine Stack）的栈元素。
  - 栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息
  - 每一个方法从调用开始至执行结束的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。
- 每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。
  - 在编译Java程序源码的时候，栈帧中需要多大的局部变量表，需要多深的操作数栈就已经被分析计算出来，并且写入到方法表的Code属性之中
  - 换言之，一个栈帧需要分配多少内存，并不会受到程序运行期变量数据的影响，而仅仅取决于程序源码和具体的虚拟机实现的栈内存布局形式。
- 一个线程中的方法调用链可能会很长，以Java程序的角度来看，同一时刻、同一条线程里面，在调用堆栈的所有方法都同时处于执行状态。而对于执行引擎来讲，在活动线程中，只有位于栈顶的方法才是在运行的，只有位于栈顶的栈帧才是生效的，其被称为**“当前栈帧”（Current Stack Frame）**，与这个栈帧所关联的方法被称为**“当前方法”（Current Method）**。
  - 执行引擎所运行的所有字节码指令都只针对当前栈帧进行操作

###### 8.2.1 局部变量表

- 局部变量表（Local Variables Table）是一组变量值的存储空间，用于存放方法参数和方法内部定义的局部变量。
  - 在Java程序被编译为Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需分配的局部变量表的最大容量。
- 局部变量表的容量以变量槽（Variable Slot）为最小单位
  - 《Java虚拟机规范》中并没有明确指出一个变量槽应占用的内存空间大小，只是很有导向性地说到每个变量槽都应该能存放一个boolean、byte、char、short、int、float、reference或returnAddress类型的数据
  - 对于64位的数据类型，Java虚拟机会以高位对齐的方式为其分配两个连续的变量槽空间。Java语言中明确的64位的数据类型只有long和double两种。
    - 这里把long和double数据类型分割存储的做法与“long 和 double 的非原子性协定”中允许把一次long和double数据类型读写分割为两次32位读写的做法有些类似，读者阅读到本书关于Java内存模型的内容时可以进行对比。
    - 不过，由于局部变量表是建立在线程堆栈中的，属于线程私有的数据，无论读写两个连续的变量槽是否为原子操作，都不会引起数据竞争和线程安全问题。
  - Java虚拟机通过索引定位的方式使用局部变量表，索引值的范围是从0开始至局部变量表最大的变量槽数量。
    - 如果访问的是32位数据类型的变量，索引N就代表了使用第N个变量槽
    - 如果访问的是64位数据类型的变量，则说明会同时使用第N和N+1两个变量槽。
      - 对于两个相邻的共同存放一个64位数据的两个变量槽，虚拟机不允许采用任何方式单独访问其中的某一个
- 当一个方法被调用时，Java虚拟机会使用局部变量表来完成参数值到参数变量列表的传递过程，即实参到形参的传递。
  - 如果执行的是实例方法（没有被static修饰的方法），那局部变量表中第0位索引的变量槽默认是用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。
  - 其余参数则按照参数表顺序排列，占用从1开始的局部变量槽，参数表分配完毕后，再根据方法体内部定义的变量顺序和作用域分配其余的变量槽。
- 为了尽可能节省栈帧耗用的内存空间，局部变量表中的变量槽是可以重用的，方法体中定义的变量，其作用域并不一定会覆盖整个方法体，如果当前字节码PC计数器的值已经超出了某个变量的作用域，那这个变量对应的变量槽就可以交给其他变量来重用。
  - 不过，这样的设计除了节省栈帧空间以外，还会伴随有少量额外的副作用，例如在某些情况下变量槽的复用会直接影响到系统的垃圾收集行为
- 关于局部变量表，还有一点可能会对实际开发产生影响，就是局部变量不像前面介绍的类变量那样存在“准备阶段”。
  - 我们已经知道类的字段变量有两次赋初始值的过程，一次在准备阶段，赋予系统初始值；另外一次在初始化阶段，赋予程序员定义的初始值。因此即使在初始化阶段程序员没有为类变量赋值也没有关系，类变量仍然具有一个确定的初始值，不会产生歧义。
  - 但局部变量就不一样了，如果一个局部变量定义了但没有赋初始值，那它是完全不能使用的。所以不要认为Java中任何情况下都存在诸如整型变量默认为0、布尔型变量默认为false等这样的默认值规则。

###### 8.2.2 操作数栈

- 操作数栈（Operand Stack）也常被称为操作栈，它是一个后入先出（Last In First Out，LIFO）栈。同局部变量表一样，操作数栈的最大深度也在编译的时候被写入到Code属性的max_stacks数据项之中。
  - 操作数栈的每一个元素都可以是包括long和double在内的任意Java数据类型。
  - 32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。
  - Javac编译器的数据流分析工作保证了在方法执行的任何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值。
- 当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈和入栈操作。
  - 譬如在做算术运算的时候是通过将运算涉及的操作数栈压入栈顶后调用运算指令来进行的，又譬如在调用其他方法的时候是通过操作数栈来进行方法参数的传递。
- 操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，在编译程序代码的时候，编译器必须要严格保证这一点，在类校验阶段的数据流分析中还要再次验证这一点。
- 另外在概念模型中，两个不同栈帧作为不同方法的虚拟机栈的元素，是完全相互独立的。
  - 但是在大多虚拟机的实现里都会进行一些优化处理，令两个栈帧出现一部分重叠。
  - 让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样做不仅节约了一些空间，更重要的是在进行方法调用时就可以直接共用一部分数据，无须进行额外的参数复制传递了
- Java虚拟机的解释执行引擎被称为“基于栈的执行引擎”，里面的“栈”就是操作数栈。后文会对基于栈的代码执行过程进行更详细的讲解，介绍它与更常见的基于寄存器的执行引擎有哪些差别。

###### 8.2.3 动态连接

- 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的**动态连接（Dynamic Linking）**。
- 我们知道Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池里指向方法的符号引用作为参数。
  - 这些符号引用一部分会在类加载阶段或者第一次使用的时候就被转化为直接引用，这种转化被称为**静态解析**。
  - 另外一部分将在每一次运行期间都转化为直接引用，这部分就称为**动态连接**。

###### 8.2.4 方法返回地址

- 当一个方法开始执行后，只有两种方式退出这个方法。
  - 第一种方式是执行引擎遇到任意一个方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者（调用当前方法的方法称为调用者或者主调方法），方法是否有返回值以及返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为**“正常调用完成”（Normal Method Invocation Completion）**。
  - 另外一种退出方式是在方法执行的过程中遇到了异常，并且这个异常没有在方法体内得到妥善处理。
    - 无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方法的方式称为**“异常调用完成（Abrupt Method Invocation Completion）”**。
    - 一个方法使用异常完成出口的方式退出，是不会给它的上层调用者提供任何返回值的。
- 无论采用何种退出方式，在方法退出之后，都必须返回到最初方法被调用时的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层主调方法的执行状态。
  - 一般来说，方法正常退出时，主调方法的PC计数器的值就可以作为返回地址，栈帧中很可能会保存这个计数器值。
  - 而方法异常退出时，返回地址是要通过异常处理器表来确定的，栈帧中就一般不会保存这部分信息。
- 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：
  - 恢复上层方法的局部变量表和操作数栈
  - 把返回值（如果有的话）压入调用者栈帧的操作数栈中
  - 调整PC计数器的值以指向方法调用指令后面的一条指令等
    - 笔者这里写的“可能”是由于这是基于概念模型的讨论，只有具体到某一款Java虚拟机实现，会执行哪些操作才能确定下来。

###### 8.2.5 附加信息

- 《Java虚拟机规范》允许虚拟机实现增加一些规范里没有描述的信息到栈帧之中，例如与调试、性能收集相关的信息，这部分信息完全取决于具体的虚拟机实现，这里不再详述。
- 在讨论概念时，一般会把动态连接、方法返回地址与其他附加信息全部归为一类，称为栈帧信息。

##### 8.3 方法调用

- 方法调用并不等同于方法中的代码被执行，方法调用阶段唯一的任务就是确定被调用方法的版本（即调用哪一个方法），暂时还未涉及方法内部的具体运行过程。
- 在程序运行时，进行方法调用是最普遍、最频繁的操作之一，但第7章中已经讲过，Class文件的编译过程中不包含传统程序语言编译的连接步骤，一切方法调用在Class文件里面存储的都只是符号引用，而不是方法在实际运行时内存布局中的入口地址（也就是之前说的直接引用）。
- 这个特性给Java带来了更强大的动态扩展能力，但也使得Java方法调用过程变得相对复杂，某些调用需要在类加载期间，甚至到运行期间才能确定目标方法的直接引用。

###### 8.3.1 解析

- 承接前面关于方法调用的话题，所有方法调用的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段，会将其中的一部分符号引用转化为直接引用，这种解析能够成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期是不可改变的。
  - 换句话说，调用目标在程序代码写好、编译器进行编译那一刻就已经确定下来。这类方法的调用被称为**解析（Resolution）**。
- 在Java语言中符合“编译期可知，运行期不可变”这个要求的方法，主要有静态方法和私有方法两大类
  - 前者与类型直接关联
  - 后者在外部不可被访问
  - 这两种方法各自的特点决定了它们都不可能通过继承或别的方式重写出其他版本，因此它们都适合在类加载阶段进行解析。
- 调用不同类型的方法，字节码指令集里设计了不同的指令。在Java虚拟机支持以下5条方法调用字节码指令，分别是：
  - invokestatic。用于调用静态方法。
  - invokespecial。用于调用实例构造器 `<init>()` 方法、私有方法和父类中的方法。
  - invokevirtual。用于调用所有的虚方法。
  - invokeinterface。用于调用接口方法，会在运行时再确定一个实现该接口的对象。
  - invokedynamic。先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法。
- 前面4条调用指令，分派逻辑都固化在Java虚拟机内部，而invokedynamic指令的分派逻辑是由用户设定的引导方法来决定的。
- 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段中确定唯一的调用版本，Java语言里符合这个条件的方法共有**静态方法、私有方法、实例构造器、父类方法**4种，再加上**被final修饰的方法**（尽管它使用invokevirtual指令调用），这5种方法调用会在类加载的时候就可以把符号引用解析为该方法的直接引用。这些方法统称为**“非虚方法”（Non-Virtual Method）**
  - 与之相反，其他方法就被称为**“虚方法”（Virtual Method）**。
- 解析调用一定是个静态的过程，在编译期间就完全确定，在类加载的解析阶段就会把涉及的符号引用全部转变为明确的直接引用，不必延迟到运行期再去完成。
  - 而另一种主要的方法调用形式：**分派（Dispatch）**调用则要复杂许多，
    - 它可能是静态的也可能是动态的
    - 按照分派依据的宗量数可分为单分派和多分派。
    - 这两类分派方式两两组合就构成了静态单分派、静态多分派、动态单分派、动态多分派4种分派组合情况

###### 8.3.2 分派

- 众所周知，Java是一门面向对象的程序语言，因为Java具备面向对象的3个基本特征：继承、封装和多态。

- 本节讲解的分派调用过程将会揭示多态性特征的一些最基本的体现，如“重载”和“重写”在Java虚拟机之中是如何实现的，这里的实现当然不是语法上该如何写，我们关心的依然是虚拟机如何确定正确的目标方法。

- 1.静态分派

  - 在开始讲解静态分派前，笔者先声明一点，“分派”（Dispatch）这个词本身就具有动态性，一般不应用在静态语境之中，这部分原本在英文原版的《Java虚拟机规范》和《Java语言规范》里的说法都是“Method Overload Resolution”，即应该归入8.2节的“解析”里去讲解，但部分其他外文资料和国内翻译的许多中文资料都将这种行为称为“静态分派”，所以笔者在此特别说明一下，以免读者阅读英文资料时遇到这两种说法产生疑惑。
  - 我们先通过如下代码来定义两个关键概念：`Human man = new Man();`
    - 我们把上面代码中的“Human”称为变量的**“静态类型”（Static Type）**，或者叫**“外观类型”（Apparent Type）**
    - 后面的“Man”则被称为变量的**“实际类型”（Actual Type）**或者叫**“运行时类型”（Runtime Type）**。
    - 静态类型和实际类型在程序中都可能会发生变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的；而实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。
  - 所有依赖静态类型来决定方法执行版本的分派动作，都称为**静态分派**。
    - 静态分派的**最典型应用表现就是方法重载**。
    - 静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，这点也是为何一些资料选择把它归入“解析”而不是“分派”的原因。
  - 需要注意Javac编译器虽然能确定出方法的重载版本，但在很多情况下这个重载版本并不是“唯一”的，往往只能确定一个“相对更合适的”版本。
    - char 极端情况下的匹配优先级：char > int > long > Character > Serializable > Object > char ...（可变参数）
    - 如果一样的优先级（比如 char 的 `Serializable` 和 `Comparable<Character>`），编译器无法确定要自动转型为哪种类型，会提示“类型模糊”（Type Ambiguous），并拒绝编译。
    - 但是如果读者愿意花费一点时间，绕过Javac编译器，自己去构造出表达相同语义的字节码，将会发现这是能够通过Java虚拟机的类加载校验，而且能够被Java虚拟机正常执行的，但是会选择Serializable还是 `Comparable<Character>` 的重载方法则并不能事先确定

- 2.动态分派

  - 了解了静态分派，我们接下来看一下Java语言里动态分派的实现过程，它与Java语言多态性的另外一个重要体现——重写（Override）有着很密切的关联。

  - 显然这里选择调用的方法版本是不可能再根据静态类型来决定的，因为静态类型同样都是 Human 的两个变量man和woman 在调用 sayHello() 方法时产生了不同的行为，甚至变量 man 在两次调用中还执行了两个不同的方法。

    - 导致这个现象的原因很明显，是因为这两个变量的实际类型不同，Java虚拟机是如何根据实际类型来分派方法执行版本的呢？
    - 那看来解决问题的关键还必须从invokevirtual指令本身入手，要弄清楚它是如何确定调用方法版本、如何实现多态查找来着手分析才行。
      - 根据《Java 虚拟机规范》，invokevirtual 指令的运行时解析过程大致分为以下几步：
        - 1）找到操作数栈顶的第一个元素所指向的对象的实际类型，记作C。
        - 2）如果在类型C中找到与常量中的描述符和简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；不通过则返回java.lang.IllegalAccessError异常。
        - 3）否则，按照继承关系从下往上依次对C的各个父类进行第二步的搜索和验证过程。
        - 4）如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。

  - 正是因为 invokevirtual 指令执行的第一步就是在运行期确定接收者的实际类型，所以两次调用中的 invokevirtual 指令并不是把常量池中方法的符号引用解析到直接引用上就结束了，还会根据方法接收者的实际类型来选择方法版本，这个过程就是Java语言中方法重写的本质。

    - 我们把这种在运行期根据实际类型确定方法执行版本的分派过程称为**动态分派**。

    - 既然这种多态性的根源在于虚方法调用指令 invokevirtual 的执行逻辑，那自然我们得出的结论就只会对方法有效，对字段是无效的，因为字段不使用这条指令。

      - 事实上，在Java里面只有虚方法存在，**字段永远不可能是虚的**，换句话说，**字段永远不参与多态**，哪个类的方法访问某个名字的字段时，该名字指的就是这个类能看到的那个字段。

      - 当子类声明了与父类同名的字段时，虽然在子类的内存中两个字段都会存在，但是**子类的字段会遮蔽父类的同名字段**。

      - 劣质面试题式代码：

        - ```java
          /**
          * 字段不参与多态
          * @author zzm
          */
          public class FieldHasNoPolymorphic {
              static class Father {
                  public int money = 1;
                  public Father() {
                      money = 2;
                      showMeTheMoney();
                  }
                  public void showMeTheMoney() {
                 		System.out.println("I am Father, i have $" + money);
                  }
              }
              static class Son extends Father {
                  public int money = 3;
                  public Son() {
                      money = 4;
                      showMeTheMoney();
                  }
                  public void showMeTheMoney() {
                  	System.out.println("I am Son, i have $" + money);
                  }
              }
              public static void main(String[] args) {
                  Father gay = new Son();
                  System.out.println("This gay has $" + gay.money);
              }
          }
          ```

        - 运行后输出结果为：

        - ```
          I am Son, i have $0
          I am Son, i have $4
          This gay has $2
          ```

        - 输出两句都是“I am Son”，这是因为 Son 类在创建的时候，首先隐式调用了 Father 的构造函数，而 Father 构造函数中对 showMeTheMoney() 的调用是一次虚方法调用，实际执行的版本是 Son::showMeTheMoney() 方法，所以输出的是“I am Son”，这点经过前面的分析相信读者是没有疑问的了。

        - 而这时候虽然父类的money字段已经被初始化成2了，但 Son::showMeTheMoney() 方法中访问的却是子类的money字段，这时候结果自然还是 0，因为它要到子类的构造函数执行时才会被初始化。main() 的最后一句通过静态类型访问到了父类中的 money，输出了 2。

- 3.单分派与多分派

  - 方法的接收者与方法的参数统称为**方法的宗量**，这个定义最早应该来源于著名的《Java与模式》一书。
  - 根据分派基于多少种宗量，可以将分派划分为单分派和多分派两种。
    - **单分派**是根据一个宗量对目标方法进行选择
    - **多分派**则是根据多于一个宗量对目标方法进行选择。
  - 我们关注的首先是**编译阶段**中编译器的选择过程，也就是**静态分派**的过程。
    - 这时候选择目标方法的依据有两点：一是静态类型是Father还是Son，二是方法参数是QQ还是360。
    - 这次选择结果的最终产物是产生了两条invokevirtual指令，两条指令的参数分别为常量池中指向 Father::hardChoice(360)及Father::hardChoice(QQ)方法的符号引用。
    - 因为是根据两个宗量进行选择，所以 Java语言的**静态分派属于多分派类型**。
  - 再看看**运行阶段**中虚拟机的选择，也就是**动态分派**的过程。
    - 因为这时候参数的静态类型、实际类型都对方法的选择不会构成任何影响，唯一可以影响虚拟机选择的因素只有该方法的接受者的实际类型是Father还是Son。
    - 因为只有一个宗量作为选择依据，所以Java语言的**动态分派属于单分派类型**。
  - 根据上述论证的结果，我们可以总结一句：如今（直至本书编写的Java 12和预览版的Java 13）的 Java 语言是一门**静态多分派、动态单分派**的语言。
    - 强调“如今的Java语言”是因为这个结论未必会恒久不变，C#在3.0及之前的版本与Java一样是动态单分派语言，但在C#4.0中引入了dynamic类型后，就可以很方便地实现动态多分派。
    - JDK 10时Java语法中新出现var关键字，但请读者切勿将其与C#中的dynamic类型混淆，事实上Java的var与C#的var才是相对应的特性，它们与dynamic有着本质的区别
      - var 是在编译时根据声明语句中赋值符右侧的表达式类型来静态地推断类型，这本质是一种语法糖；
      - 而dynamic在编译时完全不关心类型是什么，等到运行的时候再进行类型判断。
    - Java语言中与C#的dynamic类型功能相对接近（只是接近，并不是对等的）的应该是在JDK 9时通过JEP 276引入的jdk.dynalink模块，使用jdk.dynalink可以实现在表达式中使用动态类型，Javac编译器会将这些动态类型的操作翻译为invokedynamic指令的调用点。
  - 按照目前Java语言的发展趋势，它并没有直接变为动态语言的迹象，而是通过内置动态语言（如JavaScript）执行引擎、加强与其他Java虚拟机上动态语言交互能力的方式来间接地满足动态性的需求。
    - 但是作为多种语言共同执行平台的Java虚拟机层面上则不是如此，早在JDK 7中实现的JSR-292 里面就已经开始提供对动态语言的方法调用支持了，JDK 7中新增的invokedynamic指令也成为最复杂的一条方法调用的字节码指令，稍后笔者将在本章中专门开一节来讲解这个与Java调用动态语言密切相关的特性。

- 4.虚拟机动态分派的实现

  - 动态分派是执行非常频繁的动作，而且动态分派的方法版本选择过程需要运行时在接收者类型的方法元数据中搜索合适的目标方法，因此，Java虚拟机实现基于执行性能的考虑，真正运行时一般不会如此频繁地去反复搜索类型元数据。
    - 面对这种情况，一种基础而且常见的优化手段是为类型在**方法区**中建立一个**虚方法表（Virtual Method Table**，也称为vtable，与此对应的，在invokeinterface执行时也会用到**接口方法表——Interface Method Table**，简称itable），使用虚方法表索引来代替元数据查找以提高性能。
  - 虚方法表中存放着各个方法的实际入口地址。
    - 如果某个方法在子类中没有被重写，那子类的虚方法表中的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。
    - 如果子类中重写了这个方法，子类虚方法表中的地址也会被替换为指向子类实现版本的入口地址。
  - 为了程序实现方便，具有相同签名的方法，在父类、子类的虚方法表中都应当具有一样的索引序号，这样当类型变换时，仅需要变更查找的虚方法表，就可以从不同的虚方法表中按索引转换出所需的入口地址。
    - 虚方法表一般在类加载的**连接阶段**进行初始化，准备了类的变量初始值后，虚拟机会把该类的虚方法表也一同初始化完毕。
  - 上文中笔者提到了查虚方法表是分派调用的一种优化手段，由于Java对象里面的方法默认（即不使用final修饰）就是虚方法，虚拟机除了使用虚方法表之外，为了进一步提高性能，还会使用类型继承关系分析（Class Hierarchy Analysis，CHA）、守护内联（Guarded Inlining）、内联缓存（Inline Cache）等多种非稳定的激进优化来争取更大的性能空间，关于这几种优化技术的原理和运作过程，读者可以参考第11章中的相关内容。

##### 8.4 动态类型语言支持

- Java虚拟机的字节码指令集的数量自从Sun公司的第一款Java虚拟机问世至今，二十余年间只新增过一条指令，它就是随着 JDK 7 的发布的字节码首位新成员——invokedynamic 指令。
  - 这条新增加的指令是JDK 7的项目目标：实现动态类型语言（Dynamically Typed Language）支持而进行的改进之一
  - 也是为JDK 8里可以顺利实现Lambda表达式而做的技术储备。

###### 8.4.1 动态类型语言

- 何谓动态类型语言？
  - 动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期进行的，满足这个特征的语言有很多
  - 常用的包括：APL、Clojure、Erlang、Groovy、JavaScript、Lisp、Lua、PHP、Prolog、Python、Ruby、Smalltalk、Tcl，等等。
  - 那相对地，在编译期就进行类型检查过程的语言，譬如C++和Java等就是最常用的静态类型语言。
- “变量无类型而变量值才有类型”这个特点也是动态类型语言的一个核心特征
- 选择哪种语言是需要权衡的事情。
  - 静态类型语言能够在编译期确定变量类型，最显著的好处是编译器可以提供全面严谨的类型检查，这样与数据类型相关的潜在问题就能在编码时被及时发现，利于稳定性及让项目容易达到更大的规模。
  - 而动态类型语言在运行期才确定类型，这可以为开发人员提供极大的灵活性，某些在静态类型语言中要花大量臃肿代码来实现的功能，由动态类型语言去做可能会很清晰简洁，清晰简洁通常也就意味着开发效率的提升。

###### 8.4.2 Java 与动态类型

- 目前确实已经有许多动态类型语言运行于Java虚拟机之上了，如Clojure、Groovy、Jython和JRuby等
- 但遗憾的是Java虚拟机层面对动态类型语言的支持一直都还有所欠缺，主要表现在方法调用方面：JDK 7以前的字节码指令集中，4条方法调用指令（invokevirtual、invokespecial、invokestatic、invokeinterface）的第一个参数都是被调用的方法的符号引用（CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info常量），前面已经提到过，方法的符号引用在编译时产生，而动态类型语言只有在运行期才能确定方法的接收者。
  - 这样，在Java虚拟机上实现的动态类型语言就不得不使用“曲线救国”的方式（如编译时留个占位符类型，运行时动态生成字节码实现具体类型到占位符类型的适配）来实现，但这样势必会让动态类型语言实现的复杂度增加，也会带来额外的性能和内存开销。
  - 而其中最严重的性能瓶颈是在于动态类型方法调用时，由于无法确定调用对象的静态类型，而导致的方法内联无法有效进行。

###### 8.4.3 java.lang.invoker 包

- JDK 7时新加入的java.lang.invoke包[1]是JSR 292的一个重要组成部分，这个包的主要目的是在之前单纯依靠符号引用来确定调用的目标方法这条路之外，提供一种新的动态确定目标方法的机制，称为**“方法句柄”（Method Handle）**。
  - 这个表达听起来也不好懂？那不妨把方法句柄与C/C++中的函数指针（Function Pointer），或者C#里面的委派（Delegate）互相类比一下来理解。
- 确实，仅站在Java语言的角度看，MethodHandle在使用方法和效果上与Reflection有众多相似之处。不过，它们也有以下这些区别：
  - Reflection和MethodHandle机制本质上都是在模拟方法调用，但是Reflection是在模拟Java代码层次的方法调用，而**MethodHandle是在模拟字节码层次的方法调用**。在MethodHandles.Lookup上的3个方法findStatic()、findVirtual()、findSpecial()正是为了对应于invokestatic、invokevirtual（以及invokeinterface）和invokespecial这几条字节码指令的执行权限校验行为，而这些底层细节在使用Reflection API时是不需要关心的。
  - Reflection中的java.lang.reflect.Method对象远比MethodHandle机制中的java.lang.invoke.MethodHandle对象所包含的信息来得多。前者是方法在Java端的全面映像，包含了方法的签名、描述符以及方法属性表中各种属性的Java端表示方式，还包含执行权限等的运行期信息。而后者仅包含执行该方法的相关信息。用开发人员通俗的话来讲，Reflection是重量级，而**MethodHandle是轻量级**。
  - 由于MethodHandle是对字节码的方法指令调用的模拟，那理论上虚拟机在这方面做的各种优化（如方法内联），在MethodHandle上也应当可以采用类似思路去支持（但目前实现还在继续完善中），而通过反射去调用方法则几乎不可能直接去实施各类调用点优化措施。

###### 8.4.4 invokedynamic 指令

- 某种意义上可以说 invokedynamic 指令与 MethodHandle 机制的作用是一样的，都是为了解决原有 4 条“invoke*”指令方法分派规则完全固化在虚拟机之中的问题，把如何查找目标方法的决定权从虚拟机转嫁到具体用户代码之中，让用户（广义的用户，包含其他程序语言的设计者）有更高的自由度。
  - 而且，它们两者的思路也是可类比的，都是为了达成同一个目的，**只是一个用上层代码和API来实现，另一个用字节码和Class中其他属性、常量来完成。**因此，如果前面MethodHandle的例子看懂了，相信读者理解invokedynamic指令并不困难。
- 每一处含有invokedynamic指令的位置都被称作**“动态调用点（Dynamically-Computed Call Site）”**，这条指令的第一个参数不再是代表方法符号引用的CONSTANT_Methodref_info常量，而是变为JDK 7 时新加入的**CONSTANT_InvokeDynamic_info常量**
  - 从这个新常量中可以得到3项信息：
    - 引导方法（Bootstrap Method，该方法存放在新增的BootstrapMethods属性中）
      - 引导方法是有固定的参数，并且返回值规定是java.lang.invoke.CallSite对象，这个对象代表了真正要执行的目标方法调用。
    - 方法类型（MethodType）
    - 名称
  - 根据CONSTANT_InvokeDynamic_info常量中提供的信息，虚拟机可以找到并且执行引导方法，从而获得一个CallSite对象，最终调用到要执行的目标方法上。

###### 8.4.5 实战：掌控方法分派规则

- invokedynamic指令与此前4条传统的“invoke*”指令的最大区别就是它的分派逻辑不是由虚拟机决定的，而是由程序员决定。

##### 8.5 基于栈的字节码解释执行引擎

- 概述中曾提到过，许多Java虚拟机的执行引擎在执行Java代码的时候都有解释执行（通过解释器执行）和编译执行（通过即时编译器产生本地代码执行）两种选择，在本节中，我们将会分析在概念模型下的Java虚拟机解释执行字节码时，其执行引擎是如何工作的。
  - 笔者在本章多次强调了“概念模型”，是因为实际的虚拟机实现，譬如HotSpot的模板解释器工作的时候，并不是按照下文中的动作一板一眼地进行机械式计算，而是**动态产生每条字节码对应的汇编代码来运行**，这与概念模型中执行过程的差异很大，但是结果却能保证是一致的。

###### 8.5.1 解释执行

- 解释执行

  - Java语言经常被人们定位为“解释执行”的语言，在Java初生的JDK 1.0时代，这种定义还算是比较准确的
  - 但当主流的虚拟机中都包含了即时编译器后，Class文件中的代码到底会被解释执行还是编译执行，就成了只有虚拟机自己才能准确判断的事。
  - 再后来，Java也发展出可以直接生成本地代码的编译器（如Jaotc、GCJ ，Excelsior JET），而C/C++语言也出现了通过解释器执行的版本（如 CINT）
  - 这时候再笼统地说“解释执行”，对于整个Java语言来说就成了几乎是没有意义的概念，只有确定了谈论对象是某种具体的Java实现版本和执行引擎运行模式时，谈解释执行还是编译执行才会比较合理确切。

- 编译过程

  - ```mermaid
    graph LR
    	程序源码 --> 词法分析 --> 单词流 --> 语法分析 --> 抽象语法树 --> 指令流-可选 --> 解释器 --> 解释执行
    	抽象语法树 --> 优化器-可选 --> 中间代码-可选 --> 生成器 --> 目标代码
    ```

  - 如今，基于物理机、Java虚拟机，或者是非Java的其他高级语言虚拟机（HLLVM）的代码执行过程，大体上都会遵循这种符合现代经典编译原理的思路，在执行前先对程序源码进行词法分析和语法分析处理，把源码转化为**抽象语法树（Abstract Syntax Tree，AST）**。

    - 对于一门具体语言的实现来说，词法、语法分析以至后面的优化器和目标代码生成器都可以选择独立于执行引擎，形成一个完整意义的编译器去实现，这类代表是C/C++语言。
    - 也可以选择把其中一部分步骤（如生成抽象语法树之前的步骤）实现为一个半独立的编译器，这类代表是Java语言。
    - 又或者把这些步骤和执行引擎全部集中封装在一个封闭的黑匣子之中，如大多数的JavaScript执行引擎。

- 在Java语言中，Javac编译器完成了程序代码经过词法分析、语法分析到抽象语法树，再遍历语法树生成线性的字节码指令流的过程。因为这一部分动作是在Java虚拟机之外进行的，而解释器在虚拟机的内部，所以Java程序的编译就是半独立的实现。

###### 8.5.2 基于栈的指令集与基于寄存器的指令集

- Javac编译器输出的字节码指令流，基本上是一种**基于栈的指令集架构（Instruction Set Architecture，ISA）**，字节码指令流里面的指令大部分都是零地址指令，它们依赖操作数栈进行工作。
- 与之相对的另外一套常用的指令集架构是**基于寄存器的指令集**，最典型的就是x86的二地址指令集，如果说得更通俗一些就是现在我们主流PC机中物理硬件直接支持的指令集架构，这些指令依赖寄存器进行工作。
- 优点
  - 基于栈的指令集主要优点是**可移植**，因为寄存器由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。
  - 栈架构的指令集还有一些其他的优点，如**代码相对更加紧凑**（字节码中每个字节就对应一条指令，而多地址指令集中还需要存放参数）、**编译器实现更加简单**（不需要考虑空间分配的问题，所需空间都在栈上操作）等。
- 缺点
  - 栈架构指令集的主要缺点是理论上执行速度相对来说会稍慢一些，所有主流物理机的指令集都是寄存器架构也从侧面印证了这点。
    - 不过这里的执行速度是要局限在解释执行的状态下，如果经过即时编译器输出成物理机上的汇编指令流，那就与虚拟机采用哪种指令集架构没有什么关系了。
      - 在解释执行时，栈架构指令集的代码虽然紧凑，但是完成相同功能所需的指令数量一般会比寄存器架构来得更多，因为出栈、入栈操作本身就产生了相当大量的指令。
      - 更重要的是栈实现在内存中，频繁的栈访问也就意味着频繁的内存访问，相对于处理器来说，内存始终是执行速度的瓶颈。
        - 尽管虚拟机可以采取栈顶缓存的优化方法，把最常用的操作映射到寄存器中避免直接内存访问，但这也只是优化措施而不是解决本质问题的方法。
      - 因此由于**指令数量**和**内存访问**的原因，导致了栈架构指令集的执行速度会相对慢上一点。

###### 8.5.3 基于栈的解释器执行过程

- 再次强调上面的执行过程仅仅是一种概念模型，虚拟机最终会对执行过程做出一系列优化来提高性能，实际的运作过程并不会完全符合概念模型的描述。
- 更确切地说，实际情况会和上面描述的概念模型差距非常大，差距产生的根本原因是虚拟机中解析器和即时编译器都会对输入的字节码进行优化，即使解释器中也不是按照字节码指令去逐条执行的。
  - 例如在HotSpot虚拟机中，就有很多以“fast_”开头的非标准字节码指令用于合并、替换输入的字节码以提升解释执行性能，即时编译器的优化手段则更是花样繁多

#### 9、类加载及其执行子系统的案例与实战

##### 9.1 概述

- 在Class文件格式与执行引擎这部分里，用户的程序能直接参与的内容并不太多，Class文件以何种格式存储，类型何时加载、如何连接，以及虚拟机如何执行字节码指令等都是由虚拟机直接控制的行为，用户程序无法对其进行改变。
- 能通过程序进行操作的，主要是**字节码生成**与**类加载器**这两部分的功能，但仅仅在如何处理这两点上，就已经出现了许多值得欣赏和借鉴的思路，这些思路后来成为许多常用功能和程序实现的基础。

##### 9.2 案例分析

###### 9.2.1 Tomcat：正统的类加载器架构

- 主流的Java Web服务器，如Tomcat、Jetty、WebLogic、WebSphere或其他笔者没有列举的服务器，都实现了自己定义的类加载器，而且一般还都不止一个。

- 因为一个功能健全的Web服务器，都要解决如下的这些问题：

  - 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以实现相互隔离。
    - 这是最基本的需求，两个不同的应用程序可能会依赖同一个第三方类库的不同版本，不能要求每个类库在一个服务器中只能有一份，服务器应当能够保证两个独立应用程序的类库可以互相独立使用。
  - 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以互相共享。
    - 这个需求与前面一点正好相反，但是也很常见，例如用户可能有10个使用Spring组织的应用程序部署在同一台服务器上，如果把10份Spring分别存放在各个应用程序的隔离目录中，将会是很大的资源浪费——这主要倒不是浪费磁盘空间的问题，而是指类库在使用时都要被加载到服务器内存，如果类库不能共享，虚拟机的方法区就会很容易出现过度膨胀的风险。
  - 服务器需要尽可能地保证自身的安全不受部署的Web应用程序影响。
    - 目前，有许多主流的JavaWeb服务器自身也是使用Java语言来实现的。因此服务器本身也有类库依赖的问题，一般来说，基于安全考虑，服务器所使用的类库应该与应用程序的类库互相独立。
  - 支持JSP应用的Web服务器，十有八九都需要支持HotSwap功能。
    - 我们知道JSP文件最终要被编译成Java的Class文件才能被虚拟机执行，但JSP文件由于其纯文本存储的特性，被运行时修改的概率远大于第三方类库或程序自己的Class文件。而且ASP、PHP和JSP这些网页应用也把修改后无须重启作为一个很大的“优势”来看待，因此“主流”的Web服务器都会支持JSP生成类的热替换，当然也有“非主流”的，如运行在生产模式（Production Mode）下的WebLogic服务器默认就不会处理JSP文件的变化。

- 由于存在上述问题，在部署Web应用时，单独的一个ClassPath就不能满足需求了，所以各种Web服务器都不约而同地提供了好几个有着不同含义的ClassPath路径供用户存放第三方类库，这些路径一般会以“lib”或“classes”命名。

  - 被放置到不同路径中的类库，具备不同的访问范围和服务对象，通常每一个目录都会有一个相应的自定义类加载器去加载放置在里面的Java类库。

- 在Tomcat目录结构中，可以设置3组目录（`/common/*`、`/server/*` 和 `/shared/*`，但默认不一定是开放的，可能只有 `/lib/*` 目录存在）用于存放Java类库，另外还应该加上Web应用程序自身的“`/WEB-INF/*`” 目录，一共4组。把Java类库放置在这4组目录中，每一组都有独立的含义，分别是：

  - 放置在/common目录中。类库可被Tomcat和所有的Web应用程序共同使用。
  - 放置在/server目录中。类库可被Tomcat使用，对所有的Web应用程序都不可见。
  - 放置在/shared目录中。类库可被所有的Web应用程序共同使用，但对Tomcat自己不可见。
  - 放置在/WebApp/WEB-INF目录中。类库仅仅可以被该Web应用程序使用，对Tomcat和其他Web应用程序都不可见。

- 为了支持这套目录结构，并对目录里面的类库进行加载和隔离，Tomcat自定义了多个类加载器，这些类加载器按照经典的双亲委派模型来实现

  - ```mermaid
    graph BT
    	ccl2[Catalina类加载器 CatalinaClassLoader] --> ccl[Common类加载器 CommonClassLoader] --> acl[应用程序类加载器 Application ClassLoader] --> ecl[扩展类加载器 Extendsion ClassLoader] --> bcl[启动类加载类 Bootstrap ClassLoader]
    	jl[Jsp类加载器 JasperLoader] --> wcl[WebApp类加载器 WebappClassLoader] --> scl[Shared类加载器 SharedClassLoader] --> ccl
    ```

  - 灰色背景的3个类加载器（最上面三个）是 JDK（以 JDK 9 之前经典的三层类加载器为例）默认提供的类加载器，这3个加载器的作用在第7章中已经介绍过了。

  - 而Common类加载器、Catalina类加载器（也称为Server类加载器）、Shared类加载器和Webapp类加载器则是Tomcat自己定义的类加载器，它们分别加载 `/common/*`、`/server/*`、`/shared/*` 和 `/WebApp/WEB-INF/*` 中的Java类库。

  - 其中WebApp类加载器和JSP类加载器通常还会存在多个实例，每一个Web应用程序对应一个WebApp类加载器，每一个JSP文件对应一个JasperLoader类加载器。

- 本例中的类加载结构在Tomcat 6以前是它默认的类加载器结构，在Tomcat 6及之后的版本简化了默认的目录结构，只有指定了tomcat/conf/catalina.properties配置文件的server.loader和share.loader项后才会真正建立Catalina类加载器和Shared类加载器的实例，否则会用到这两个类加载器的地方都会用 Common类加载器的实例代替，而默认的配置文件中并没有设置这两个loader项，所以Tomcat 6之后也顺理成章地把/common、/server和/shared这3个目录**默认合并到一起变成1个/lib目录**，这个目录里的类库相当于以前/common目录中类库的作用，是Tomcat的开发团队为了简化大多数的部署场景所做的一项易用性改进。如果默认设置不能满足需要，用户可以通过修改配置文件指定server.loader和share.loader的方式重新启用原来完整的加载器架构。

###### 9.2.2 OSGi：灵活的类加载器架构

- OSGi （Open Service Gateway Initiative）是OSGi联盟（OSGi Alliance）制订的一个基于Java语言的动态模块化规范（在JDK 9引入的JPMS是静态的模块系统），这个规范最初由IBM、爱立信等公司联合发起，在早期连Sun公司都有参与。
- OSGi中的每个模块（称为Bundle）与普通的Java类库区别并不太大，两者一般都以JAR格式进行封装，并且内部存储的都是Java的Package和Class。
  - 但是一个Bundle可以声明它所依赖的Package（通过Import-Package描述），也可以声明它允许导出发布的Package（通过Export-Package描述）。
  - 在OSGi里面，Bundle之间的依赖关系从传统的上层模块依赖底层模块转变为平级模块之间的依赖，而且类库的可见性能得到非常精确的控制，一个模块里只有被Export过的Package才可能被外界访问，其他的Package和Class将会被隐藏起来。
- 以上这些静态的模块化特性原本也是OSGi的核心需求之一，不过它和后来出现的Java的模块化系统互相重叠了，所以OSGi现在着重向动态模块化系统的方向发展。
  - 在今天，通常引入OSGi的主要理由是基于OSGi架构的程序很可能（只是很可能，并不是一定会，需要考虑热插拔后的内存管理、上下文状态维护问题等复杂因素）会实现模块级的热插拔功能
    - 当程序升级更新或调试除错时，可以只停用、重新安装然后启用程序的其中一部分，这对大型软件、企业级程序开发来说是一个非常有诱惑力的特性
    - 譬如Eclipse中安装、卸载、更新插件而不需要重启动，就使用到了这种特性。
- OSGi之所以能有上述诱人的特点，必须要归功于它灵活的类加载器架构。
  - OSGi的Bundle类加载器之间只有规则，没有固定的委派关系。
    - 例如，某个Bundle声明了一个它依赖的Package，如果有其他Bundle声明了发布这个Package后，那么所有对这个Package的类加载动作都会委派给发布它的Bundle类加载器去完成。
  - 不涉及某个具体的Package时，各个Bundle加载器都是平级的关系，只有具体使用到某个Package和Class的时候，才会根据Package导入导出定义来构造Bundle间的委派和依赖。
  - 另外，一个Bundle类加载器为其他Bundle提供服务时，会根据Export-Package列表严格控制访问范围
    - 如果一个类存在于Bundle的类库中但是没有被Export，那么这个Bundle的类加载器能找到这个类，但不会提供给其他Bundle使用，而且OSGi框架也不会把其他Bundle的类加载请求分配给这个Bundle来处理。
- 在OSGi中，加载器之间的关系不再是双亲委派模型的树形结构，而是已经进一步发展成一种更为复杂的、运行时才能确定的网状结构。
  - 这种网状的类加载器架构在带来更优秀的灵活性的同时，也可能会产生许多新的隐患。

###### 9.2.3 字节码生成技术与动态代理的实现

- “字节码生成”并不是什么高深的技术，读者在看到“字节码生成”这个标题时也先不必去想诸如 Javassist、CGLib、ASM 之类的字节码类库，因为 JDK 里面的 Javac 命令就是字节码生成技术的“老祖宗”，并且 Javac 也是一个由 Java 语言写成的程序，它的代码存放在 OpenJDK 的jdk.compiler\share\classes\com\sun\tools\javac 目录中
- 我们选择其中相对简单的动态代理技术来讲解字节码生成技术是如何影响程序运作的。
  - 动态代理中所说的“动态”，是针对使用Java代码实际编写了代理类的“静态”代理而言的，它的优势不在于省去了编写代理类那一点编码工作量，而是实现了可以在原始类和接口还未知的时候，就确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以很灵活地重用于不同的应用场景之中。

###### 9.2.4 Backport 工具：Java 的时光机器

##### 9.3 实战：自己动手实现远程执行功能

## 程序编译与代码优化

### 具体问题

- **JVM Server模式与client模式启动的差别？**
- **Java 语法糖（lambda、自动装箱、for-each、泛型）**
- 动态编译和静态编译的区别
- 为何引入 JIT 编译？逃逸分析是什么？
- 什么是逃逸，是不是所有对象都在堆上分配内存

### 思考方向

#### 10、前端编译与优化

##### 10.1 概述

- 在Java技术下谈“编译期”而没有具体上下文语境的话，其实是一句很含糊的表述
  - 因为它可能是指一个前端编译器（叫“编译器的前端”更准确一些）把 `*.java` 文件转变成 `*.class` 文件的过程；
  - 也可能是指Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器码的过程；
  - 还可能是指使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程。
- 下面笔者列举了这3类编译过程里一些比较有代表性的编译器产品：
  - 前端编译器：JDK 的 Javac、Eclipse JDT中的增量式编译器（ECJ）。
  - 即时编译器：HotSpot虚拟机的C1、C2编译器，Graal编译器。
  - 提前编译器：JDK的Jaotc、GNU Compiler for the Java（GCJ）、Excelsior JET。
- 这3类过程中最符合普通程序员对Java程序编译认知的应该是第一类，本章标题中的“前端”指的也是这种由前端编译器完成的编译行为。
  - 在本章后续的讨论里，笔者提到的全部“编译期”和“编译器”都仅限于第一类编译过程，我们会把第二、三类编译过程留到第11章中去讨论。
- 限制了“编译期”的范围后，我们对于“优化”二字的定义也需要放宽一些，因为 **Javac 这类前端编译器对代码的运行效率几乎没有任何优化措施可言**（在JDK 1.3之后，Javac的-O优化参数就不再有意义），哪怕是编译器真的采取了优化措施也不会产生什么实质的效果。
  - 因为Java虚拟机设计团队选择把对性能的优化全部集中到运行期的即时编译器中，这样可以让那些不是由Javac产生的Class文件（如JRuby、Groovy等语言的Class文件）也同样能享受到编译器优化措施所带来的性能红利。
- 但是，如果把“优化”的定义放宽，把对开发阶段的优化也计算进来的话，Javac确实是做了许多针对Java语言编码过程的优化措施来降低程序员的编码复杂度、提高编码效率。
  - 相当多新生的Java语法特性，都是靠编译器的“语法糖”来实现，而不是依赖字节码或者Java虚拟机的底层改进来支持。
  - 我们可以这样认为，Java中即时编译器在运行期的优化过程，支撑了程序执行效率的不断提升；而前端编译器在编译期的优化过程，则是支撑着程序员的编码效率和语言使用者的幸福感的提高。

##### 10.2 Javac 编译器

- Javac编译器不像HotSpot虚拟机那样使用C++语言（包含少量C语言）实现，它本身就是一个由Java语言编写的程序，这为纯Java的程序员了解它的编译过程带来了很大的便利。

###### 10.2.1 Javac 的源码与调试

- 在JDK 6以前，Javac并不属于标准Java SE API的一部分，它实现代码单独存放在tools.jar中，要在程序中使用的话就必须把这个库放到类路径上。

- 在JDK 6发布时通过了JSR 199编译器API的提案，使得Javac编译器的实现代码晋升成为标准Java类库之一

- 从Javac代码的总体结构来看，编译过程大致可以分为1个准备过程和3个处理过程，它们分别如下所示。

  - 1）准备过程：初始化插入式注解处理器。
  - 2）解析与填充符号表过程，包括：
    - 词法、语法分析。将源代码的字符流转变为标记集合，构造出抽象语法树。
    - 填充符号表。产生符号地址和符号信息。
  - 3）插入式注解处理器的注解处理过程：插入式注解处理器的执行阶段，本章的实战部分会设计一个插入式注解处理器来影响Javac的编译行为。
  - 4）分析与字节码生成过程，包括：
    - 标注检查。对语法的静态信息进行检查。
    - 数据流及控制流分析。对程序动态运行过程进行检查。
    - 解语法糖。将简化代码编写的语法糖还原为原有的形式。
    - 字节码生成。将前面各个步骤所生成的信息转化成字节码。

- 上述3个处理过程里，执行插入式注解时又可能会产生新的符号，如果有新的符号产生，就必须转回到之前的解析、填充符号表的过程中重新处理这些新符号

  - 从总体来看，三者之间的关系与交互顺序如图所示。

  - ```mermaid
    graph LR
    	pe[解析与填充符号表 Parse and Enter] --> ap[注解处理 Annotation Processing] --> ag[分析与字节码生成 Analyse and Generate]
    	ap --> pe
    ```

###### 10.2.2 解析与填充符号表

- 解析过程由 parseFiles() 方法来完成，解析过程包括了经典程序编译原理中的词法分析和语法分析两个步骤。
  - 1.词法、语法分析
    - 词法分析是将源代码的字符流转变为标记（Token）集合的过程，单个字符是程序编写时的最小元素，但标记才是编译时的最小元素。
    - 语法分析是根据标记序列构造抽象语法树的过程
      - 抽象语法树（Abstract Syntax Tree，AST）是一种用来描述程序代码语法结构的树形表示方式
      - 抽象语法树的每一个节点都代表着程序代码中的一个语法结构（SyntaxConstruct），例如包、类型、修饰符、运算符、接口、返回值甚至连代码注释等都可以是一种特定的语法结构。
    - 经过词法和语法分析生成语法树以后，编译器就不会再对源码字符流进行操作了，后续的操作都建立在抽象语法树之上。
    - 在Javac的源码中，语法分析过程由com.sun.tools.javac.parser.Parser类实现，这个阶段产出的抽象语法树是以com.sun.tools.javac.tree.JCTree类表示的。
  - 2.填充符号表
    - 完成了语法分析和词法分析之后，下一个阶段是对符号表进行填充的过程，也就是 enterTrees() 方法要做的事情。
    - 符号表（Symbol Table）是由一组符号地址和符号信息构成的数据结构，读者可以把它类比想象成哈希表中键值对的存储形式（实际上符号表不一定是哈希表实现，可以是有序符号表、树状符号表、栈结构符号表等各种形式）。
      - 符号表中所登记的信息在编译的不同阶段都要被用到。
        - 譬如在语义分析的过程中，符号表所登记的内容将用于语义检查（如检查一个名字的使用和原先的声明是否一致）和产生中间代码
        - 在目标代码生成阶段，当对符号名进行地址分配时，符号表是地址分配的直接依据。
    - 在Javac源代码中，填充符号表的过程由com.sun.tools.javac.comp.Enter类实现，该过程的产出物是一个待处理列表，其中包含了每一个编译单元的抽象语法树的顶级节点，以及package-info.java（如果存在的话）的顶级节点。

###### 10.2.3 注解处理器

- JDK 5之后，Java语言提供了对注解（Annotations）的支持，注解在设计上原本是与普通的Java代码一样，都只会在程序运行期间发挥作用的。
- 但在JDK 6中又提出并通过了JSR-269提案，该提案设计了一组被称为“插入式注解处理器”的标准API，可以提前至编译期对代码中的特定注解进行处理，从而影响到前端编译器的工作过程。
- 我们可以把插入式注解处理器看作是一组编译器的插件，当这些插件工作时，允许读取、修改、添加抽象语法树中的任意元素。如果这些插件在处理注解期间对语法树进行过修改，编译器将回到解析及填充符号表的过程重新处理，直到所有插入式注解处理器都没有再对语法树进行修改为止，每一次循环过程称为一个轮次（Round），这也就对应着 10.2.1 最后图的那个回环过程。
- 有了编译器注解处理的标准API后，程序员的代码才有可能干涉编译器的行为，由于语法树中的任意元素，甚至包括代码注释都可以在插件中被访问到，所以通过插入式注解处理器实现的插件在功能上有很大的发挥空间。
  - 只要有足够的创意，程序员能使用插入式注解处理器来实现许多原本只能在编码中由人工完成的事情。譬如Java著名的编码效率工具 **Lombok**，它可以通过注解来实现自动产生getter/setter方法、进行空置检查、生成受查异常表、产生equals()和hashCode()方法，等等，帮助开发人员消除Java的冗长代码，这些都是依赖插入式注解处理器来实现的
- 在Javac源码中，插入式注解处理器的初始化过程是在initPorcessAnnotations()方法中完成的，而它的执行过程则是在processAnnotations()方法中完成。
  - 这个方法会判断是否还有新的注解处理器需要执行，如果有的话，通过com.sun.tools.javac.processing.JavacProcessing-Environment类的doProcessing()方法来生成一个新的JavaCompiler对象，对编译的后续步骤进行处理。

###### 10.2.4 语义分析与字节码生成

- 经过语法分析之后，编译器获得了程序代码的抽象语法树表示，抽象语法树能够表示一个结构正确的源程序，但无法保证源程序的语义是符合逻辑的。
- 而语义分析的主要任务则是对结构上正确的源程序进行上下文相关性质的检查，譬如进行类型检查、控制流检查、数据流检查，等等。
- 1.标注检查
  - Javac在编译过程中，语义分析过程可分为标注检查和数据及控制流分析两个步骤，分别由 attribute()和flow() 方法完成。
  - 标注检查步骤要检查的内容包括诸如变量使用前是否已被声明、变量与赋值之间的数据类型是否能够匹配，等等
  - 在标注检查中，还会顺便进行一个称为**常量折叠（Constant Folding）**的代码优化，这是Javac编译器会对源代码做的极少量优化措施之一（代码优化几乎都在即时编译器中进行）。
    - 例如 “a=1+2” 优化为 "a=3"
    - 除了字面量，final 修饰的变量也可以
    - 除了基本类型，String 也可以
  - 标注检查步骤在Javac源码中的实现类是 com.sun.tools.javac.comp.Attr 类和 com.sun.tools.javac.comp.Check 类。
- 2.数据及控制流分析
  - 数据流分析和控制流分析是对程序上下文逻辑更进一步的验证，它可以检查出诸如程序局部变量在使用前是否有赋值、方法的每条路径是否都有返回值、是否所有的受查异常都被正确处理了等问题。
  - 编译时期的数据及控制流分析与类加载时的数据及控制流分析的目的基本上可以看作是一致的，但校验范围会有所区别，有一些校验项只有在编译期或运行期才能进行。
    - 对Class文件结构的讲解我们已经知道，局部变量与类的字段（实例变量、类变量）的存储是有显著差别的，局部变量在常量池中并没有CONSTANT_Fieldref_info的符号引用，自然就不可能存储有访问标志（access_flags）的信息，甚至可能连变量名称都不一定会被保留下来（这取决于编译时的编译器的参数选项），自然在Class文件中就不可能知道一个局部变量是不是被声明为final了。
    - 因此，可以肯定地推断出把局部变量声明为final，对运行期是完全没有影响的，变量的不变性仅仅由Javac编译器在编译期间来保障，这就是一个只能在编译期而不能在运行期中检查的例子。
  - 在Javac的源码中，数据及控制流分析的入口 flow() 方法，具体操作由com.sun.tools.javac.comp.Flow类来完成。
- 3.解语法糖
  - 语法糖（Syntactic Sugar），也称糖衣语法，是由英国计算机科学家Peter J.Landin发明的一种编程术语，指的是在计算机语言中添加的某种语法，这种语法对语言的编译结果和功能并没有实际影响，但是却能更方便程序员使用该语言。
  - 通常来说使用语法糖能够减少代码量、增加程序的可读性，从而减少程序代码出错的机会。
  - Java 中最常见的语法糖包括了前面提到过的泛型（其他语言中泛型并不一定都是语法糖实现，如 C# 的泛型就是直接由CLR支持的）、变长参数、自动装箱拆箱，等等，Java虚拟机运行时并不直接支持这些语法，它们在编译阶段被还原回原始的基础语法结构，这个过程就称为解语法糖。
  - 在Javac的源码中，解语法糖的过程由desugar()方法触发，在com.sun.tools.javac.comp.TransTypes类和com.sun.tools.javac.comp.Lower类中完成。
- 4.字节码生成
  - 字节码生成是Javac编译过程的最后一个阶段，在Javac源码里面由com.sun.tools.javac.jvm.Gen类来完成。
  - 字节码生成阶段不仅仅是把前面各个步骤所生成的信息（语法树、符号表）转化成字节码指令写到磁盘中，编译器还进行了少量的代码添加和转换工作。
    - 例如前文多次登场的实例构造器 `<init>()` 方法和类构造器 `<clinit>()` 方法就是在这个阶段被添加到语法树之中的。
    - 除了生成构造器以外，还有其他的一些代码替换工作用于优化程序某些逻辑的实现方式，如把字符串的加操作替换为StringBuffer或StringBuilder（取决于目标代码的版本是否大于或等于JDK 5）的append()操作，等等。
  - 完成了对语法树的遍历和调整之后，就会把填充了所有所需信息的符号表交到com.sun.tools.javac.jvm.ClassWriter类手上，由这个类的writeClass()方法输出字节码，生成最终的Class文件，到此，整个编译过程宣告结束。

##### 10.3 Java 语法糖的味道

###### 10.3.1 泛型

- 泛型的本质是参数化类型（Parameterized Type）或者参数化多态（Parametric Polymorphism）的应用，即可以将操作的数据类型指定为方法签名中的一种特殊参数，这种参数类型能够用在类、接口和方法的创建中，分别构成泛型类、泛型接口和泛型方法。
- 1.Java与C#的泛型
  - 在2004年，Java和C#两门语言于同一年更新了一个重要的大版本，即Java 5.0和C#2.0，在这个大版本中，两门语言又不约而同地各自添加了泛型的语法特性。
  - Java选择的泛型实现方式叫作“类型擦除式泛型”（Type Erasure Generics），而C#选择的泛型实现方式是“具现化式泛型”（Reified Generics）。
    - 具现化和特化、偏特化这些名词最初都是源于C++模版语法中的概念，如果读者本身不使用C++的话，在本节的阅读中可不必太纠结其概念定义，把它当一个技术名词即可，只需要知道C#里面泛型无论在程序源码里面、编译后的中间语言表示（Intermediate Language，这时候泛型是一个占位符）里面，抑或是运行期的CLR里面都是切实存在的，`List<int>` 与 `List<string>` 就是两个不同的类型，它们由系统在运行期生成，有着自己独立的虚方法表和类型数据。
    - 而Java语言中的泛型则不同，它只在程序源码中存在，在编译后的字节码文件中，全部泛型都被替换为原来的裸类型（Raw Type，稍后我们会讲解裸类型具体是什么）了，并且在相应的地方插入了强制转型代码，因此对于运行期的Java语言来说，ArrayList<int>与ArrayList<String>其实是同一个类型，由此读者可以想象“类型擦除”这个名字的含义和来源，这也是为什么笔者会把Java泛型安排在语法糖里介绍的原因。
  - C#2.0引入了泛型之后，带来的显著优势之一便是对比起Java在执行性能上的提高，因为在使用平台提供的容器类型（如 `List<T>`，`Dictionary<TKey, TValue>`）时，无须像Java里那样不厌其烦地拆箱和装箱，如果在Java中要避免这种损失，就必须构造一个与数据类型相关的容器类（譬如IntFloatHashMap这样的容器）。
    - 显然，这除了引入更多代码造成复杂度提高、复用性降低之外，更是丧失了泛型本身的存在价值。
  - Java的类型擦除式泛型无论在使用效果上还是运行效率上，几乎是全面落后于C#的具现化式泛型，而它的唯一优势是在于实现这种泛型的影响范围上：擦除式泛型的实现几乎只需要在Javac编译器上做出改进即可，不需要改动字节码、不需要改动Java虚拟机，也保证了以前没有使用泛型的库可以直接运行在Java 5.0之上。
- 2.泛型的历史背景
  - Martin Odersky（后来Scala语言的缔造者）注意到了刚刚发布一年的Java，并在它上面实现了函数式编程的3大特性：泛型、高阶函数和模式匹配，形成了Scala语言的前身Pizza语言
  - 后来，Java的开发团队找到了Martin Odersky，表示对Pizza语言的泛型功能很感兴趣，他们就一起建立了一个叫作“Generic Java”的新项目，目标是把Pizza语言的泛型单独拎出来移植到Java语言上，其最终成果就是Java 5.0中的那个泛型实现
- 3.类型擦除
  - 引出了“裸类型”（Raw Type）的概念，裸类型应被视为所有该类型泛型化实例的共同父类型（Super Type）
  - 接下来的问题是该如何实现裸类型。这里又有了两种选择：
    - 一种是在运行期由Java虚拟机来自动地、真实地构造出 `ArrayList<Integer>` 这样的类型，并且自动实现从 `ArrayList<Integer>` 派生自 ArrayList 的继承关系来满足裸类型的定义；
    - 另外一种是索性简单粗暴地直接在编译时把 `ArrayList<Integer>` 还原回 ArrayList，只在元素访问、修改时自动插入一些强制类型转换和检查指令，这样看起来也是能满足需要
    - 这两个选择的最终结果大家已经都知道了：后者
  - 类型擦除带来的缺陷前面已经提到过一些，为了系统性地讲述，笔者在此再举3个例子，把前面与C#对比时简要提及的擦除式泛型的缺陷做更具体的说明。
    - 首先，使用擦除法实现泛型直接导致了对原始类型（Primitive Types）数据的支持又成了新的麻烦，因为不支持int、long与Object之间的强制转型。
      - 当时Java给出的解决方案一如既往的简单粗暴：既然没法转换那就索性别支持原生类型的泛型了吧，你们都用 `ArrayList<Integer>`、`ArrayList<Long>`，反正都做了自动的强制类型转换，遇到原生类型时把装箱、拆箱也自动做了得了。
      - 这个决定后面导致了无数构造包装类和装箱、拆箱的开销，成为Java泛型慢的重要原因，也成为今天Valhalla项目要重点解决的问题之一。
    - 第二，运行期无法取到泛型类型信息，会让一些代码变得相当啰嗦
  - 由于Java泛型的引入，各种场景（虚拟机解析、反射等）下的方法调用都可能对原有的基础产生影响并带来新的需求，如在泛型类中如何获取传入的参数化类型等。
    - 所以JCP组织对《Java虚拟机规范》做出了相应的修改，引入了诸如Signature、LocalVariableTypeTable等新的属性用于解决伴随泛型而来的参数类型的识别问题，Signature是其中最重要的一项属性，它的作用就是存储一个方法在字节码层面的特征签名，这个属性中保存的参数类型并不是原生类型，而是包括了参数化类型的信息。
    - 修改后的虚拟机规范要求所有能识别49.0以上版本的Class文件的虚拟机都要能正确地识别Signature参数。
    - 另外，从Signature属性的出现我们还可以得出结论，擦除法所谓的擦除，仅仅是对方法的Code属性中的字节码进行擦除，实际上元数据中还是保留了泛型信息，这也是我们在编码时能通过反射手段取得参数化类型的根本依据。
- 4.值类型与未来的泛型
  - 在2014年，刚好是Java泛型出现的十年之后，Oracle建立了一个名为Valhalla的语言改进项目，希望改进Java语言留下的各种缺陷（解决泛型的缺陷就是项目主要目标其中之一）。
  - 相对于使用不同方式实现泛型，目前比较明确的是未来的Java应该会提供“值类型”（Value Type）的语言层面的支持。
  - 在Valhalla项目中，Java的值类型方案被称为“内联类型”，计划通过一个新的关键字inline来定义，字节码层面也有专门与原生类型对应的以Q开头的新的操作码（譬如iload对应qload）来支撑。

###### 10.3.2 自动装箱、拆箱与遍历循环

- 泛型就不必说了
- 自动装箱、拆箱在编译之后被转化成了对应的包装和还原方法，如本例中的Integer.valueOf()与Integer.intValue()方法
- 而遍历循环则是把代码还原成了迭代器的实现，这也是为何遍历循环需要被遍历的类实现 Iterable 接口的原因
- 最后再看看变长参数，它在调用的时候变成了一个数组类型的参数，在变长参数出现之前，程序员的确也就是使用数组来完成类似功能的。

###### 10.3.3 条件编译

- 许多程序设计语言都提供了条件编译的途径，如C、C++中使用预处理器指示符（#ifdef）来完成条件编译。
- Java语言当然也可以进行条件编译，方法就是使用条件为常量的if语句。
  - 只能使用条件为常量的if语句才能达到上述效果，如果使用常量与其他带有条件判断能力的语句搭配，则可能在控制流分析中提示错误，被拒绝编译
- Java语言中条件编译的实现，也是Java语言的一颗语法糖，根据布尔常量值的真假，编译器将会把分支中不成立的代码块消除掉，这一工作将在编译器解除语法糖阶段（com.sun.tools.javac.comp.Lower类中）完成。



除了本节中介绍的泛型、自动装箱、自动拆箱、遍历循环、变长参数和条件编译之外，Java语言还有不少其他的语法糖，如内部类、枚举类、断言语句、数值字面量、对枚举和字符串的switch支持、try语句中定义和关闭资源（这3个从JDK 7开始支持）、Lambda表达式（从JDK 8开始支持，Lambda不能算是单纯的语法糖，但在前端编译器中做了大量的转换工作），等等，读者可以通过跟踪Javac源码、反编译Class文件等方式了解它们的本质实现，囿于篇幅，笔者就不再一一介绍了。

##### 10.4 实战：插入式注解处理器

#### 11、后端编译与优化

##### 11.1 概述

- 如果我们把字节码看作是程序语言的一种中间表示形式（Intermediate Representation，IR）的话，那编译器无论在何时、在何种状态下把Class文件转换成与本地基础设施（硬件指令集、操作系统）相关的二进制机器码，它都可以视为**整个编译过程的后端**。
- 无论是提前编译器抑或即时编译器，都不是Java虚拟机必需的组成部分
  - 但是，后端编译器编译性能的好坏、代码优化质量的高低却是衡量一款商用虚拟机优秀与否的关键指标之一，它们也是商业Java虚拟机中的核心，是最能体现技术水平与价值的功能。
- 既然《Java虚拟机规范》没有具体的约束规则去限制后端编译器应该如何实现，那这部分功能就完全是与虚拟机具体实现相关的内容，如无特殊说明，本章中所提及的即时编译器都是特指HotSpot虚拟机内置的即时编译器，虚拟机也是特指HotSpot虚拟机。
  - 不过，本章虽然有大量的内容涉及了特定的虚拟机和编译器的实现层面，但主流Java虚拟机中后端编译器的行为会有很多相似相通之处，因此对其他虚拟机来说也具备一定的类比参考价值。

##### 11.2 即时编译器

- 目前主流的两款商用Java虚拟机（HotSpot、OpenJ9）里，Java程序最初都是通过解释器（Interpreter）进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁，就会把这些代码认定为**“热点代码”（Hot Spot Code）**，为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成本地机器码，并以各种手段尽可能地进行代码优化，运行时完成这个任务的后端编译器被称为**即时编译器**。

###### 11.2.1 解释器与编译器

- 尽管并不是所有的Java虚拟机都采用解释器与编译器并存的运行架构，但目前主流的商用Java虚拟机，譬如HotSpot、OpenJ9等，内部都同时包含解释器与编译器
- 解释器与编译器两者各有优势：
  - 当程序需要迅速启动和执行的时候，解释器可以首先发挥作用，省去编译的时间，立即运行。
  - 当程序启动后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，这样可以减少解释器的中间损耗，获得更高的执行效率。
- 当程序运行环境中内存资源限制较大，可以使用解释执行节约内存（如部分嵌入式系统中和大部分的JavaCard应用中就只有解释器的存在），反之可以使用编译执行来提升效率。
- 同时，解释器还可以作为编译器激进优化时后备的“逃生门”（如果情况允许，HotSpot虚拟机中也会采用不进行激进优化的客户端编译器充当“逃生门”的角色），让编译器根据概率选择一些不能保证所有情况都正确，但大多数时候都能提升运行速度的优化手段，当激进优化的假设不成立，如加载了新类以后，类型继承结构出现变化、出现“罕见陷阱”（Uncommon Trap）时可以通过逆优化（Deoptimization）退回到解释状态继续执行，因此在整个Java虚拟机执行架构里，解释器与编译器经常是相辅相成地配合工作
- HotSpot虚拟机中内置了两个（或三个）即时编译器
  - 其中有两个编译器存在已久，分别被称为“客户端编译器”（Client Compiler）和“服务端编译器”（Server Compiler），或者简称为C1编译器和C2编译器（部分资料和JDK源码中C2也叫Opto编译器）
  - 第三个是在 JDK 10 时才出现的、长期目标是代替C2的Graal编译器。Graal编译器目前还处于实验状态，本章将安排出专门的小节对它讲解与实战，在本节里，我们将重点关注传统的C1、C2编译器的工作过程。
- 在分层编译（Tiered Compilation）的工作模式出现以前，HotSpot 虚拟机通常是采用解释器与其中一个编译器直接搭配的方式工作，程序使用哪个编译器，只取决于虚拟机运行的模式，HotSpot 虚拟机会根据自身版本与宿主机器的硬件性能自动选择运行模式，用户也可以使用“-client”或“-server”参数去强制指定虚拟机运行在客户端模式还是服务端模式。
- 无论采用的编译器是客户端编译器还是服务端编译器，解释器与编译器搭配使用的方式在虚拟机中被称为**“混合模式”（Mixed Mode）**
  - 用户也可以使用参数“-Xint”强制虚拟机运行于“解释模式”（Interpreted Mode），这时候编译器完全不介入工作，全部代码都使用解释方式执行。
  - 另外，也可以使用参数“-Xcomp”强制虚拟机运行于“编译模式”（Compiled Mode），这时候将优先采用编译方式执行程序，但是解释器仍然要在编译无法进行的情况下介入执行过程。
  - 可以通过虚拟机的“-version”命令的输出结果显示出这三种模式
- 由于即时编译器编译本地代码需要占用程序运行时间，通常要编译出优化程度越高的代码，所花费的时间便会越长；而且想要编译出优化程度更高的代码，解释器可能还要替编译器收集性能监控信息，这对解释执行阶段的速度也有所影响。
  - 为了在程序启动响应速度与运行效率之间达到最佳平衡，HotSpot 虚拟机在编译子系统中加入了**分层编译**的功能，分层编译的概念其实很早就已经提出，但直到 JDK 6 时期才被初步实现，后来一直处于改进阶段，最终在 JDK 7 的服务端模式虚拟机中作为默认编译策略被开启。
  - 分层编译根据编译器编译、优化的规模与耗时，划分出不同的编译层次，其中包括：
    - 第0层。程序纯解释执行，并且解释器不开启性能监控功能（Profiling）。
    - 第1层。使用客户端编译器将字节码编译为本地代码来运行，进行简单可靠的稳定优化，不开启性能监控功能。
    - 第2层。仍然使用客户端编译器执行，仅开启方法及回边次数统计等有限的性能监控功能。
    - 第3层。仍然使用客户端编译器执行，开启全部性能监控，除了第2层的统计信息外，还会收集如分支跳转、虚方法调用版本等全部的统计信息。
    - 第4层。使用服务端编译器将字节码编译为本地代码，相比起客户端编译器，服务端编译器会启用更多编译耗时更长的优化，还会根据性能监控信息进行一些不可靠的激进优化。
  - 以上层次并不是固定不变的，根据不同的运行参数和版本，虚拟机可以调整分层的数量。
  - 实施分层编译后，解释器、客户端编译器和服务端编译器就会同时工作，热点代码都可能会被多次编译，用客户端编译器获取更高的编译速度，用服务端编译器来获取更好的编译质量，在解释执行的时候也无须额外承担收集性能监控信息的任务，而在服务端编译器采用高复杂度的优化算法时，客户端编译器可先采用简单优化来为它争取更多的编译时间。

###### 11.2.2 编译对象与触发条件

- 在本章概述中提到了在运行过程中会被即时编译器编译的目标是“热点代码”，这里所指的热点代码主要有两类，包括：
  - 被多次调用的方法。
  - 被多次执行的循环体。
- 对于这两种情况，编译的目标对象都是整个方法体，而不会是单独的循环体。
  - 第一种情况，由于是依靠方法调用触发的编译，那编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的即时编译方式。
  - 而对于后一种情况，尽管编译动作是由循环体所触发的，热点只是方法的一部分，但编译器依然必须以整个方法作为编译对象，只是执行入口（从方法第几条字节码指令开始执行）会稍有不同，编译时会传入执行入口点字节码序号（Byte Code Index，BCI）。
    - 这种编译方式因为编译发生在方法执行的过程中，因此被很形象地称为**“栈上替换”（On Stack Replacement，OSR）**，即方法的栈帧还在栈上，方法就被替换了。
- 要知道某段代码是不是热点代码，是不是需要触发即时编译，这个行为称为**“热点探测”（Hot Spot Code Detection）**，其实进行热点探测并不一定要知道方法具体被调用了多少次，目前主流的热点探测判定方式有两种，分别是：
  - **基于采样的热点探测（Sample Based Hot Spot Code Detection）**。采用这种方法的虚拟机会周期性地检查各个线程的调用栈顶，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法”。基于采样的热点探测的好处是实现简单高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可），缺点是很难精确地确认一个方法的热度，容易因为受到线程阻塞或别的外界因素的影响而扰乱热点探测。
  - **基于计数器的热点探测（Counter Based Hot Spot Code Detection）**。采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是“热点方法”。这种统计方法实现起来要麻烦一些，需要为每个方法建立并维护计数器，而且不能直接获取到方法的调用关系。但是它的统计结果相对来说更加精确严谨。
- 这两种探测手段在商用Java虚拟机中都有使用到，譬如J9用过第一种采样热点探测，而在**HotSpot虚拟机**中使用的是**第二种基于计数器**的热点探测方法
  - 为了实现热点计数，HotSpot为每个方法准备了两类计数器：**方法调用计数器（Invocation Counter）**和**回边计数器（Back Edge Counter**，“回边”的意思就是指在循环边界往回跳转）。
  - 当虚拟机运行参数确定的前提下，这两个计数器都有一个明确的阈值，计数器阈值一旦溢出，就会触发即时编译。
    - 我们首先来看看方法调用计数器。
      - 阈值
        - 顾名思义，这个计数器就是用于统计方法被调用的次数，它的默认阈值在客户端模式下是1500次，在服务端模式下是10000次，这个阈值可以通过虚拟机参数 -XX:CompileThreshold来人为设定。
      - 流程
        - 当一个方法被调用时，虚拟机会先检查该方法是否存在被即时编译过的版本，如果存在，则优先使用编译后的本地代码来执行。
        - 如果不存在已被编译过的版本，则将该方法的调用计数器值加一，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阈值。
        - 一旦已超过阈值的话，将会向即时编译器提交一个该方法的代码编译请求。
        - 如果没有做过任何设置，执行引擎默认不会同步等待编译请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被即时编译器编译完成。
        - 当编译工作完成后，这个方法的调用入口地址就会被系统自动改写成新值，下一次调用该方法时就会使用已编译的版本了
      - 在默认设置下，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个**相对的执行频率**，即一段时间之内方法被调用的次数。
        - 当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那该方法的调用计数器就会被减少一半，这个过程被称为方法调用**计数器热度的衰减（Counter Decay）**，而这段时间就称为此方法统计的**半衰周期（Counter Half Life Time）**
        - 进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数 -XX:-UseCounterDecay来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样只要系统运行时间足够长，程序中绝大部分方法都会被编译成本地代码。
        - 另外还可以使用 -XX:CounterHalfLifeTime参数设置半衰周期的时间，单位是秒。
    - 现在我们再来看看另外一个计数器——回边计数器，它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令就称为“回边（Back Edge）”，很显然建立回边计数器统计的目的是为了触发栈上的替换编译。
      - 关于回边计数器的阈值，虽然HotSpot虚拟机也提供了一个类似于方法调用计数器阈值-XX:CompileThreshold的参数-XX:BackEdgeThreshold供用户设置，但是当前的HotSpot虚拟机实际上并未使用此参数，我们必须设置另外一个参数-XX:OnStackReplacePercentage来间接调整回边计数器的阈值，其计算公式有如下两种。
        - 虚拟机运行在客户端模式下，回边计数器阈值计算公式为：方法调用计数器阈值（-XX:CompileThreshold）乘以OSR比率（-XX:OnStackReplacePercentage）除以100。其中-XX:OnStackReplacePercentage默认值为933，如果都取默认值，那客户端模式虚拟机的回边计数器的阈值为13995。
        - 虚拟机运行在服务端模式下，回边计数器阈值的计算公式为：方法调用计数器阈值（-XX:CompileThreshold）乘以（OSR比率（-XX:OnStackReplacePercentage）减去解释器监控比率（-XX:InterpreterProfilePercentage）的差值）除以100。其中 -XX:OnStackReplacePercentage 默认值为140，-XX:InterpreterProfilePercentage 默认值为33，如果都取默认值，那服务端模式虚拟机回边计数器的阈值为10700。
      - 流程
        - 当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否有已经编译好的版本
        - 如果有的话，它将会优先执行已编译的代码，否则就把回边计数器的值加一，然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阈值。
        - 当超过阈值的时候，将会提交一个栈上替换编译请求，并且把回边计数器的值稍微降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果
      - 与方法计数器不同，回边计数器没有计数热度衰减的过程，因此这个计数器统计的就是该方法循环执行的绝对次数。当计数器溢出的时候，它还会把方法计数器的值也调整到溢出状态，这样下次再进入该方法的时候就会执行标准编译过程。

###### 11.2.3 编译过程

- 在默认条件下，无论是方法调用产生的标准编译请求，还是栈上替换编译请求，虚拟机在编译器还未完成编译之前，都仍然将按照解释方式继续执行代码，而编译动作则在后台的编译线程中进行。
- 用户可以通过参数-XX:-BackgroundCompilation来禁止后台编译，后台编译被禁止后，当达到触发即时编译的条件时，执行线程向虚拟机提交编译请求以后将会一直阻塞等待，直到编译过程完成再开始执行编译器输出的本地代码。
- 服务端编译器和客户端编译器的编译过程是有所差别的。
  - 对于客户端编译器来说，它是一个相对简单快速的三段式编译器，主要的关注点在于局部性的优化，而放弃了许多耗时较长的全局优化手段。
    - 在第一个阶段，一个平台独立的前端将字节码构造成一种**高级中间代码表示（High-Level Intermediate Representation，HIR**，即与目标机器指令集无关的中间表示）。HIR使用**静态单分配（Static Single Assignment，SSA）**的形式来代表代码值，这可以使得一些在HIR的构造过程之中和之后进行的优化动作更容易实现。在此之前编译器已经会在字节码上完成一部分基础优化，如**方法内联、常量传播**等优化将会在字节码被构造成HIR之前完成。
    - 在第二个阶段，一个平台相关的后端从HIR中产生**低级中间代码表示（Low-Level Intermediate Representation，LIR**，即与目标机器指令集相关的中间表示），而在此之前会在HIR上完成另外一些优化，如**空值检查消除、范围检查消除**等，以便让HIR达到更高效的代码表示形式。
    - 最后的阶段是在平台相关的后端使用**线性扫描算法（Linear Scan Register Allocation）**在LIR上分配寄存器，并在LIR上做**窥孔（Peephole）优化**，然后产生机器代码。
  - 而服务端编译器则是专门面向服务端的典型应用场景，并为服务端的性能配置针对性调整过的编译器，也是一个能容忍很高优化复杂度的高级编译器，几乎能达到GNU C++编译器使用-O2参数时的优化强度。
    - 它会执行大部分经典的优化动作，如：**无用代码消除（Dead Code Elimination）**、**循环展开（Loop Unrolling）**、**循环表达式外提（Loop Expression Hoisting）**、**消除公共子表达式（Common Subexpression Elimination）**、**常量传播（Constant Propagation）**、**基本块重排序（Basic Block Reordering）**等
    - 还会实施一些与Java语言特性密切相关的优化技术，如**范围检查消除（Range Check Elimination）**、**空值检查消除（Null Check Elimination**，不过并非所有的空值检查消除都是依赖编译器优化的，有一些是代码运行过程中自动优化了）等。
    - 另外，还可能根据解释器或客户端编译器提供的性能监控信息，进行一些不稳定的预测性激进优化，如**守护内联（Guarded Inlining）**、**分支频率预测（Branch Frequency Prediction）**等，本章的下半部分将会挑选上述的一部分优化手段进行分析讲解，在此就先不做展开。
    - 服务端编译采用的寄存器分配器是一个全局图着色分配器，它可以充分利用某些处理器架构（如 RISC）上的大寄存器集合。
    - 以即时编译的标准来看，服务端编译器无疑是比较缓慢的，但它的编译速度依然远远超过传统的静态优化编译器，而且它相对于客户端编译器编译输出的代码质量有很大提高，可以大幅减少本地代码的执行时间，从而抵消掉额外的编译时间开销，所以也有很多非服务端的应用选择使用服务端模式的HotSpot虚拟机来运行。

###### 11.2.4 实战：查看及分析即时编译结果

- 本节中提到的部分运行参数需要FastDebug或SlowDebug优化级别的HotSpot虚拟机才能够支持，Product级别的虚拟机无法使用这部分参数。

##### 11.3 提前编译器

###### 11.3.1 提前编译的优劣得失

- 现在提前编译产品和对其的研究有着两条明显的分支
  - 一条分支是做与传统C、C++编译器类似的，在程序运行之前把程序代码编译成机器码的静态翻译工作；
  - 另外一条分支是把原本即时编译器在运行时要做的编译工作提前做好并保存下来，下次运行到这些代码（譬如公共库代码在被同一台机器其他Java进程使用）时直接把它加载进来使用。
- 笔者将简要介绍三种即时编译器相对于提前编译器的天然优势。
  - 首先，是性能分析制导优化（Profile-Guided Optimization，PGO）。
  - 其次，是激进预测性优化（Aggressive Speculative Optimization），这也已经成为很多即时编译优化措施的基础。
  - 最后，是链接时优化（Link-Time Optimization，LTO），Java语言天生就是动态链接的，一个个Class文件在运行期被加载到虚拟机内存当中，然后在即时编译器里产生优化后的本地代码，这类事情在Java程序员眼里看起来毫无违和之处。

###### 11.3.2 实战：Jaotc 的提前编译

- JDK 9引入了用于支持对Class文件和模块进行提前编译的工具Jaotc，以减少程序的启动时间和到达全速性能的预热时间，但由于这项功能必须针对特定物理机器和目标虚拟机的运行参数来使用，加之限制太多，Java开发人员对此了解、使用普遍比较少
- 目前状态的Jaotc还有许多需要完善的地方，仍难以直接编译SpringBoot、MyBatis这些常见的第三方工具库，甚至在众多Java标准模块中，能比较顺利编译的也只有java.base模块而已。不过随着Graal编译器的逐渐成熟，相信Jaotc前途还是可期的。
- 此外，本书虽然选择Jaotc来进行实战，但同样有发展潜力的Substrate VM也不应被忽视。Jaotc做的提前编译属于本节开头所说的“第二条分支”，即做即时编译的缓存；而Substrate VM则是选择的“第一条分支”，做的是传统的静态提前编译，关于Substrate VM的实战，建议读者自己去尝试一下。

##### 11.4 编译器优化技术

###### 11.4.1 优化技术概览

- OpenJDK的官方Wiki上，HotSpot虚拟机设计团队列出了一个相对比较全面的、即时编译器中采用的优化技术列表

  - 编译器策略（Compiler Tactics）
    - 延迟编译（Delayed Compilation）
    - 分层编译（Tiered Compilation）
    - 栈上替换（On-Stack Replacement）
    - 延迟优化（Delayed Reoptimization）
    - 程序依赖图表示（Program Dependence Graph Representation）
    - 静态单赋值表示（Static Single Assignment Representation）
  - 基于性能监控的优化技术（Profile-Based Techniques）
    - 乐观空值断言（Optimistic Nullness Assertions）
    - 乐观类型断言（Optimistic Type Assertions）
    - 乐观类型增强（Optimistic Type Strengthening）
    - 乐观数组长度增强（Optimistic Array Length Strengthening）
    - 裁剪未被选择的分支（Untaken Branch Pruning）
    - 乐观的多态内联（Optimistic N-Morphic Inlining）
    - 分支频率预测（Branch Frequency Prediction）
    - 调用频率预测（Call Frequency Prediction）
  - 基于证据的优化技术（Proof-Based Techniques）
    - 精确类型推断（Exact Type Inference）
    - 内存值推断（Memory Value Inference）
    - 内存值跟踪（Memory Value Tracking）
    - 常量折叠（Constant Folding）
    - 重组（Reassociation）
    - 操作符退化（Operator Strength Reduction）
    - 空值检查消除（Null Check Elimination）
    - 类型检测退化（Type Test Strength Reduction）
    - 类型检测消除（Type Test Elimination）
    - 代数化简（Algebraic Simplification）
    - 公共子表达式消除（Common Subexpression Elimination）
  - 数据流敏感重写（Flow-Sensitive Rewrites）
    - 条件常量传播（Conditional Constant Propaggation）
    - 基于流承载的类型缩减转换（Flow-Carried Type Narrowing）
    - 无用代码消除（Dead Code Elimination）
  - 语言相关的优化技术（Language-Specific Techniques）
    - 类型继承关系分析（Class Hierarchy Analysis）
    - 去虚拟机化（Devirtualization）
    - 符号常量传播（Symbolic Constant Propagation）
    - 自动装箱消除（Autobox Elimation）
    - 逃逸分析（Escape Analysis）
    - 锁消除（Lock Elision）
    - 锁膨胀（Lock Coarsening）
    - 消除反射（De-Reflection）
  - 内存及代码位置变换（Memory And Placement Transformation）
    - 表达式提升（Expression Hoisting）
    - 表达式下沉（Expression Sinking）
    - 冗余存储消除（Redundant Store Elimination）
    - 相邻存储合并（Adjacent Store Fusion）
    - 交汇点分离（Merge-Point Splitting）
  - 循环变换（Loop Transformation）
    - 循环展开（Loop Unrolling）
    - 循环剥离（Loop Peeling）
    - 安全点消除（Safepoint Elimination）
    - 迭代范围分离（Iteration Range Splitting）
    - 范围检查消除（Range Check Elimination）
    - 循环向量化（Loop Vectorization）
  - 全局代码调整（Global Code Shaping）
    - 内联（Inlining）
    - 全局代码外提（Global Code Motion）
    - 基于热度的代码布局（Heat-Based Code Layout）
    - Switch 调整（Switch Balancing）
  - 控制流图变换（Control Flow Graph Transformation）
    - 本地代码编排（Local Code Scheduling）
    - 本地代码封包（Local Code Bundling）
    - 延迟槽填充（Delay Solt Filling）
    - 着色图寄存器分配（Graph-Coloring Register Allocation）
    - 线性扫描寄存器分配（Linear Scan Register Allocation）
    - 复写聚合（Copy Coalescing）
    - 常量分裂（Constant Splitting）
    - 复写移除（Copy Removal）
    - 地址模式匹配（Address Mode Matching）
    - 指令窥孔优化（Instruction Peepholing）
    - 基于确定有限状态机的代码生成（DFA-Based Code Generator）

- 例子：

  - 第一步，从原始代码开始

    - ```java
      static class B {
          int value;
          final int get() {
          	return value;
          }
      }
      public void foo() {
          y = b.get();
          // ...do stuff...
          z = b.get();
          sum = y + z;
      }
      ```

    - 内容已经非常简化了，但是仍有不少优化的空间。

      - 首先，第一个要进行的优化是方法内联

        - 它的主要目的有两个：

          - 一是去除方法调用的成本（如查找方法版本、建立栈帧等）；
          - 二是为其他优化建立良好的基础。方法内联膨胀之后可以便于在更大范围上进行后续的优化手段，可以获取更好的优化效果。因此各种编译器一般都会把内联优化放在优化序列最靠前的位置。

        - 内联后的代码

        - ```java
          public void foo() {
              y = b.value;
              // ...do stuff...
              z = b.value;
              sum = y + z;
          }
          ```

      - 第二步进行冗余访问消除（Redundant Loads Elimination）

        - 假设代码中间注释掉的“…do stuff…”所代表的操作不会改变b.value的值，那么就可以把“z=b.value”替换为“z=y”，因为上一句“y=b.value”已经保证了变量y与b.value是一致的，这样就可以不再去访问对象b的局部变量了。如果把b.value看作一个表达式，那么也可以把这项优化看作一种公共子表达式消除（Common Subexpression Elimination），优化后的代码如下所示。

        - ```java
          public void foo() {
              y = b.value;
              // ...do stuff...
              z = y;
              sum = y + z;
          }
          ```

      - 第三步进行复写传播（Copy Propagation）

        - 因为这段程序的逻辑之中没有必要使用一个额外的变量z，它与变量y是完全相等的，因此我们可以使用y来代替z。复写传播之后的程序如下所示。

        - ```java
          public void foo() {
              y = b.value;
              // ...do stuff...
              y = y;
              sum = y + y;
          }
          ```

      - 第四步进行无用代码消除（Dead Code Elimination）

        - 无用代码可能是永远不会被执行的代码，也可能是完全没有意义的代码。因此它又被很形象地称为“Dead Code”，在代码清单11-9中，“y=y”是没有意义的，把它消除后的程序如下所示。

        - ```java
          public void foo() {
              y = b.value;
              // ...do stuff...
              sum = y + y;
          }
          ```

  - 经过四次优化之后，代码清单11-10所示代码与代码清单11-6所示代码所达到的效果是一致的，但是前者比后者省略了许多语句，体现在字节码和机器码指令上的差距会更大，执行效率的差距也会更高。

  - 编译器的这些优化技术实现起来也许确实复杂，但是要理解它们的行为，对于一个初学者来说都是没有什么困难的，完全不需要有任何的恐惧心理。

###### 11.4.2 方法内联

- 在前面的讲解中，我们多次提到方法内联，说它是**编译器最重要的优化手段**，甚至都可以不加上“之一”。
- 内联被业内戏称为优化之母，因为除了消除方法调用的成本之外，它更重要的意义是为其他优化手段建立良好的基础
- 方法内联的优化行为理解起来是没有任何困难的，不过就是把目标方法的代码原封不动地“复制”到发起调用的方法之中，避免发生真实的方法调用而已。
- 但实际上Java虚拟机中的内联过程却远没有想象中容易，甚至如果不是即时编译器做了一些特殊的努力，按照经典编译原理的优化理论，大多数的Java方法都无法进行内联。
  - 无法内联的原因其实在第8章中讲解Java方法解析和分派调用的时候就已经解释过：只有使用 invokespecial 指令调用的私有方法、实例构造器、父类方法和使用invokestatic指令调用的静态方法才会在编译期进行解析。
  - 除了上述四种方法之外（最多再除去被final修饰的方法这种特殊情况，尽管它使用invokevirtual指令调用，但也是非虚方法，《Java语言规范》中明确说明了这点），其他的Java方法调用都必须在运行时进行方法接收者的多态选择，它们都有可能存在多于一个版本的方法接收者，简而言之，**Java语言中默认的实例方法是虚方法**。
  - 对于一个虚方法，编译器静态地去做内联的时候很难确定应该使用哪个方法版本
- 那是不是为了提高执行性能，就应该默认给每个方法都使用final关键字去修饰呢？C和C++语言的确是这样做的，默认的方法是非虚方法，如果需要用到多态，就用virtual关键字来修饰，但Java选择了在虚拟机中解决这个问题。
  - 为了解决虚方法的内联问题，Java虚拟机首先引入了一种名为**类型继承关系分析（Class Hierarchy Analysis，CHA）**的技术，这是整个应用程序范围内的类型分析技术，用于确定在目前已加载的类中，某个接口是否有多于一种的实现、某个类是否存在子类、某个子类是否覆盖了父类的某个虚方法等信息。
  - 这样，编译器在进行内联时就会分不同情况采取不同的处理：
    - 如果是非虚方法，那么直接进行内联就可以了，这种的内联是有百分百安全保障的；
    - 如果遇到虚方法，则会向CHA查询此方法在当前程序状态下是否真的有多个目标版本可供选择，如果查询到只有一个版本，那就可以假设“应用程序的全貌就是现在运行的这个样子”来进行内联，这种内联被称为**守护内联（Guarded Inlining）**。
      - 不过由于Java程序是动态连接的，说不准什么时候就会加载到新的类型从而改变CHA结论，因此这种内联属于激进预测性优化，必须预留好“逃生门”，即当假设条件不成立时的“退路”（Slow Path）。
      - 假如在程序的后续执行过程中，虚拟机一直没有加载到会令这个方法的接收者的继承关系发生变化的类，那这个内联优化的代码就可以一直使用下去。
      - 如果加载了导致继承关系发生变化的新类，那么就必须抛弃已经编译的代码，退回到解释状态进行执行，或者重新进行编译。
    - 假如向CHA查询出来的结果是该方法确实有多个版本的目标方法可供选择，那即时编译器还将进行最后一次努力，使用**内联缓存（Inline Cache）**的方式来缩减方法调用的开销。
      - 这种状态下方法调用是真正发生了的，但是比起直接查虚方法表还是要快一些。内联缓存是一个建立在目标方法正常入口之前的缓存，它的工作原理大致为：在未发生方法调用之前，内联缓存状态为空，当第一次调用发生后，缓存记录下方法接收者的版本信息，并且每次进行方法调用时都比较接收者的版本。如果以后进来的每次调用的方法接收者版本都是一样的，那么这时它就是一种**单态内联缓存（Monomorphic Inline Cache）**。
        - 通过该缓存来调用，比用不内联的非虚方法调用，仅多了一次类型判断的开销而已。
      - 但如果真的出现方法接收者不一致的情况，就说明程序用到了虚方法的多态特性，这时候会退化成**超多态内联缓存（Megamorphic Inline Cache）**，其开销相当于真正查找虚方法表来进行方法分派。

###### 11.4.3 逃逸分析

- **逃逸分析（Escape Analysis）**是目前Java虚拟机中比较前沿的优化技术，它与类型继承关系分析一样，并不是直接优化代码的手段，而是为其他优化措施提供依据的分析技术。
- 逃逸分析的基本原理是：
  - 分析对象动态作用域，当一个对象在方法里面被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他方法中，这种称为**方法逃逸**；
  - 甚至还有可能被外部线程访问到，譬如赋值给可以在其他线程中访问的实例变量，这种称为**线程逃逸**；
  - 从不逃逸、方法逃逸到线程逃逸，称为对象由低到高的不同逃逸程度。
- 如果能证明一个对象不会逃逸到方法或线程之外（换句话说是别的方法或线程无法通过任何途径访问到这个对象），或者逃逸程度比较低（只逃逸出方法而不会逃逸出线程），则可能为这个对象实例采取不同程度的优化，如：
  - **栈上分配（Stack Allocations）**：在Java虚拟机中，Java堆上分配创建对象的内存空间几乎是Java程序员都知道的常识，Java堆中的对象对于各个线程都是共享和可见的，只要持有这个对象的引用，就可以访问到堆中存储的对象数据。
    - 虚拟机的垃圾收集子系统会回收堆中不再使用的对象，但回收动作无论是标记筛选出可回收对象，还是回收和整理内存，都需要耗费大量资源。
    - 如果确定一个对象不会逃逸出线程之外，那让这个对象在栈上分配内存将会是一个很不错的主意，对象所占用的内存空间就可以随栈帧出栈而销毁。
    - 在一般应用中，完全不会逃逸的局部对象和不会逃逸出线程的对象所占的比例是很大的，如果能使用栈上分配，那大量的对象就会随着方法的结束而自动销毁了，垃圾收集子系统的压力将会下降很多。
    - 栈上分配**可以支持方法逃逸，但不能支持线程逃逸**。
  - **标量替换（Scalar Replacement）**：若一个数据已经无法再分解成更小的数据来表示了，Java虚拟机中的原始数据类型（int、long等数值类型及reference类型等）都不能再进一步分解了，那么这些数据就可以被称为**标量**。相对的，如果一个数据可以继续分解，那它就被称为**聚合量（Aggregate）**，Java中的对象就是典型的聚合量。如果把一个Java对象拆散，根据程序访问的情况，将其用到的成员变量恢复为原始类型来访问，这个过程就称为**标量替换**。
    - 假如逃逸分析能够证明一个对象不会被方法外部访问，并且这个对象可以被拆散，那么程序真正执行的时候将可能不去创建这个对象，而改为直接创建它的若干个被这个方法使用的成员变量来代替。
    - 将对象拆分后，除了可以让对象的成员变量在栈上（栈上存储的数据，很大机会被虚拟机分配至物理机器的高速寄存器中存储）分配和读写之外，还可以为后续进一步的优化手段创建条件。
    - 标量替换可以视作栈上分配的一种特例，实现更简单（不用考虑整个对象完整结构的分配），但对逃逸程度的要求更高，它不允许对象逃逸出方法范围内。
  - **同步消除（Synchronization Elimination）**：线程同步本身是一个相对耗时的过程，如果逃逸分析能够确定一个变量不会逃逸出线程，无法被其他线程访问，那么这个变量的读写肯定就不会有竞争，对这个变量实施的同步措施也就可以安全地消除掉。
- C和C++语言里面原生就支持了栈上分配（不使用new操作符即可），而C#也支持值类型，可以很自然地做到标量替换（但并不会对引用类型做这种优化）。在灵活运用栈内存方面，确实是Java的一个弱项。
- 在现在仍处于实验阶段的Valhalla项目里，设计了新的inline关键字用于定义Java的内联类型，目的是实现与C#中值类型相对标的功能。有了这个标识与约束，以后逃逸分析做起来就会简单很多。
- 曾经在很长的一段时间里，即使是服务端编译器，也默认不开启逃逸分析，甚至在某些版本（如JDK 6 Update 18）中还曾经完全禁止了这项优化，一直到JDK 7时这项优化才成为**服务端编译器默认开启**的选项。
  - 如果有需要，或者确认对程序运行有益，用户也可以使用:
    - 参数-XX:+DoEscapeAnalysis来手动开启逃逸分析，开启之后可以通过参数-XX:+PrintEscapeAnalysis来查看分析结果。
  - 有了逃逸分析支持之后，用户可以使用:
    - 参数-XX:+EliminateAllocations来开启标量替换
    - 使用 +XX:+EliminateLocks 来开启同步消除
    - 使用参数-XX:+PrintEliminateAllocations查看标量的替换情况。

###### 11.4.4 公共子表达式消除

- 公共子表达式消除是一项非常经典的、普遍应用于各种编译器的优化技术，它的含义是：如果一个表达式E之前已经被计算过了，并且从先前的计算到现在E中所有变量的值都没有发生变化，那么E的这次出现就称为公共子表达式。
- 对于这种表达式，没有必要花时间再对它重新进行计算，只需要直接用前面计算过的表达式结果代替E。
  - 如果这种优化仅限于程序基本块内，便可称为**局部公共子表达式消除（Local Common Subexpression Elimination）**
  - 如果这种优化的范围涵盖了多个基本块，那就称为**全局公共子表达式消除（Global Common Subexpression Elimination）**。
- 编译器还可能（取决于哪种虚拟机的编译器以及具体的上下文而定）进行另外一种优化——**代数化简（Algebraic Simplification）**
  - `int d = E * 12 + a + (a + E);` -> `int d = E * 13 + a + a;`
- 如果读者还对其他的经典编译优化技术感兴趣，可以参考《编译原理》（俗称龙书）中的相关章节。

###### 11.4.5 数组边界检查消除

- 数组边界检查消除（Array Bounds Checking Elimination）是即时编译器中的一项语言相关的经典优化技术。
- 为了安全，数组边界检查肯定是要做的，但数组边界检查是不是必须在运行期间一次不漏地进行则是可以“商量”的事情。
  - 简单的情况：数组下标是一个常量，如 foo[3]，只要在编译期根据数据流分析来确定foo.length的值，并判断下标“3”没有越界，执行的时候就无须判断了。
  - 更加常见的情况是，数组访问发生在循环之中，并且使用循环变量来进行数组的访问。如果编译器只要通过数据流分析就可以判定循环变量的取值范围永远在区间[0，foo.length)之内，那么在循环中就可以把整个数组的上下界检查消除掉，这可以节省很多次的条件判断操作。
- 比如：数组越界会得到ArrayIndexOutOfBoundsException异常；空指针访问会得到NullPointException异常；除数为零会得到ArithmeticException异常……
  - 这些安全检查也导致出现相同的程序，从而使Java比C和C++要做更多的事情（各种检查判断），这些事情就会导致一些隐式开销，如果不处理好它们，就很可能成为一项“Java语言天生就比较慢”的原罪。
  - 为了消除这些隐式开销，除了如数组边界检查优化这种尽可能把运行期检查提前到编译期完成的思路之外，还有一种避开的处理思路——**隐式异常处理**
    - Java中空指针检查和算术运算中除数为零的检查都采用了这种方案。
- 与语言相关的其他消除操作还有不少，如自动装箱消除（Autobox Elimination）、安全点消除（Safepoint Elimination）、消除反射（Dereflection）等，这里就不再一一介绍了。

##### 11.5 实战：深入理解 Graal 编译器

- 从JDK 10起，HotSpot就同时拥有三款不同的即时编译器。此前我们已经介绍了经典的客户端编译器和服务端编译器，在本节，我们将把目光聚焦到HotSpot即时编译器以及提前编译器共同的最新成果——Graal编译器身上。

###### 11.5.1 历史背景

###### 11.5.2 构建编译调试环境

###### 11.5.3 JVMCI 编译器接口

###### 11.5.4 代码中间表示

###### 11.5.5 代码优化和生成

## 内存模型与线程

### 具体问题

- Java 内存模型
- Java内存模型
- jvm内存模型jmm 知道的全讲讲
- jvm内存模型
- jvm内存模型
- JVM内存模型
- jvm的内存模型
- 讲一讲java的内存模型
- JAVA内存区域（堆 栈等） JAVA内存模型（工作内存 主内存等）
- jvm内存模型，如何分配内存
- 写屏障和读屏障的区别是什么？
- mesi协议（缓存一致性协议）
- 内存屏障
- Java内存模型说一下
- JVM的内存模型 （我开始以为他问的是工作内存和主内存），他说不是，不用讲这些，他说记住我问的问题，我说您问的是栈，堆之类吗？他说是的，然后就给他解释（我一直记得内存结构是这些，内存模型是工作内存和主内存，还特意区分了）  
- volatile 的作用是什么
  - 防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性
  - 会主动刷新存储

- JVM 内存模型和垃圾回收；
- 讲一下  JMM
- 讲解一下 JVM 内存模型；
- 讲解一下 JVM 的内存模型；
- 讲讲 JMM
- JVM 的内存模型？运行时是怎么运作的？

### 思考方向

Java 内存模型与线程

#### 12.2 硬件的效率与一致性

- 由于计算机的存储设备与处理器的运算速度有着几个数量级的差距，所以现代计算机系统都不得不加入一层或多层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。
- 基于高速缓存的存储交互很好地解决了处理器与内存速度之间的矛盾，但是也为计算机系统带来更高的复杂度，它引入了一个新的问题：**缓存一致性（Cache Coherence）**。
  - 在多路处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），这种系统称为共享内存多核系统（Shared Memory Multiprocessors System）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。
  - 如果真的发生这种情况，那同步回到主内存时该以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。
    - **MESI 详解**
      - MESI 指的是缓存行的四种状态（Modified，Exclusive，Shared， Invalid），用 2 个 bit 表示。
- 从本章开始，我们将会频繁见到“**内存模型**”一词，它可以理解为在特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。
  - 不同架构的物理机器可以拥有不一样的内存模型，而Java虚拟机也有自己的内存模型，并且与这里介绍的内存访问操作及硬件的缓存访问操作具有高度的可类比性。
- 除了增加高速缓存之外，为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行**乱序执行（Out-Of-Order Execution）优化**，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。
  - 与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有**指令重排序（Instruction Reorder）优化**。

#### 12.3 Java 内存模型

- 《Java虚拟机规范》中曾试图定义一种**“Java内存模型” （Java Memory Model，JMM）**来屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。
  - 在此之前，主流程序语言（如C和C++等）直接使用物理硬件和操作系统的内存模型。因此，由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错，所以在某些场景下必须针对不同的平台来编写程序
- 定义Java内存模型并非一件容易的事情
  - 这个模型必须定义得足够严谨，才能让Java的并发内存访问操作不会产生歧义；
  - 但是也必须定义得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取更好的执行速度。
- 经过长时间的验证和修补，直至 **JDK 5**（实现了JSR-133 ）发布后，Java内存模型才终于成熟、完善起来了。

##### 12.3.1 主内存与工作内存

- Java 内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。
  - 此处的变量（Variables）与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。
  - 为了获得更好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器是否要进行调整代码执行顺序这类优化措施。
- Java内存模型规定了所有的变量都存储在**主内存（Main Memory）**中（此处的主内存与介绍物理硬件时提到的主内存名字一样，两者也可以类比，但物理上它仅是虚拟机内存的一部分）。
- 每条线程还有自己的**工作内存（Working Memory**，可与前面讲的处理器高速缓存类比）
  - 线程的工作内存中保存了被该线程使用的变量的主内存副本
  - 线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。
  - 不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成
- 这里所讲的主内存、工作内存与第2章所讲的Java内存区域中的Java堆、栈、方法区等并不是同一个层次的对内存的划分，这两者基本上是没有任何关系的。
  - 如果两者一定要勉强对应起来，那么从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。
  - 从更基础的层次上说，主内存直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（或者是硬件、操作系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问的是工作内存。

##### 12.3.2 内存间交互操作

- 关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存这一类的实现细节，Java内存模型中定义了以下8种操作来完成。
- Java虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外，这个问题在12.3.4节会专门讨论）
  - lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。
  - unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
  - read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。
  - load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
  - use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。
  - assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
  - store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。
  - write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。
- 如果要把一个变量从主内存拷贝到工作内存，那就要按顺序执行read和load操作，如果要把变量从工作内存同步回主内存，就要按顺序执行store和write操作。
  - 注意，Java内存模型只要求上述两个操作必须按顺序执行，但不要求是连续执行。
  - 也就是说read与load之间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能出现的顺序是read a、read b、load b、load a。
- 除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：
  - 不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者工作内存发起回写了但主内存不接受的情况出现。
  - 不允许一个线程丢弃它最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。
  - 不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。·一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use、store操作之前，必须先执行assign和load操作。
  - 一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。
  - 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作以初始化变量的值。
  - 如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。
  - 对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）。
- 这8种内存访问操作以及上述规则限定，再加上稍后会介绍的专门针对volatile的一些特殊规定，就已经能准确地描述出Java程序中哪些内存访问操作在并发下才是安全的。
  - 这种定义相当严谨，但也是极为烦琐，实践起来更是无比麻烦。
  - 可能部分读者阅读到这里已经对多线程开发产生恐惧感了，后来Java设计团队大概也意识到了这个问题，将Java内存模型的操作简化为read、write、lock和unlock四种，但这只是语言描述上的等价化简，Java内存模型的基础设计并未改变，即使是这四操作种，对于普通用户来说阅读使用起来仍然并不方便。
  - 不过读者对此无须过分担忧，除了进行虚拟机开发的团队外，大概没有其他开发人员会以这种方式来思考并发问题，我们只需要理解 Java 内存模型的定义即可。
  - 12.3.6节将介绍这种定义的一个等效判断原则——先行发生原则，用来确定一个操作在并发环境下是否安全的。

##### 12.3.3 对于 volatile 型变量的特殊规则

- 关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制
- 当一个变量被定义成volatile之后，它将具备两项特性：
  - 第一项是**保证此变量对所有线程的可见性**
    - 这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。
    - 而普通变量并不能做到这一点，普通变量的值在线程间传递时均需要通过主内存来完成。
    - 比如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线程A回写完成了之后再对主内存进行读取操作，新变量值才会对线程B可见。
    - 但是Java里面的运算操作符并非原子操作，这导致volatile变量的运算在并发下一样是不安全的
      - 问题就出在自增运算“race++”之中，我们用Javap反编译这段代码后会得到代码清单12-2所示，发现只有一行代码的increase()方法在Class文件中是由4条字节码指令构成（return指令不是由race++产生的，这条指令可以不计算）
      - 实事求是地说，笔者使用字节码来分析并发问题仍然是不严谨的，因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。
        - 一条字节码指令在解释执行时，解释器要运行许多行代码才能实现它的语义。
        - 如果是编译执行，一条字节码指令也可能转化成若干条本地机器码指令。
      - 此处使用-XX：+PrintAssembly参数输出反汇编来分析才会更加严谨一些，但是考虑到读者阅读的方便性，并且字节码已经能很好地说明问题，所以此处使用字节码来解释。
    - 由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁（使用synchronized、java.util.concurrent中的锁或原子类）来保证原子性：
      - 运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。
      - 变量不需要与其他的状态变量共同参与不变约束。
  - 使用volatile变量的第二个语义是**禁止指令重排序优化**
    - 普通的变量仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。
      - 因为在同一个线程的方法执行过程中无法感知到这点，这就是Java内存模型中描述的所谓“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。
    - 通过对比发现，关键变化在于有 volatile 修饰的变量，赋值后（前面 `mov %eax，0x150(%esi)` 这句便是赋值操作）多执行了一个“`lock addl $0x0，(%esp)`”操作，这个操作的作用相当于一个内存屏障（Memory Barrier或Memory Fence，指重排序时不能把后面的指令重排序到内存屏障之前的位置，**注意不要与第3章中介绍的垃圾收集器用于捕获变量访问的内存屏障互相混淆**），只有一个处理器访问内存时，并不需要内存屏障；但如果有两个或更多处理器访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。
      - 这里的关键在于 lock 前缀，查询IA32手册可知，它的作用是将本处理器的缓存写入了内存，该写入动作也会引起别的处理器或者别的内核无效化（Invalidate）其缓存，这种操作相当于对缓存中的变量做了一次前面介绍Java内存模式中所说的“store和write”操作[4]。所以通过这样一个空操作，可让前面volatile变量的修改对其他处理器立即可见。
- 我们再回头来看看Java内存模型中对volatile变量定义的特殊规则的定义。假定T表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、assign、store和write操作时需要满足如下规则：
  - 只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行load动作。线程T对变量V的use动作可以认为是和线程T对变量V的load、read动作相关联的，必须连续且一起出现。
    - 这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量V所做的修改。
  - 只有当线程T对变量V执行的前一个动作是assign的时候，线程T才能对变量V执行store动作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行assign动作。线程T对变量V的assign动作可以认为是和线程T对变量V的store、write动作相关联的，必须连续且一起出现。
    - 这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程可以看到自己对变量V所做的修改。
  - 假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load或store动作，假定动作P是和动作F相应的对变量V的read或write动作；与此类似，假定动作B是线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假定动作Q是和动作G相应的对变量W的read或write动作。如果A先于B，那么P先于Q。
    - 这条规则要求volatile修饰的变量不会被指令重排序优化，从而保证代码的执行顺序与程序的顺序相同。

##### 12.3.4 针对 long 和 double 型变量的特殊规则

- Java内存模型要求lock、unlock、read、load、assign、use、store、write这八种操作都具有原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性，这就是所谓的“long和double的非原子性协定”（Non-Atomic Treatment of double and long Variables）。
- 在目前主流平台下商用的64位Java虚拟机中并不会出现非原子性访问行为，但是对于32位的Java虚拟机，譬如比较常用的32位x86平台下的HotSpot虚拟机，对long类型的数据确实存在非原子性访问的风险。
- 笔者的看法是，在实际开发中，除非该数据有明确可知的线程竞争，否则我们在编写代码时一般不需要因为这个原因刻意把用到的long和double变量专门声明为volatile。

##### 12.3.5 原子性、可见性与有序性

- Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的，我们逐个来看一下哪些操作实现了这三个特性。
  - 1.原子性（Atomicity）
    - 由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write这六个，我们大致可以认为，基本数据类型的访问、读写都是具备原子性的（例外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况）。
    - 如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作。
      - 这两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块之间的操作也具备原子性。
  - 2.可见性（Visibility）
    - 可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。上文在讲解volatile变量的时候我们已详细讨论过这一点。
    - Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此。
      - 普通变量与volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。因此我们可以说volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点。
    - 除了volatile之外，Java还有两个关键字能实现可见性，它们是synchronized和final。
      - 同步块的可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）”这条规则获得的。
      - 而final关键字的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那么在其他线程中就能看见final字段的值。
  - 3.有序性（Ordering）
    - Java内存模型的有序性在前面讲解volatile时也比较详细地讨论过了，Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。
      - 前半句是指“线程内似表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。
    - Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性
      - volatile关键字本身就包含了禁止指令重排序的语义
      - 而synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。

##### 12.3.6 先行发生原则

- 如果Java内存模型中所有的有序性都仅靠volatile和synchronized来完成，那么有很多操作都将会变得非常啰嗦，但是我们在编写Java并发代码的时候并没有察觉到这一点，这是因为Java语言中有一个“先行发生”（Happens-Before）的原则。
  - 这个原则非常重要，它是判断数据是否存在竞争，线程是否安全的非常有用的手段。
  - 依赖这个原则，我们可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题，而不需要陷入Java内存模型苦涩难懂的定义之中。
- 现在就来看看“先行发生”原则指的是什么。先行发生是Java内存模型中定义的两项操作之间的偏序关系，比如说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。
- 下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来，则它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。
  - **程序次序规则（Program Order Rule）**：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
  - **管程锁定规则（Monitor Lock Rule）**：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。
  - **volatile变量规则（Volatile Variable Rule）**：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。
  - **线程启动规则（Thread Start Rule）**：Thread对象的start()方法先行发生于此线程的每一个动作。
  - **线程终止规则（Thread Termination Rule）**：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。
  - **线程中断规则（Thread Interruption Rule）**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。
  - **对象终结规则（Finalizer Rule）**：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize()方法的开始。
  - **传递性（Transitivity）**：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。
- Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些

#### 12.4 Java 与线程

##### 12.4.1 线程的实现

- 我们知道，线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以独立调度。
- 目前线程是Java里面进行处理器资源调度的最基本单位，不过如果日后Loom项目能成功为Java引入纤程（Fiber）的话，可能就会改变这一点。
- 实现线程主要有三种方式：使用内核线程实现（1：1实现），使用用户线程实现（1：N实现），使用用户线程加轻量级进程混合实现（N：M实现）。
  - 1.内核线程实现
    - 使用内核线程实现的方式也被称为1：1实现。
      - 内核线程（Kernel-Level Thread，KLT）就是直接由操作系统内核（Kernel，下称内核）支持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行调度，并负责将线程的任务映射到各个处理器上。
      - 每个内核线程可以视为内核的一个分身，这样操作系统就有能力同时处理多件事情，支持多线程的内核就称为多线程内核（Multi-Threads Kernel）。
    - 程序一般不会直接使用内核线程，而是使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型
    - 由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使其中某一个轻量级进程在系统调用中被阻塞了，也不会影响整个进程继续工作。
    - 轻量级进程也具有它的局限性：
      - 首先，由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要进行系统调用。而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（Kernel Mode）中来回切换。
      - 其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是有限的。
  - 2.用户线程实现
    - 使用用户线程实现的方式被称为1：N实现。
    - 广义上来讲，一个线程只要不是内核线程，都可以认为是用户线程（User Thread，UT）的一种，因此从这个定义上看，轻量级进程也属于用户线程，但轻量级进程的实现始终是建立在内核之上的，许多操作都要进行系统调用，因此效率会受到限制，并不具备通常意义上的用户线程的优点。
    - 而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到用户线程的存在及如何实现的。
      - 用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。
      - 如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也能够支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。
      - 这种进程与用户线程之间1：N的关系称为一对多的线程模型
    - 用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有的线程操作都需要由用户程序自己去处理。
      - 线程的创建、销毁、切换和调度都是用户必须考虑的问题，而且由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至有些是不可能实现的。
    - 因为使用用户线程实现的程序通常都比较复杂，除了有明确的需求外（譬如以前在不支持多线程的操作系统中的多线程程序、需要支持大规模线程数量的应用），一般的应用程序都不倾向使用用户线程。
      - Java、Ruby等语言都曾经使用过用户线程，最终又都放弃了使用它。
      - 但是近年来许多新的、以高并发为卖点的编程语言又普遍支持了用户线程，譬如Golang、Erlang等，使得用户线程的使用率有所回升。
  - 3.混合实现
    - 线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用户线程一起使用的实现方式，被称为N：M实现。
    - 在这种混合实现下，既存在用户线程，也存在轻量级进程。
      - 用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并且可以支持大规模的用户线程并发。
      - 而操作系统支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，这大大降低了整个进程被完全阻塞的风险。
      - 在这种混合模式中，用户线程与轻量级进程的数量比是不定的，是N：M的关系，这种就是多对多的线程模型。
    - 许多UNIX系列的操作系统，如Solaris、HP-UX等都提供了M：N的线程模型实现。在这些操作系统上的应用也相对更容易应用M：N的线程模型。
  - 4.Java线程的实现
    - 但从JDK 1.3起，“主流”平台上的“主流”商用Java虚拟机的线程模型普遍都被替换为基于操作系统原生线程模型来实现，即采用1：1的线程模型。
    - 以HotSpot为例，它的每一个Java线程都是直接映射到一个操作系统原生线程来实现的，而且中间没有额外的间接结构，所以HotSpot自己是不会去干涉线程调度的（可以设置线程优先级给操作系统提供调度建议），全权交给底下的操作系统去处理，所以何时冻结或唤醒线程、该给线程分配多少处理器执行时间、该把线程安排给哪个处理器核心去执行等，都是由操作系统完成的，也都是由操作系统全权决定的。
- 操作系统支持怎样的线程模型，在很大程度上会影响上面的Java虚拟机的线程是怎样映射的，这一点在不同的平台上很难达成一致，因此《Java虚拟机规范》中才不去限定Java线程需要使用哪种线程模型来实现。
  - 线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码和运行过程来说，这些差异都是完全透明的。

##### 12.4.2 Java 线程调度

- 线程调度是指系统为线程分配处理器使用权的过程，调度主要方式有两种，分别是协同式（Cooperative Threads-Scheduling）线程调度和抢占式（Preemptive Threads-Scheduling）线程调度。
  - Java使用的线程调度方式就是抢占式调度。
- 不过，线程优先级并不是一项稳定的调节手段，很显然因为主流虚拟机上的Java线程是被映射到系统的原生线程上来实现的，所以线程调度最终还是由操作系统说了算。

##### 12.4.3 状态转换

- Java语言定义了6种线程状态，在任意一个时间点中，一个线程只能有且只有其中的一种状态，并且可以通过特定的方法在不同状态之间转换。这6种状态分别是：
  - 新建（New）：创建后尚未启动的线程处于这种状态。
  - 运行（Runnable）：包括操作系统线程状态中的Running和Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着操作系统为它分配执行时间。
  - 无限期等待（Waiting）：处于这种状态的线程不会被分配处理器执行时间，它们要等待被其他线程显式唤醒。以下方法会让线程陷入无限期的等待状态：
    - 没有设置Timeout参数的Object::wait()方法；
    - 没有设置Timeout参数的Thread::join()方法；
    - LockSupport::park()方法。
  - 限期等待（Timed Waiting）：处于这种状态的线程也不会被分配处理器执行时间，不过无须等待被其他线程显式唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程进入限期等待状态：
    - Thread::sleep()方法；
    - 设置了Timeout参数的Object::wait()方法；
    - 设置了Timeout参数的Thread::join()方法；
    - LockSupport::parkNanos()方法；
    - LockSupport::parkUntil()方法。
  - 阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是“阻塞状态”在等待着获取到一个排它锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将进入这种状态。
  - 结束（Terminated）：已终止线程的线程状态，线程已经结束执行。

#### 12.5 Java 与协程

##### 12.5.1 内核线程的局限

- Java目前的并发编程机制就与上述架构趋势产生了一些矛盾，1：1的内核线程模型是如今Java虚拟机线程实现的主流选择，但是这种映射到操作系统上的线程天然的缺陷是切换、调度成本高昂，系统能容纳的线程数量也很有限。
- 传统的Java Web服务器的线程池的容量通常在几十个到两百之间，当程序员把数以百万计的请求往线程池里面灌时，系统即使能处理得过来，但其中的切换损耗也是相当可观的。

##### 12.5.2 协程的复苏

- 内核线程的调度成本主要来自于用户态与核心态之间的状态转换，而这两种状态转换的开销主要来自于响应中断、保护和恢复执行现场的成本。
- 由于最初多数的用户线程是被设计成协同式调度（Cooperative Scheduling）的，所以它有了一个别名——**“协程”（Coroutine）**。
  - 又由于这时候的协程会完整地做调用栈的保护、恢复工作，所以今天也被称为“有栈协程”（Stackfull Coroutine），起这样的名字是为了便于跟后来的“无栈协程”（Stackless Coroutine）区分开。
  - 无栈协程不是本节的主角，不过还是可以简单提一下它的典型应用，即各种语言中的await、async、yield这类关键字。
    - 无栈协程本质上是一种有限状态机，状态保存在闭包里，自然比有栈协程恢复调用栈要轻量得多，但功能也相对更有限。
- 协程的主要优势是轻量，无论是有栈协程还是无栈协程，都要比传统内核线程要轻量得多。
- 协程当然也有它的局限，需要在应用层面实现的内容（调用栈、调度器这些）特别多，这个缺点就不赘述了。
  - 具体到Java语言，还会有一些别的限制，譬如HotSpot这样的虚拟机，Java调用栈跟本地调用栈是做在一起的。
  - 如果在协程中调用了本地方法，还能否正常切换协程而不影响整个线程？
  - 另外，如果协程中遇传统的线程同步措施会怎样？譬如Kotlin提供的协程实现，一旦遭遇synchronize关键字，那挂起来的仍将是整个线程。

##### 12.5.3 Java 的解决方案

- 对于有栈协程，有一种特例实现名为纤程（Fiber），这个词最早是来自微软公司，后来微软还推出过系统层面的纤程包来方便应用做现场保存、恢复和纤程调度。
  - OpenJDK在2018年创建了Loom项目，这是Java用来应对本节开篇所列场景的官方解决方案，根据目前公开的信息，如无意外，日后该项目为Java语言引入的、与现在线程模型平行的新并发编程机制中应该也会采用“纤程”这个名字，不过这显然跟微软是没有任何关系的。(注：然而 JDK 21 实际引入时叫的是“虚拟线程”)
  - 从Oracle官方对“什么是纤程”的解释里可以看出，它就是一种典型的有栈协程
- 在新并发模型下，一段使用纤程并发的代码会被分为两部分——执行过程（Continuation）和调度器（Scheduler）。

## 线程安全与锁优化

### 具体问题

- 字节码头部有哪些组成？说说锁标记和锁升级
- 偏向锁、轻量级锁是怎么做到的，我回答的是每个对象都有对象头，对象头里做的标记，然后他问我对象头里有哪些信息

### 思考方向

线程安全与锁优化

#### 13.2 线程安全

- 笔者认为《Java并发编程实战（Java Concurrency In Practice）》的作者Brian Goetz为“线程安全”做出了一个比较恰当的定义：“当多个线程同时访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获得正确的结果，那就称这个对象是线程安全的。”
  - 这个定义就很严谨而且有可操作性，它要求线程安全的代码都必须具备一个共同特征：代码本身封装了所有必要的正确性保障手段（如互斥同步等），令调用者无须关心多线程下的调用问题，更无须自己实现任何措施来保证多线程环境下的正确调用。
  - 这点听起来简单，但其实并不容易做到，在许多场景中，我们都会将这个定义弱化一些。如果把“调用这个对象的行为”限定为“单次调用”，这个定义的其他描述能够成立的话，那么就已经可以称它是线程安全了。

##### 13.2.1 Java 语言中的线程安全

- 按照线程安全的“安全程度”由强至弱来排序，我们可以将Java语言中各种操作共享的数据分为以下五类：不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。
  - 1.不可变
    - 在Java语言里面（特指JDK 5以后，即Java内存模型被修正之后的Java语言），不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何线程安全保障措施。
      - 在第10章里我们讲解“final关键字带来的可见性”时曾经提到过这一点：只要一个不可变的对象被正确地构建出来（即没有发生this引用逃逸的情况），那其外部的可见状态永远都不会改变，永远都不会看到它在多个线程之中处于不一致的状态。
      - “不可变”带来的安全性是最直接、最纯粹的。
    - Java语言中，如果多线程共享的数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。
    - 如果共享数据是一个对象，由于Java语言目前暂时还没有提供值类型的支持，那就需要对象自行保证其行为不会对其状态产生任何影响才行。
      - 不妨类比java.lang.String类的对象实例，它是一个典型的不可变对象，用户调用它的substring()、replace()和concat()这些方法都不会影响它原来的值，只会返回一个新构造的字符串对象。
  - 2.绝对线程安全
    - 绝对的线程安全能够完全满足Brian Goetz给出的线程安全的定义，这个定义其实是很严格的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”可能需要付出非常高昂的，甚至不切实际的代价。
      - 在Java API中标注自己是线程安全的类，大多数都不是绝对的线程安全。
      - 对Vector线程安全的测试：很明显，尽管这里使用到的Vector的get()、remove()和size()方法都是同步的，但是在多线程的环境中，如果不在方法调用端做额外的同步措施，使用这段代码仍然是不安全的。
  - 3.相对线程安全
    - 相对线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单次的操作是线程安全的，我们在调用的时候不需要进行额外的保障措施，但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性
      - 在Java语言中，大部分声称线程安全的类都属于这种类型，例如Vector、HashTable、Collections的 synchronizedCollection()方法包装的集合等。
  - 4.线程兼容
    - 线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。
      - 我们平常说一个类不是线程安全的，通常就是指这种情况。
      - Java类库API中大部分的类都是线程兼容的，如与前面的Vector和HashTable相对应的集合类ArrayList和HashMap等。
  - 5.线程对立
    - 线程对立是指不管调用端是否采取了同步措施，都无法在多线程环境中并发使用代码。由于 Java 语言天生就支持多线程的特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。
      - 一个线程对立的例子是Thread类的suspend()和resume()方法。
        - 也正是这个原因，suspend()和resume()方法都已经被声明废弃了。
      - 常见的线程对立的操作还有System.setIn()、Sytem.setOut()和System.runFinalizersOnExit()等。

##### 13.2.2 线程安全的实现方法

- 1.互斥同步
  - 互斥同步（Mutual Exclusion & Synchronization）是一种最常见也是最主要的并发正确性保障手段。
    - 同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一条（或者是一些，当使用信号量的时候）线程使用。
    - 而互斥是实现同步的一种手段，临界区（Critical Section）、互斥量（Mutex）和信号量（Semaphore）都是常见的互斥实现方式。
      - 因此在“互斥同步”这四个字里面，互斥是因，同步是果；互斥是方法，同步是目的。
  - 在Java里面，最基本的互斥同步手段就是synchronized关键字，这是一种块结构（Block Structured）的同步语法。
    - synchronized关键字经过Javac编译之后，会在同步块的前后分别形成 monitorenter和monitorexit这两个字节码指令。
    - 这两个字节码指令都需要一个reference类型的参数来指明要锁定和解锁的对象。
      - 如果Java源码中的synchronized明确指定了对象参数，那就以这个对象的引用作为reference；
      - 如果没有明确指定，那将根据synchronized修饰的方法类型（如实例方法或类方法），来决定是取代码所在的对象实例还是取类型对应的Class对象来作为线程要持有的锁。
    - 根据《Java虚拟机规范》的要求，在执行monitorenter指令时，首先要去尝试获取对象的锁。
      - 如果这个对象没被锁定，或者当前线程已经持有了那个对象的锁，就把锁的计数器的值增加一，而在执行monitorexit指令时会将锁计数器的值减一。
      - 一旦计数器的值为零，锁随即就被释放了。
      - 如果获取对象锁失败，那当前线程就应当被阻塞等待，直到请求锁定的对象被持有它的线程释放为止。
    - 从功能上看，根据以上《Java虚拟机规范》对monitorenter和monitorexit的行为描述，我们可以得出两个关于synchronized的直接推论，这是使用它时需特别注意的：
      - 被synchronized修饰的同步块对同一条线程来说是**可重入的**。这意味着同一线程反复进入同步块也不会出现自己把自己锁死的情况。
      - 被synchronized修饰的同步块在持有锁的线程执行完毕并释放锁之前，会无条件地阻塞后面其他线程的进入。这意味着无法像处理某些数据库中的锁那样，强制已获取锁的线程释放锁；也无法强制正在等待锁的线程中断等待或超时退出。
    - 从执行成本的角度看，持有锁是一个重量级（Heavy-Weight）的操作。
  - 从上面的介绍中我们可以看到synchronized的局限性，除了synchronized关键字以外，自JDK 5起（实现了JSR 166 [1]），Java类库中新提供了java.util.concurrent包（下文称J.U.C包），其中的java.util.concurrent.locks.Lock接口便成了Java的另一种全新的互斥同步手段。
    - 基于Lock接口，用户能够以非块结构（Non-Block Structured）来实现互斥同步，从而摆脱了语言特性的束缚，改为在类库层面去实现同步，这也为日后扩展出不同调度算法、不同特征、不同性能、不同语义的各种锁提供了广阔的空间。
    - 重入锁（ReentrantLock）是Lock接口最常见的一种实现，顾名思义，它与synchronized一样是可重入的。
    - 在基本用法上，ReentrantLock 也与 synchronized 很相似，只是代码写法上稍有区别而已。不过，ReentrantLock与synchronized相比增加了一些高级功能，主要有以下三项：等待可中断、可实现公平锁及锁可以绑定多个条件。
      - **等待可中断**：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。可中断特性对处理执行时间非常长的同步块很有帮助。
      - **公平锁**：是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock在默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。不过一旦使用了公平锁，将会导致ReentrantLock的性能急剧下降，会明显影响吞吐量。
      - **锁绑定多个条件**：是指一个ReentrantLock对象可以同时绑定多个Condition对象。在synchronized中，锁对象的wait()跟它的notify()或者notifyAll()方法配合可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁；而ReentrantLock则无须这样做，多次调用 newCondition()方法即可。
  - 根据上面的讨论，ReentrantLock在功能上是synchronized的超集，在性能上又至少不会弱于synchronized，那synchronized修饰符是否应该被直接抛弃，不再使用了呢？当然不是，基于以下理由，笔者仍然推荐在synchronized与ReentrantLock都可满足需要时优先使用synchronized：
    - synchronized是在Java语法层面的同步，足够清晰，也足够简单。每个Java程序员都熟悉synchronized，但J.U.C中的Lock接口则并非如此。因此在只需要基础的同步功能时，更推荐synchronized。
    - Lock应该确保在finally块中释放锁，否则一旦受同步保护的代码块中抛出异常，则有可能永远不会释放持有的锁。这一点必须由程序员自己来保证，而使用synchronized的话则可以由Java虚拟机来确保即使出现异常，锁也能被自动释放。
    - 尽管在JDK 5时代ReentrantLock曾经在性能上领先过synchronized，但这已经是十多年之前的胜利了。从长远来看，Java虚拟机更容易针对synchronized来进行优化，因为Java虚拟机可以在线程和对象的元数据中记录synchronized中锁的相关信息，而使用J.U.C中的Lock的话，Java虚拟机是很难得知具体哪些锁对象是由特定线程锁持有的。
- 2.非阻塞同步
  - 互斥同步面临的主要问题是进行线程阻塞和唤醒所带来的性能开销，因此这种同步也被称为**阻塞同步（Blocking Synchronization）**。
    - 从解决问题的方式上看，互斥同步属于一种悲观的并发策略，其总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论共享的数据是否真的会出现竞争，它都会进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁），这将会导致用户态到核心态转换、维护锁计数器和检查是否有被阻塞的线程需要被唤醒等开销。
  - 随着硬件指令集的发展，我们已经有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说就是不管风险，先进行操作，如果没有其他线程争用共享数据，那操作就直接成功了；如果共享的数据的确被争用，产生了冲突，那再进行其他的补偿措施，最常用的补偿措施是不断地重试，直到出现没有竞争的共享数据为止。
    - 这种乐观并发策略的实现不再需要把线程阻塞挂起，因此这种同步操作被称为**非阻塞同步（Non-Blocking Synchronization）**，使用这种措施的代码也常被称为**无锁（Lock-Free）编程**。
  - 因为Java里最终暴露出来的是CAS操作，所以我们以CAS指令为例进行讲解。
    - CAS指令需要有三个操作数，分别是内存位置（在Java中可以简单地理解为变量的内存地址，用V表示）、旧的预期值（用A表示）和准备设置的新值（用B表示）。
    - CAS指令执行时，当且仅当V符合A时，处理器才会用B更新V的值，否则它就不执行更新。
    - 但是，不管是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断。
  - 在JDK 5之后，Java类库中才开始使用CAS操作，该操作由sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供。
    - HotSpot虚拟机在内部对这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，或者可以认为是无条件内联进去了
    - 直到JDK 9之后，Java类库才在VarHandle类里开放了面向用户程序使用的CAS操作。
  - 尽管CAS看起来很美好，既简单又高效，但显然这种操作无法涵盖互斥同步的所有使用场景，并且CAS从语义上来说并不是真正完美的，它存在一个逻辑漏洞：如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然为A值，那就能说明它的值没有被其他线程改变过了吗？这是不能的，因为如果在这段期间它的值曾经被改成B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。
    - 这个漏洞称为CAS操作的“**ABA问题**”。
    - J.U.C包为了解决这个问题，提供了一个带有标记的原子引用类AtomicStampedReference，它可以通过控制变量值的版本来保证CAS的正确性。
- 3.无同步方案
  - 要保证线程安全，也并非一定要进行阻塞或非阻塞同步，同步与线程安全两者没有必然的联系。同步只是保障存在共享数据争用时正确性的手段，如果能让一个方法本来就不涉及共享数据，那它自然就不需要任何同步措施去保证其正确性，因此会有一些代码天生就是线程安全的，笔者简单介绍其中的两类。
    - 可重入代码（Reentrant Code）：这种代码又称纯代码（Pure Code），是指可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误，也不会对结果有所影响。
    - 线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。
      - 我们可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。

#### 13.3 锁优化

- 高效并发是从JDK 5升级到JDK 6后一项重要的改进项，HotSpot虚拟机开发团队在这个版本上花费了大量的资源去实现各种锁优化技术，如适应性自旋（Adaptive Spinning）、锁消除（Lock Elimination）、锁膨胀（Lock Coarsening）、轻量级锁（Lightweight Locking）、偏向锁（Biased Locking）等，这些技术都是为了在线程之间更高效地共享数据及解决竞争问题，从而提高程序的执行效率。

##### 13.3.1 自旋锁与自适应自旋

- 现在绝大多数的个人电脑和服务器都是多路（核）处理器系统，如果物理机器有一个以上的处理器或者处理器核心，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。
  - 为了让线程等待，我们只须让线程执行一个忙循环（自旋），这项技术就是所谓的**自旋锁**。
- 自旋锁在JDK 1.4.2中就已经引入，只不过默认是关闭的，可以使用-XX:+UseSpinning参数来开启，在JDK 6中就已经改为默认开启了。
  - 自旋等待的时间必须有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程。自旋次数的默认值是十次，用户也可以使用参数-XX:PreBlockSpin来自行更改。
- 在JDK 6中对自旋锁的优化，引入了**自适应的自旋**。自适应意味着自旋的时间不再是固定的了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。
  - 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而允许自旋等待持续相对更长的时间
  - 另一方面，如果对于某个锁，自旋很少成功获得过锁，那在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源。

##### 13.3.2 锁消除

- **锁消除**是指虚拟机即时编译器在运行时，对一些代码要求同步，但是对被检测到不可能存在共享数据竞争的锁进行消除。
  - 锁消除的主要判定依据来源于逃逸分析的数据支持（第11章已经讲解过逃逸分析技术），如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须再进行。
  - 也许读者会有疑问，变量是否逃逸，对于虚拟机来说是需要使用复杂的过程间分析才能确定的，但是程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下还要求同步呢？这个问题的答案是：**有许多同步措施并不是程序员自己加入的**，同步的代码在Java程序中出现的频繁程度也许超过了大部分读者的想象。

##### 13.3.3 锁粗化

- 但是如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作是出现在循环体之中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。
- 如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部，这样只需要加锁一次就可以了。

##### 13.3.4 轻量级锁

- 轻量级锁是JDK 6时加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就被称为“重量级”锁。

- 要理解轻量级锁，以及后面会讲到的偏向锁的原理和运作过程，必须要对HotSpot虚拟机对象的内存布局（尤其是对象头部分）有所了解。

  - HotSpot虚拟机的对象头（Object Header）分为两部分

    - 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄（Generational GC Age）等。这部分数据的长度在32位和64位的Java虚拟机中分别会占用32个或64个比特，官方称它为“MarkWord”。
      - 这部分是实现轻量级锁和偏向锁的关键。
    - 另外一部分用于存储指向方法区对象类型数据的指针，如果是数组对象，还会有一个额外的部分用于存储数组长度。这些对象内存布局的详细内容，我们已经在第2章中学习过

  - 由于对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到Java虚拟机的空间使用效率，Mark Word被设计成一个非固定的动态数据结构，以便在极小的空间内存储尽量多的信息。

    - 它会根据对象的状态复用自己的存储空间。

    - 对象除了未被锁定的正常状态外，还有轻量级锁定、重量级锁定、GC标记、可偏向等几种不同状态

    - 这些状态下对象头的存储内容如下表所示。（注：表中 <- 表示该单元格内容为左边写的，Markdown 没有合并单元格，坑爹啊）

    - | 锁状态               | 23bit                             | 2bit  | 4bit     | 1bit（偏向模式） | 2bit（标志位） |
      | -------------------- | --------------------------------- | ----- | -------- | ---------------- | -------------- |
      | 未锁定               | 对象哈希码（25bit）               | <-    | 分代年龄 | 0                | 01             |
      | 轻量级锁定           | 指向调用栈中锁记录的指针（30bit） | <-    | <-       | <-               | 00             |
      | 重量级锁定（锁膨胀） | 指向重量级锁的指针（30bit）       | <-    | <-       | <-               | 10             |
      | GC 标记              | 空（30bit）                       | <-    | <-       | <-               | 11             |
      | 可偏向               | 线程ID                            | Epoch | 分代年龄 | 1                | 01             |

- 我们简单回顾了对象的内存布局后，接下来就可以介绍轻量级锁的工作过程了：

  - 在代码即将进入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方为这份拷贝加了一个Displaced前缀，即Displaced Mark Word）
  - 然后，虚拟机将使用CAS操作尝试把对象的Mark Word更新为指向Lock Record的指针。如果这个更新动作成功了，即代表该线程拥有了这个对象的锁，并且对象Mark Word的锁标志位（Mark Word的最后两个比特）将转变为“00”，表示此对象处于轻量级锁定状态。
  - 如果这个更新操作失败了，那就意味着至少存在一条线程与当前线程竞争获取该对象的锁。
  - 虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。
  - 如果出现两条以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要膨胀为重量级锁，锁标志的状态值变为“10”，此时Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也必须进入阻塞状态。

- 上面描述的是轻量级锁的加锁过程，它的解锁过程也同样是通过CAS操作来进行的

  - 如果对象的 Mark Word仍然指向线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来。假如能够成功替换，那整个同步过程就顺利完成了；如果替换失败，则说明有其他线程尝试过获取该锁，就要在释放锁的同时，唤醒被挂起的线程。

- 轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”这一经验法则。如果没有竞争，轻量级锁便通过CAS操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外发生了CAS操作的开销。因此在有竞争的情况下，轻量级锁反而会比传统的重量级锁更慢。

##### 13.3.5 偏向锁

- 偏向锁也是JDK 6中引入的一项锁优化措施，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。
  - 偏向锁中的“偏”，就是偏心的“偏”、偏袒的“偏”。它的意思是这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁一直没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。
- 假设当前虚拟机启用了偏向锁（启用参数-XX:+UseBiased Locking，这是自JDK 6 起HotSpot虚拟机的默认值），那么当锁对象第一次被线程获取的时候，虚拟机将会把对象头中的标志位设置为“01”、把偏向模式设置为“1”，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如加锁、解锁及对Mark Word的更新操作等）。
  - 一旦出现另外一个线程去尝试获取这个锁的情况，偏向模式就马上宣告结束。根据锁对象目前是否处于被锁定的状态决定是否撤销偏向（偏向模式设置为“0”），撤销后标志位恢复到未锁定（标志位为“01”）或轻量级锁定（标志位为“00”）的状态，后续的同步操作就按照上面介绍的轻量级锁那样去执行。
- 细心的读者看到这里可能会发现一个问题：当对象进入偏向状态的时候，Mark Word大部分的空间（23个比特）都用于存储持有锁的线程ID了，这部分空间占用了原有存储对象哈希码的位置，那原来对象的哈希码怎么办呢？
  - 在Java语言里面一个对象如果计算过哈希码，就应该一直保持该值不变（强烈推荐但不强制，因为用户可以重载hashCode()方法按自己的意愿返回哈希码），否则很多依赖对象哈希码的API都可能存在出错风险。
  - 而作为绝大多数对象哈希码来源的Object::hashCode()方法，返回的是对象的一致性哈希码（Identity Hash Code），这个值是能强制保证不变的，它通过在对象头中存储计算结果来保证第一次计算之后，再次调用该方法取到的哈希码值永远不会再发生改变。
  - 因此，当一个对象已经计算过一致性哈希码后，它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态，又收到需要计算其一致性哈希码请求（注意，这里说的计算请求应来自于对Object::hashCode()或者System::identityHashCode(Object)方法的调用，如果重写了对象的hashCode()方法，计算哈希码时并不会产生这里所说的请求）时，它的偏向状态会被立即撤销，并且锁会膨胀为重量级锁。
  - 在重量级锁的实现中，对象头指向了重量级锁的位置，代表重量级锁的ObjectMonitor类里有字段可以记录非加锁状态（标志位为“01”）下的Mark Word，其中自然可以存储原来的哈希码。
- 偏向锁可以提高带有同步但无竞争的程序性能，但它同样是一个带有效益权衡（Trade Off）性质的优化，也就是说它并非总是对程序运行有利。如果程序中大多数的锁都总是被多个不同的线程访问，那偏向模式就是多余的。在具体问题具体分析的前提下，有时候使用参数-XX:-UseBiasedLocking来禁止偏向锁优化反而可以提升性能。